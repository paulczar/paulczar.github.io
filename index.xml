<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Paul Czarkowski</title>
    <link>http://tech.paulcz.net/index.xml</link>
    <description>Recent content on Paul Czarkowski</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 25 Jun 2017 09:04:08 -0600</lastBuildDate>
    <atom:link href="http://tech.paulcz.net/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Resume for Paul Czarkowski</title>
      <link>http://tech.paulcz.net/page/resume/</link>
      <pubDate>Sun, 25 Jun 2017 09:04:08 -0600</pubDate>
      
      <guid>http://tech.paulcz.net/page/resume/</guid>
      <description>

&lt;h1 id=&#34;paul-czarkowski&#34;&gt;Paul Czarkowski&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Technical Lead, IBM Cloud Developer Labs&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;mailto:username.taken@gmail.com&#34;&gt;username.taken@gmail.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://tech.paulcz.net/&#34;&gt;http://tech.paulcz.net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/paulczar&#34;&gt;https://github.com/paulczar&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Work Permits : US, Australian, UK/Europe.&lt;/p&gt;

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;

&lt;p&gt;I am an experienced hands-on Architect / DevOps Engineer with a long history in Operations and Infrastructure Automation.  I have a broad depth of experience across most IT and Operations related areas with strong experience in using and evangelizing DevOps tools and methodologies.&lt;/p&gt;

&lt;p&gt;My current role at IBM has me focused on helping to rebuild the IBM developer advocacy programs and content creation processes.  Previous to that I led the conversion of our OpenStack Automation platform (&lt;a href=&#34;https://github.com/blueboxgroup/ursula&#34;&gt;ursula&lt;/a&gt;) from just Ubuntu to also supporting Redhat Enterprise Linux.  I also architected and built the Blue Box Cloud SRE Operations Platform (which we recently open-sourced as &lt;a href=&#34;https://github.com/IBM/cuttle&#34;&gt;cuttle&lt;/a&gt;) and built a team to maintain it.&lt;/p&gt;

&lt;p&gt;Previous to IBM/Blue Box I was at Rackspace where I worked on a team building a product with Docker on top of Openstack, and before that I worked at EA where I helped build and design the infrastructure for SimCity ( on AWS ) and SWTOR ( own data centers, approx 6,000 servers, 2M+ subscribers at launch ).&lt;/p&gt;

&lt;h2 id=&#34;speaking-engagements&#34;&gt;Speaking Engagements&lt;/h2&gt;

&lt;p&gt;see &lt;a href=&#34;http://tech.paulcz.net/page/speaker/&#34;&gt;http://tech.paulcz.net/page/speaker/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;open-source-and-passion-projects&#34;&gt;Open Source and Passion Projects&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;In an effort to learn more about Kubernetes I got involved in the Kargo/Kubespray community and made a significant amount of contributions to help improve the quality of the Ansible being written and the composability of the Roles. Surprisingly a year on I&amp;rsquo;m still in the top &lt;a href=&#34;https://github.com/kubernetes-incubator/kubespray/graphs/contributors&#34;&gt;5 contributors&lt;/a&gt; (based on lines of code, which is obviously the most important metric AMIRITE)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Built out a Chef Inspec Repository for &lt;a href=&#34;https://github.com/inspec-stigs/inspec-stig-rhel6&#34;&gt;RedHat 6 STIG auditing&lt;/a&gt; and formed a small community around using &lt;a href=&#34;https://github.com/inspec-stigs&#34;&gt;Inspec for STIG auditing&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;I got tired of fighting openssl commands to create SSL/TLS for development so I built a Docker Image called &lt;a href=&#34;https://github.com/paulczar/omgwtfssl&#34;&gt;omgwtfssl&lt;/a&gt; that takes a few environment variables and spits out a CA/key/cert combo.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;As a joke I wrote a 100 lines of code IPVS load balancer called &lt;a href=&#34;https://github.com/paulczar/lolbalancer&#34;&gt;lolbalancer&lt;/a&gt;, but have actually found it to be useful on occasion for demonstrations.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Over Christmas 2014 I built out &lt;a href=&#34;https://github.com/factorish/factorish&#34;&gt;Factorish&lt;/a&gt; as a concept to show managing the life-cycle and configuration of applications in Docker using service discovery, and built several example apps such as &lt;a href=&#34;https://github.com/paulczar/docker-percona_galera&#34;&gt;Percona with Galera Replication&lt;/a&gt; and the &lt;a href=&#34;https://github.com/factorish/factorish-elk&#34;&gt;ELK stack&lt;/a&gt;.  Some of these concepts have found their way into tools such as &lt;a href=&#34;https://github.com/joyent/containerpilot&#34;&gt;Container Pilot&lt;/a&gt; and &lt;a href=&#34;https://habitat.sh&#34;&gt;Habitat.sh&lt;/a&gt;.  I also used it as a basis for a &lt;a href=&#34;http://tech.paulcz.net/blog/factorish_and_the_12_fakter_app/&#34;&gt;blog post&lt;/a&gt; and a series of talks I gave on Dockerizing apps that really shouldn’t be Dockerized.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;professional-accomplishments&#34;&gt;Professional Accomplishments&lt;/h2&gt;

&lt;h3 id=&#34;ibm-blue-box&#34;&gt;IBM / Blue Box&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Led the effort to port the Blue Box OpenStack automation tool (&lt;a href=&#34;https://github.com/blueboxgroup/ursula&#34;&gt;ursula&lt;/a&gt;) to support RedHat Enterprise Linux as well as Ubuntu (&lt;a href=&#34;https://www.ibm.com/blogs/bluemix/2017/04/ibm-bluemix-private-cloud-red-hat/&#34;&gt;see&lt;/a&gt;), with full STIG compliance and Chef Inspec for auditing.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Recognized the need for a unified SRE Operations Platform to support growth and built SiteController (&lt;a href=&#34;https://github.com/IBM/cuttle&#34;&gt;cuttle&lt;/a&gt;) and architected and built it, later forming and leading a team to maintain and develop it further.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Successfully led the effort to make Blue Box OpenStack installable in customer data centers with no Internet access utilizing SiteController and overhauling large parts of Ursula.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;rackspace&#34;&gt;Rackspace&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Built the initial Build/Push/Run workflow for the [now mostly defunct] OpenStack PaaS project (Solum) utilizing Docker and the Cedarish style workflow demonstrated by Dokku and DEIS.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Worked on the OpenStack nova-docker driver, and was the first [that I know of] person to successfully run &lt;a href=&#34;https://github.com/paulczar/dockenstack&#34;&gt;OpenStack in Docker&lt;/a&gt; containers.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Maintained Community Chef Cookbooks for Elasticsearch, Logstash, and Kibana.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;electronic-arts&#34;&gt;Electronic Arts&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Planned and Executed migration of live game services for multiple games from their existing expensive datacenters to spare capacity from the cheaper BioWare datacenters.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Built and deployed dozens of websites for game code redemptions and blogs into Amazon using Rightscale.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Helped build and scale Sim City Online servers in Amazon using Rightscale, implemented monitoring and logging systems to help debug and discover load and performance issues during launch instability.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;bioware-star-wars-the-old-republic-swtor&#34;&gt;BioWare – Star Wars The Old Republic (SWTOR)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Supported the studio during development.   Lead the Online Operations team through purchasing and deploying over 6,000 servers in four data centers to run the online environment. Ensured a successful and glitch free  launch of SWTOR on the 20th December 2011.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Built a large cluster of Xen Hypervisors to provide virtual game servers for development and wrote scripts for deploying game databases from SAN snapshots ( reducing storage requirements from 36Tb to less than 1Tb ).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Successfully deployed a proof of concept private cloud with CloudStack to further increase our Virtualization abilities and create a self-service portal for our developers.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;employment-history&#34;&gt;Employment History&lt;/h2&gt;

&lt;h3 id=&#34;bluebox-an-ibm-company-nov-2014-to-current&#34;&gt;BlueBox an IBM Company – Nov 2014 to Current&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Austin, Texas&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Technical Lead, IBM Cloud Developer Labs,&lt;/p&gt;

&lt;p&gt;Architect / Senior DevOps Engineer,&lt;/p&gt;

&lt;p&gt;Technical lead of Site Controller team.&lt;/p&gt;

&lt;h3 id=&#34;rackspace-nov-2013-to-nov-2014&#34;&gt;Rackspace – Nov 2013 to Nov 2014&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Austin, Texas&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Senior Operations Engineer&lt;/p&gt;

&lt;h3 id=&#34;ea-bioware-april-2008-to-nov-2013&#34;&gt;EA / BioWare – April 2008 to Nov 2013&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Austin, Texas&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Manager, Systems Engineering &lt;em&gt;( March 2012 to current )&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Lead Systems Engineer  &lt;em&gt;( 2010  to March 2012 )&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Senior Systems Engineer  ( 2008 to 2010 )&lt;/p&gt;

&lt;h3 id=&#34;older&#34;&gt;Older&lt;/h3&gt;

&lt;p&gt;2004 - 2008 : IT Manager, Pandemic Studios.
2001 - 2004 : NOC Manager iTEL Community Telco
2000 – 2001 : Systems Administrator / Web Application Developer BMC Networks
1999 – 2000 : Systems Administrator, Global Info-Links
1998 – 1999 : Computer Technician, Altech Computers
1998             : Computer Technician, Harvey Norman
1997 - 1998  : OzNetCom&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;Available on request.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>http://tech.paulcz.net/page/about/</link>
      <pubDate>Fri, 16 Dec 2016 09:04:08 -0600</pubDate>
      
      <guid>http://tech.paulcz.net/page/about/</guid>
      <description>&lt;p&gt;Paul is an Infrastructure Engineer who has been doing IT and Operations for longer than he cares to admit and has worked across many industries, retail, game development, managed hosting, and more.  He has worked in both very large and very small organizations.&lt;/p&gt;

&lt;p&gt;As an avid Technologist he can be found tinkering with emergent technologies (hello running docker in production in 2014) and optimizing and codifying the operations of large legacy applications.&lt;/p&gt;

&lt;p&gt;Paul is an active member of the Austin Technology scene and is often found at the &lt;a href=&#34;https://www.meetup.com/austin-devops/&#34;&gt;Austin DevOps&lt;/a&gt;, &lt;a href=&#34;https://www.meetup.com/CloudAustin/&#34;&gt;Cloud Austin&lt;/a&gt;, &lt;a href=&#34;https://www.meetup.com/Docker-Austin/&#34;&gt;Docker Austin&lt;/a&gt;, and &lt;a href=&#34;https://www.meetup.com/OpenStack-Austin/&#34;&gt;OpenStack Austin&lt;/a&gt; both as a attendee and as a &lt;a href=&#34;http://tech.paulcz.net/page/speaker&#34;&gt;speaker&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Paul also helps organize local community conferences such as &lt;a href=&#34;https://www.devopsdays.org/events/2016-austin/welcome/&#34;&gt;DevOps Days Austin&lt;/a&gt; and &lt;a href=&#34;http://www.containerdaysaustin.com&#34;&gt;Container Days Austin&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Technology isn&amp;rsquo;t his only interest though.  Paul has a love of cooking and can often be found baking sourdough bread and cooking Texas style barbecue in his custom offset pit and competing ( and winning ) in food competitions both locally and interstate.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paul Talks about stuff</title>
      <link>http://tech.paulcz.net/page/speaker/</link>
      <pubDate>Fri, 16 Dec 2016 09:04:08 -0600</pubDate>
      
      <guid>http://tech.paulcz.net/page/speaker/</guid>
      <description>

&lt;p&gt;An incomplete list of events that I&amp;rsquo;ve spoken at&lt;/p&gt;

&lt;h1 id=&#34;2016&#34;&gt;2016&lt;/h1&gt;

&lt;h2 id=&#34;all-day-devops&#34;&gt;All Day DevOps&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Serverfull computing - &lt;a href=&#34;https://youtu.be/MOrWDvpZTdY?t=4874&#34;&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;openstack-summit-barcelona&#34;&gt;OpenStack Summit Barcelona&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;InterOp Panel - &lt;a href=&#34;https://www.openstack.org/videos/barcelona-2016/interop-you-keep-using-that-word-i-do-not-think-it-means-what-you-think-it-means&#34;&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;OpenStack Compliance the DevOps way - &lt;a href=&#34;https://www.openstack.org/videos/barcelona-2016/openstack-compliance-the-devops-way&#34;&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;openstack-day-seattle&#34;&gt;OpenStack Day Seattle&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;99 OpenStack clouds on the wall - &lt;a href=&#34;https://www.youtube.com/watch?v=erjUIO0kKI8&#34;&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;openstack-summit-austin&#34;&gt;OpenStack Summit Austin&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;A PaaS for Continuous Delivery - &lt;a href=&#34;https://www.openstack.org/videos/austin-2016/a-paas-for-continuous-delivery-of-cloud-native-apps-minus-kubernetes-and-mesos&#34;&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;2015&#34;&gt;2015&lt;/h1&gt;

&lt;h2 id=&#34;openstack-summit-tokyo&#34;&gt;OpenStack Summit Tokyo&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Chef vs Ansible vs Puppet vs Salt - &lt;a href=&#34;https://www.openstack.org/videos/tokio-2015/chef-vs-puppet-vs-ansible-vs-salt-whats-best-for-deploying-and-managing-openstack&#34;&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;devops-days-austin&#34;&gt;DevOps Days Austin&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Scout-A-Park a story of pragmatic dockerization - &lt;a href=&#34;https://vimeo.com/album/3437844/video/129894208&#34;&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;openstack-day-seattle-1&#34;&gt;OpenStack Day Seattle&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Just enough OpenStack for Docker - &lt;a href=&#34;https://www.youtube.com/watch?v=mYYa84WQowQ&#34;&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;openstack-summit-vancouver&#34;&gt;OpenStack Summit Vancouver&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Docker Docker Docker Openstack - &lt;a href=&#34;https://www.openstack.org/videos/vancouver-2015/docker-docker-docker-openstack&#34;&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;docker-austin-meetup&#34;&gt;Docker Austin meetup&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Factorish - &lt;a href=&#34;https://www.youtube.com/watch?v=uqKPgc8jMkI&#34;&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;2014&#34;&gt;2014&lt;/h1&gt;

&lt;h2 id=&#34;dockercon14&#34;&gt;DockerCon14&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Automated Chef cookbook testing with Drone.io and GitHub - &lt;a href=&#34;https://www.youtube.com/watch?v=9_H41VFfKcM&#34;&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Flexible Private Docker Registry Infrastructure</title>
      <link>http://tech.paulcz.net/2016/01/flexible-docker-registry-infrastructure/</link>
      <pubDate>Sun, 10 Jan 2016 10:22:22 -0600</pubDate>
      
      <guid>http://tech.paulcz.net/2016/01/flexible-docker-registry-infrastructure/</guid>
      <description>

&lt;p&gt;Previously I showed how to run a &lt;a href=&#34;http://tech.paulcz.net/2016/01/deploying-a-secure-docker-registry/&#34;&gt;basic secure Docker Registry&lt;/a&gt;.  I am now going to expand on this to show you something that you might use in production as part of your CI/CD infrastructure.&lt;/p&gt;

&lt;p&gt;The beauty of running Docker is that you &lt;em&gt;can&lt;/em&gt; push an image from a developer&amp;rsquo;s laptop all the way into production which helps ensure that what you see in development and your various test/qa/stage environments are exactly the same as what you run in production.&lt;/p&gt;

&lt;p&gt;So they tell you anyway. The reality is that you don&amp;rsquo;t ever want to push an image built on a developer&amp;rsquo;s machine into production as you can&amp;rsquo;t be sure what is in it.  Instead you want to have a trusted build server build images from a &lt;code&gt;Dockerfile&lt;/code&gt; in your git repository and have it promoted through your environments from there.&lt;/p&gt;

&lt;p&gt;To ensure the integrity of your images you&amp;rsquo;ll want to run a Docker Registry that can be reached by all of your servers (and potentially people), but can only be written to by your build server (and/or an administrative user).&lt;/p&gt;

&lt;p&gt;You could run your &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; behind a &lt;a href=&#34;https://docs.docker.com/registry/recipes/&#34;&gt;complicated reverse proxy&lt;/a&gt; and create rules about who can GET/POST/etc through to the &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; however we can use the magic of &amp;ldquo;&lt;a href=&#34;https://github.com/panicsteve/cloud-to-butt&#34;&gt;The Cloud&lt;/a&gt;&amp;rdquo; to reduce the complexity and thus the need for a reverse proxy.&lt;/p&gt;

&lt;p&gt;You will want to use either the &lt;a href=&#34;https://wiki.openstack.org/wiki/Swift&#34;&gt;Openstack Swift&lt;/a&gt; or the &lt;a href=&#34;https://aws.amazon.com/s3/&#34;&gt;Amazon S3&lt;/a&gt; object storage driver for the &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt;. I will demonstrate using Swift, but using S3 should be very similar.&lt;/p&gt;

&lt;p&gt;You will of course want to also build all of these servers with Configuration Management including the commands to actually run the &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;build-server-s&#34;&gt;Build Server(s)&lt;/h2&gt;

&lt;p&gt;For your build server(s) you&amp;rsquo;ll want to be running an OS with Docker installed on it. I use the &lt;a href=&#34;https://hub.docker.com/_/jenkins/&#34;&gt;Jenkins&lt;/a&gt; Docker image on &lt;a href=&#34;http://coreos.com/&#34;&gt;CoreOS&lt;/a&gt; for both my Jenkins Master and Slaves, however this is just personal preference.&lt;/p&gt;

&lt;p&gt;On each server you want to run a &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; with your Swift credentials passed through to it. Since we&amp;rsquo;re only accessing this via &lt;code&gt;127.0.0.1&lt;/code&gt; we do not need to secure it with TLS or authentication.&lt;/p&gt;

&lt;p&gt;Run the following on each build server to run the Registry backed by Swift, replacing the OpenStack credentials with your own:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;build01$ docker run -d \
              -p 127.0.0.1:5000:5000 \
              --name registry \
              --restart always \
              -e REGISTRY_STORAGE=swift \
              -e REGISTRY_STORAGE_SWIFT_USERNAME=${OS_USERNAME} \
              -e REGISTRY_STORAGE_SWIFT_PASSWORD=${OS_PASSWORD} \
              -e REGISTRY_STORAGE_SWIFT_TENANT=${OS_TENANT} \
              -e REGISTRY_STORAGE_SWIFT_AUTHURL=${OS_AUTH_URL} \
              -e REGISTRY_STORAGE_SWIFT_CONTAINER=docker-registry \
              registry:2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Push an image to make sure it worked:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;build01$ docker pull alpine
Using default tag: latest
latest: Pulling from library/alpine
Digest: sha256:78a756d480bcbc35db6dcc05b08228a39b32c2b2c7e02336a2dcaa196547a41d
Status: Downloaded newer image for alpine:latest
$ docker tag alpine 127.0.0.1:5000/alpine
$ docker push 127.0.0.1:5000/alpine
The push refers to a repository [127.0.0.1:5000/alpine] (len: 1)
74e49af2062e: Pushed 
latest: digest: sha256:a96155be113bb2b4b82ebbc11cf1b511726c5b41617a70e0772f8180afc72fa5 size: 1369
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you have more that one build server try to pull the image from one of the others, since we&amp;rsquo;re backing the &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; with an object store they should retrieve it just fine:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;build02$ docker pull 127.0.0.1:5000/alpine
Using default tag: latest
latest: Pulling from alpine

340b2f9a2643: Already exists 
Digest: sha256:a96155be113bb2b4b82ebbc11cf1b511726c5b41617a70e0772f8180afc72fa5
Status: Downloaded newer image for 127.0.0.1:5000/alpine:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;regular-server-s&#34;&gt;Regular Server(s)&lt;/h2&gt;

&lt;p&gt;We have a couple of options here.  You can run a &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; on each server listening only on localhost, or you can run one or more of them on their own servers that will listen on an IP and be secured with TLS.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll cover the former use case, for the latter use case you can adapt the instructions found &lt;a href=&#34;http://tech.paulcz.net/2016/01/deploying-a-secure-docker-registry/&#34;&gt;at my previous blog post&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The important step in either case is to start the Registry as read-only so that regular servers cannot alter the contents of the Registry.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; is fairly light-weight when the files are in external storage and thus will use a neglible amount of your system resources and provides the advantages and security of running the registry on localhost and not needed to set &lt;code&gt;--insecure-registry&lt;/code&gt; settings or worrying about TLS certs for the docker daemon.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d \
      -p 127.0.0.1:5000:5000 \
      --name registry \
      --restart always \
      -e REGISTRY_STORAGE_MAINTENANCE_READONLY=&#39;enabled: true&#39; \
      -e REGISTRY_STORAGE=swift \
      -e REGISTRY_STORAGE_SWIFT_USERNAME=${OS_USERNAME} \
      -e REGISTRY_STORAGE_SWIFT_PASSWORD=${OS_PASSWORD} \
      -e REGISTRY_STORAGE_SWIFT_TENANT=${OS_TENANT} \
      -e REGISTRY_STORAGE_SWIFT_AUTHURL=${OS_AUTH_URL} \
      -e REGISTRY_STORAGE_SWIFT_CONTAINER=docker-registry \
      registry:2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With &lt;code&gt;REGISTRY_STORAGE_MAINTENANCE_READONLY=&#39;enabled: true&lt;/code&gt; set, when we try to push to the registry it should fail:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker push 127.0.0.1:5000/alpine
The push refers to a repository [127.0.0.1:5000/alpine] (len: 1)
f4fddc471ec2: Preparing 
Error parsing HTTP response: invalid character &#39;M&#39; looking for beginning of value: &amp;quot;Method not allowed\n&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;user-access-to-registry&#34;&gt;User Access to Registry:&lt;/h2&gt;

&lt;p&gt;If you want to provide access to regular users and don&amp;rsquo;t mind maintaining the password files locally you can adapt my &lt;a href=&#34;http://tech.paulcz.net/2016/01/deploying-a-secure-docker-registry/&#34;&gt;basic secure Docker Registry&lt;/a&gt; blog post to use the object storage backend.&lt;/p&gt;

&lt;p&gt;Assuming you&amp;rsquo;ve followed the instructions provided to create the TLS certificates you can run two &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt;s each pointing at a different &lt;code&gt;htpasswd&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;These can run on the same server, or on seperate servers.  They can also be run on multiple servers that are load balanced via an external load balancer or via round-robin-dns for high availability.&lt;/p&gt;

&lt;h3 id=&#34;read-only-users&#34;&gt;Read only Users&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d \
      -p 443:5000 \
      --name registry \
      --restart always \
      -v /opt/registry \
      -e REGISTRY_STORAGE_MAINTENANCE_READONLY=&#39;enabled: true&#39; \
      -e REGISTRY_STORAGE=swift \
      -e REGISTRY_STORAGE_SWIFT_USERNAME=${OS_USERNAME} \
      -e REGISTRY_STORAGE_SWIFT_PASSWORD=${OS_PASSWORD} \
      -e REGISTRY_STORAGE_SWIFT_TENANT=${OS_TENANT} \
      -e REGISTRY_STORAGE_SWIFT_AUTHURL=${OS_AUTH_URL} \
      -e REGISTRY_STORAGE_SWIFT_CONTAINER=docker-registry \
      -e REGISTRY_AUTH=htpasswd \
      -e &amp;quot;REGISTRY_AUTH_HTPASSWD_REALM=Admin Registry Realm&amp;quot; \
      -e REGISTRY_AUTH_HTPASSWD_PATH=/opt/registry/auth/admin.htpasswd \
      -e REGISTRY_HTTP_SECRET=qerldsljckjqr \
      -e REGISTRY_HTTP_TLS_CERTIFICATE=/opt/registry/ssl/cert.pem \
      -e REGISTRY_HTTP_TLS_KEY=/opt/registry/ssl/key.pem \
      registry:2
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;admin-read-write&#34;&gt;Admin Read/Write&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d \
      -p 444:5000 \
      --name registry \
      --restart always \
      -v /opt/registry \
      -e REGISTRY_STORAGE=swift \
      -e REGISTRY_STORAGE_SWIFT_USERNAME=${OS_USERNAME} \
      -e REGISTRY_STORAGE_SWIFT_PASSWORD=${OS_PASSWORD} \
      -e REGISTRY_STORAGE_SWIFT_TENANT=${OS_TENANT} \      
      -e REGISTRY_STORAGE_SWIFT_AUTHURL=${OS_AUTH_URL} \
      -e REGISTRY_STORAGE_SWIFT_CONTAINER=docker-registry \
      -e REGISTRY_AUTH=htpasswd \
      -e &amp;quot;REGISTRY_AUTH_HTPASSWD_REALM=Read Only Registry Realm&amp;quot; \
      -e REGISTRY_AUTH_HTPASSWD_PATH=/opt/registry/auth/users.htpasswd \
      -e REGISTRY_HTTP_SECRET=hlyrehbrvgszd \
      -e REGISTRY_HTTP_TLS_CERTIFICATE=/opt/registry/ssl/cert.pem \
      -e REGISTRY_HTTP_TLS_KEY=/opt/registry/ssl/key.pem \
      registry:2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Before pushing or pull images to these registries you&amp;rsquo;ll need to log in using &lt;code&gt;docker login myregistrydomain.com:443&lt;/code&gt; or &lt;code&gt;docker login myregistrydomain.com:444&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;By using external storage for the Registry we have increased our ability to run a resiliant Docker Registry with no single points of failure. All of the servers access the registry itself via localhost which means they have almost no reliance on external systems (except for a very robust object storage platform) and no need for complicated authentication systems.&lt;/p&gt;

&lt;p&gt;We also provide access to both Admin (read/write) and Regular (read-only) users via &lt;code&gt;htpasswd&lt;/code&gt; files and &lt;code&gt;TLS&lt;/code&gt; certificates/encryption which can be managed by Configuration Management.&lt;/p&gt;

&lt;p&gt;It goes without saying that you should further lock down all of these services with network based access restrictions in the form of Firewall/IPTables/Security-Groups so that only certain trusted networks can access any of the public endpoints we have created.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deploying a Simple and Secure Docker Registry</title>
      <link>http://tech.paulcz.net/2016/01/deploying-a-secure-docker-registry/</link>
      <pubDate>Sun, 10 Jan 2016 05:22:22 -0600</pubDate>
      
      <guid>http://tech.paulcz.net/2016/01/deploying-a-secure-docker-registry/</guid>
      <description>

&lt;p&gt;There comes a time in everybody&amp;rsquo;s life where they realize they have to run their own &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt;. Unfortunately there&amp;rsquo;s not a lot of good information on how to run one. &lt;a href=&#34;http://docker.com&#34;&gt;Docker&lt;/a&gt;&amp;rsquo;s documentation is pretty good, but is verbose and across a lot of different pages which means having half a dozen tabs open and searching for the right information.&lt;/p&gt;

&lt;p&gt;While it&amp;rsquo;s pretty common to run the &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; itself with little to no security settings and fronting it with NGINX or Apache to provide this security I wanted to show how it can be done with just the &lt;a href=&#34;http://docker.com&#34;&gt;Docker&lt;/a&gt; Registry. If you need to do really clever stuff like authenticate against LDAP then you&amp;rsquo;ll want to go down the reverse proxy road.&lt;/p&gt;

&lt;p&gt;This example will demonstrate using just the &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; itself with both TLS certificate backed encryption and Certificate based endpoint authorization.&lt;/p&gt;

&lt;p&gt;For simplicity it will assume a single registry running on the local filesystem and will avoid using OS specific init (systemd/upstart/etc) systems by focusing just on the docker commands themselves.  This should work on any system capable of running &lt;a href=&#34;http://docker.com&#34;&gt;Docker&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;

&lt;p&gt;Boot a server that has &lt;a href=&#34;http://docker.com&#34;&gt;Docker&lt;/a&gt; installed. For an OS with &lt;a href=&#34;http://docker.com&#34;&gt;Docker&lt;/a&gt; already installed I recommend &lt;a href=&#34;http://coreos.com/&#34;&gt;CoreOS&lt;/a&gt;. However you could just as easily boot Ubuntu or CentOS and run &lt;code&gt;curl -sSL get.docker.com | sudo bash&lt;/code&gt; if you&amp;rsquo;re into that sort of thing.&lt;/p&gt;

&lt;p&gt;SSH into the server and ensure &lt;a href=&#34;http://docker.com&#34;&gt;Docker&lt;/a&gt; is working:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh core@xx.xx.xx.xx
$ docker info
Containers: 0
Images: 0
Server Version: 1.9.1
Storage Driver: overlay
 Backing Filesystem: extfs
Execution Driver: native-0.2
Logging Driver: json-file
Kernel Version: 4.3.3-coreos
Operating System: CoreOS 899.1.0
CPUs: 1
Total Memory: 997.4 MiB
Name: core-01
ID: C5XV:CZ3H:EAO4:ATJ3:ARSO:UOGD:XH3X:UKLZ:V3FO:2LRF:6E3X:CV5K
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;create-certificates&#34;&gt;Create Certificates&lt;/h2&gt;

&lt;p&gt;To keep this as simple as possible I will demonstrate using the &lt;a href=&#34;https://github.com/paulczar/omgwtfssl&#34;&gt;paulczar/omgwtfssl&lt;/a&gt; image to create certificates. If you would rather create them manually via the &lt;code&gt;openssl&lt;/code&gt; cli see my blog post on &lt;a href=&#34;http://tech.paulcz.net/2016/01/secure-docker-with-tls/&#34;&gt;Securing Docker with TLS&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We need to create a place on the filesystem to store the data for the registry as well as certificates and config data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mkdir -p /opt/registry/{data,ssl,config}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can create the certificates, add any IPs and DNS that you might address your registry with including that of any loadbalancer or floating IP that you might have:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run --rm \
  -v /opt/registry/ssl:/certs \
  -e SSL_IP=172.17.8.101 \
  -e SSL_DNS=registry.local \
  paulczar/omgwtfssl
----------------------------
| OMGWTFSSL Cert Generator |
----------------------------

--&amp;gt; Certificate Authority
====&amp;gt; Generating new CA key ca-key.pem
Generating RSA private key, 2048 bit long modulus
................+++
.................................+++
e is 65537 (0x10001)
====&amp;gt; Generating new CA Certificate ca.pem
====&amp;gt; Generating new config file openssl.cnf
====&amp;gt; Generating new SSL KEY key.pem
Generating RSA private key, 2048 bit long modulus
..........................................................+++
.............................................+++
e is 65537 (0x10001)
====&amp;gt; Generating new SSL CSR key.csr
====&amp;gt; Generating new SSL CERT cert.pem
Signature ok
subject=/CN=example.com
Getting CA Private Key

core@core-01 ~ $ ls /opt/registry/ssl/
ca-key.pem  ca.pem  ca.srl  cert.pem  key.csr  key.pem  openssl.cnf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our next step is to create a config file &lt;code&gt;/opt/registry/config/registry.env&lt;/code&gt; which will contain a list of Environment Variables that will be passed into the container:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;For this example I&amp;rsquo;m using the same CA certificate for clients as I did for the server, in reality it should probably be a different CA.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# location of registry data
REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY=/opt/registry/data

# location of TLK key/cert
REGISTRY_HTTP_TLS_KEY=/opt/registry/ssl/key.pem
REGISTRY_HTTP_TLS_CERTIFICATE=/opt/registry/ssl/cert.pem

# location of CA of trusted clients
REGISTRY_HTTP_TLS_CLIENTCAS_0=/opt/registry/ssl/ca.pem
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All that is left to do now is start the registry container, bind mount in the &lt;code&gt;/opt/registry&lt;/code&gt; directory, pass in the config file, and expose port &lt;code&gt;443&lt;/code&gt; to the internal registry port:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d --name registry \
  -v /opt/registry:/opt/registry \
  -p 443:5000 --restart always \
  --env-file /opt/registry/config/registry.env \
  registry:2
Unable to find image &#39;registry:2&#39; locally
2: Pulling from library/registry
Digest: sha256:a842b52833778977f7b4466b90cc829e0f9aae725aebe3e32a5a6c407acd2a03
Status: Downloaded newer image for registry:2
d0106555b2d0aa30691c75c50b279e6a8bd485aa4ba2f203773e971988253169  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can check that we can access it from the server itself by tagging and pushing the &lt;code&gt;alpine&lt;/code&gt; image to it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker pull alpine
Using default tag: latest
latest: Pulling from library/alpine
Digest: sha256:78a756d480bcbc35db6dcc05b08228a39b32c2b2c7e02336a2dcaa196547a41d
Status: Downloaded newer image for alpine:latest
$ docker tag alpine 127.0.0.1/alpine
$ docker push 127.0.0.1/alpine
The push refers to a repository [127.0.0.1/alpine] (len: 1)
74e49af2062e: Pushed 
latest: digest: sha256:a96155be113bb2b4b82ebbc11cf1b511726c5b41617a70e0772f8180afc72fa5 size: 1369
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To check the security settings worked we&amp;rsquo;ll try to access the docker registry from a remote host:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Anywhere you see &lt;code&gt;172.17.8.101&lt;/code&gt; you will want to replace it with the IP or hostname of your docker registry.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker pull 172.17.8.101/alpine
Using default tag: latest
Error response from daemon: unable to ping registry endpoint https://172.17.8.101/v0/
v2 ping attempt failed with error: Get https://172.17.8.101/v2/: x509: certificate signed by unknown authority
 v1 ping attempt failed with error: Get https://172.17.8.101/v1/_ping: x509: certificate signed by unknown authority
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;On the server we can see this failure in the docker logs:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker logs registry
2016/01/10 16:18:47 http: TLS handshake error from 172.17.8.1:44096: remote error: bad certificate
2016/01/10 16:18:47 http: TLS handshake error from 172.17.8.1:44098: remote error: bad certificate
2016/01/10 16:18:47 http: TLS handshake error from 172.17.8.1:44099: remote error: bad certificate
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are two things causing this failure. The first is that the remote server does not trust the client because it cannot provide the trusted CA certificate as specified in &lt;code&gt;REGISTRY_HTTP_TLS_CLIENTCAS_0&lt;/code&gt;. The second reason for failure is that the client doesn&amp;rsquo;t trust the &lt;code&gt;CA&lt;/code&gt; of the server.&lt;/p&gt;

&lt;p&gt;If we didn&amp;rsquo;t have &lt;code&gt;REGISTRY_HTTP_TLS_CLIENTCAS_0&lt;/code&gt; set we could simply add &lt;code&gt;--insecure-registry 172.17.8.101&lt;/code&gt; to &lt;code&gt;DOCKER_OPTS&lt;/code&gt; in &lt;code&gt;/etc/default/docker&lt;/code&gt;, however since we do have this set we&amp;rsquo;ll want to take the &lt;code&gt;CA.pem&lt;/code&gt; and save it as &lt;code&gt;/etc/docker/certs.d/172.17.8.101/ca.crt&lt;/code&gt; on the remote machine that you want to trust the registry server.&lt;/p&gt;

&lt;p&gt;I do this with the following commands, you may need to do it differently based on how your server is set up for access:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mkdir -p /etc/docker/certs.d/172.17.8.101
$ sudo scp core@172.17.8.101:/opt/docker/registry/ca.pem \
    /etc/docker/certs.d/172.17.8.101/ca.crt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have established trust in both directions we can try to access the docker registry again:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker pull 172.17.8.101/alpine
Using default tag: latest
latest: Pulling from alpine

340b2f9a2643: Already exists 
Digest: sha256:a96155be113bb2b4b82ebbc11cf1b511726c5b41617a70e0772f8180afc72fa5
Status: Downloaded newer image for 172.17.8.101/alpine:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Success!   We know have a &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; that is secured both with Encryption and an authorization based on each client having a specific CA certificate.  This setup is ideal for providing secure access to a private registry for remote servers.&lt;/p&gt;

&lt;p&gt;If you want to do this in a more automated fashion you can look at the various configuration management communities such as &lt;a href=&#34;https://supermarket.chef.io/cookbooks/docker_registry&#34;&gt;chef&lt;/a&gt; for examples.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Securing Docker with TLS certificates</title>
      <link>http://tech.paulcz.net/2016/01/secure-docker-with-tls/</link>
      <pubDate>Sun, 03 Jan 2016 14:44:30 -0600</pubDate>
      
      <guid>http://tech.paulcz.net/2016/01/secure-docker-with-tls/</guid>
      <description>

&lt;p&gt;By default Docker (and by extension Docker Swarm) has no authentication or authorization on its API, relying instead on the filesystem security of its unix socket &lt;code&gt;/var/run/docker.sock&lt;/code&gt; which by default is only accessible by the root user.&lt;/p&gt;

&lt;p&gt;This is fine for the basic use case of the default behavior of only accessing the Docker API on the local machine via the socket as the root user. However if you wish to use the Docker API over TCP then you&amp;rsquo;ll want to secure it so that you don&amp;rsquo;t give out root access to anyone that happens to poke you on the TCP port.&lt;/p&gt;

&lt;p&gt;Docker supports using TLS certificates (both on the server and the client) to provide proof of identity. When set up correctly it will only allow clients/servers with a certificate signed by a specific CA to talk to eachother. While not providing fine grained access permissions it does at least allow us to listen on a TCP socket and restrict access with a bonus of also providing encryption.&lt;/p&gt;

&lt;p&gt;Here I will detail what is required to secure Docker (and in turn Docker Swarm) running on a &lt;a href=&#34;http://coreos.com/&#34;&gt;CoreOS&lt;/a&gt; server. I will assume you already have a &lt;a href=&#34;http://coreos.com/&#34;&gt;CoreOS&lt;/a&gt; server running as described in my Docker Swarm &lt;a href=&#34;http://tech.paulcz.net/2016/01/running-ha-docker-swarm/&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you are only interested in securing Docker itself and not Docker Swarm then this should apply to any server with Docker installed that uses systemd.  Even on systems without systemd it should provide enough details to secure Docker.&lt;/p&gt;

&lt;h2 id=&#34;creating-certificates&#34;&gt;Creating Certificates&lt;/h2&gt;

&lt;p&gt;I will offer two methods to create the certificates, the first by using &lt;code&gt;openssl&lt;/code&gt; to create a CA and then sign a key/cert pair, the second by using the &lt;a href=&#34;https://hub.docker.com/r/paulczar/omgwtfssl/&#34;&gt;paulczar/omgwtfssl&lt;/a&gt; Docker Image which automates the certificate creation process.&lt;/p&gt;

&lt;p&gt;Either way you&amp;rsquo;ll want to start off by creating directories for both the server and client certificate sets:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mkdir -p /etc/docker/ssl
$ mkdir -p ~/.docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;For this example we&amp;rsquo;re creating the keys and certificates on the server itself, ideally you would do this on your laptop or via configuration management and never store the CA key on a public server.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;openssl&#34;&gt;OpenSSL&lt;/h3&gt;

&lt;p&gt;First run &lt;code&gt;openssl&lt;/code&gt; to create and sign a CA key and certificate and copy the CA certificate into &lt;code&gt;/etc/docker/ssl&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openssl genrsa -out ~/.docker/ca-key.pem 2048
.+++
..........................................................................................................+++
e is 65537 (0x10001)

$ openssl req -x509 -new -nodes -key ~/.docker/ca-key.pem \
    -days 10000 -out ~/.docker/ca.pem -subj &#39;/CN=docker-CA&#39;

$ ls ~/.docker/
ca-key.pem  ca.pem

$ sudo cp ~/.docker/ca.pem /etc/docker/ssl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we&amp;rsquo;ll need an openssl configuration file for the Docker client &lt;code&gt;~/.docker/openssl.cnf&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[req]
req_extensions = v3_req
distinguished_name = req_distinguished_name
[req_distinguished_name]
[ v3_req ]
basicConstraints = CA:FALSE
keyUsage = nonRepudiation, digitalSignature, keyEncipherment
extendedKeyUsage = serverAuth, clientAuth
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Followed by a configuration file for the Docker server &lt;code&gt;/etc/docker/ssl/openssl.cnf&lt;/code&gt;.  Add any DNS or IPs that you might use to access the Docker Server with, this is critical as the Golang SSL libraries are very strict:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[req]
req_extensions = v3_req
distinguished_name = req_distinguished_name
[req_distinguished_name]
[ v3_req ]
basicConstraints = CA:FALSE
keyUsage = nonRepudiation, digitalSignature, keyEncipherment
extendedKeyUsage = serverAuth, clientAuth
subjectAltName = @alt_names

[alt_names]
DNS.1 = docker.local
IP.1 = 172.17.8.101
IP.2 = 127.0.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next create and sign a certificate for the client:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openssl genrsa -out ~/.docker/key.pem 2048
....................................+++
.............+++
e is 65537 (0x10001)

$ openssl req -new -key ~/.docker/key.pem -out ~/.docker/cert.csr \
    -subj &#39;/CN=docker-client&#39; -config ~/.docker/openssl.cnf

$ openssl x509 -req -in ~/.docker/cert.csr -CA ~/.docker/ca.pem \
    -CAkey ~/.docker/ca-key.pem -CAcreateserial \
    -out ~/.docker/cert.pem -days 365 -extensions v3_req \
    -extfile ~/.docker/openssl.cnf
Signature ok
subject=/CN=docker-client
Getting CA Private Key
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then do the same for the server:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo openssl genrsa -out /etc/docker/ssl/key.pem 2048
................................................................................+++
....................................+++
e is 65537 (0x10001)

$ sudo openssl req -new -key /etc/docker/ssl/key.pem \
    -out /etc/docker/ssl/cert.csr \
    -subj &#39;/CN=docker-server&#39; -config /etc/docker/ssl/openssl.cnf

$ sudo openssl x509 -req -in /etc/docker/ssl/cert.csr -CA ~/.docker/ca.pem \
    -CAkey ~/.docker/ca-key.pem -CAcreateserial \
    -out /etc/docker/ssl/cert.pem -days 365 -extensions v3_req \
    -extfile /etc/docker/ssl/openssl.cnf
Signature ok
subject=/CN=docker-client
Getting CA Private Key
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;omgwtfssl&#34;&gt;OMGWTFSSL&lt;/h3&gt;

&lt;p&gt;If you want to skip manually creating the certificates you can use the &lt;a href=&#34;https://hub.docker.com/r/paulczar/omgwtfssl/&#34;&gt;paulczar/omgwtfssl&lt;/a&gt; image which is a small (&amp;lt; 10mb) Docker image built specifically for creating certificates for situations like this.&lt;/p&gt;

&lt;p&gt;First we&amp;rsquo;ll create our client certs and use a docker volume binding to put the CA and certs into &lt;code&gt;~/.docker&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run --rm -v $(pwd)/.docker:/certs \
    paulczar/omgwtfssl
----------------------------
| OMGWTFSSL Cert Generator |
----------------------------

--&amp;gt; Certificate Authority
====&amp;gt; Using existing CA Key ca-key.pem
====&amp;gt; Using existing CA Certificate ca.pem
====&amp;gt; Generating new config file openssl.cnf
====&amp;gt; Generating new SSL KEY key.pem
Generating RSA private key, 2048 bit long modulus
.............+++
..........+++
e is 65537 (0x10001)
====&amp;gt; Generating new SSL CSR key.csr
====&amp;gt; Generating new SSL CERT cert.pem
Signature ok
subject=/CN=example.com
Getting CA Private Key
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we&amp;rsquo;ll take ownership of them back from root (because of the docker volume binding) and then create the server certificates using the same CA using a second volume binding to &lt;code&gt;/etc/docker/ssl&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Since this is a server certificate we need to pass the IP and DNS that the server may respond to via the -e command line arguments.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo cp ~/.docker/ca.pem /etc/docker/ssl/ca.pem
$ chown -R $USER ~/.docker
$ docker run --rm -v /etc/docker/ssl:/server \
    -v $(pwd)/.docker:/certs \
    -e SSL_IP=127.0.0.1,172.17.8.101 \
    -e SSL_DNS=docker.local -e SSL_KEY=/server/key.pem \
    -e SSL_CERT=/server/cert.pem paulczar/omgwtfssl
----------------------------
| OMGWTFSSL Cert Generator |
----------------------------

--&amp;gt; Certificate Authority
====&amp;gt; Using existing CA Key ca-key.pem
====&amp;gt; Using existing CA Certificate ca.pem
====&amp;gt; Generating new config file openssl.cnf
====&amp;gt; Generating new SSL KEY /server/key.pem
Generating RSA private key, 2048 bit long modulus
.................................+++
..................+++
e is 65537 (0x10001)
====&amp;gt; Generating new SSL CSR key.csr
====&amp;gt; Generating new SSL CERT /server/cert.pem
Signature ok
subject=/CN=example.com
Getting CA Private Key
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;using-the-tls-certificates-with-docker&#34;&gt;Using the TLS certificates with Docker&lt;/h2&gt;

&lt;p&gt;Now we have our TLS certificates created and in the correct locations you need to tell Docker to use the TLS certificate and also verify the client.  You do this by creating a drop in systemd unit to modify the existing Docker systemd unit.&lt;/p&gt;

&lt;p&gt;Create the file &lt;code&gt;custom.conf&lt;/code&gt; in &lt;code&gt;/etc/systemd/system/docker.service.d/&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;If you want to restrict local users from using the docker unix socket remove the second -H command line option, if you already have a custom drop in unit you can add the -H and &amp;ndash;tls* arguments to it.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Service]
Environment=&amp;quot;DOCKER_OPTS=-H=0.0.0.0:2376 -H unix:///var/run/docker.sock --tlsverify --tlscacert=/etc/docker/ssl/ca.pem --tlscert=/etc/docker/ssl/cert.pem --tlskey=/etc/docker/ssl/key.pem&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Reload systemd and the Docker service:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo systemctl daemon-reload
$ sudo systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now when you try to access Docker via the TCP port you should get a TLS error:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker -H tcp://127.0.0.1:2376 info
Get http://127.0.0.1:2376/v1.21/containers/json: malformed HTTP response &amp;quot;\x15\x03\x01\x00\x02\x02&amp;quot;.
* Are you trying to connect to a TLS-enabled daemon without TLS?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is because the Docker client does not know to use TLS to communicate with the server.  We can set some environment variables to enable TLS for the client and use the client key we created:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ export DOCKER_HOST=tcp://127.0.0.1:2376
$ export DOCKER_TLS_VERIFY=1
$ export DOCKER_CERT_PATH=~/.docker
$ docker info
docker info
Containers: 0
Images: 0
Server Version: 1.9.1
Storage Driver: overlay
 Backing Filesystem: extfs
Execution Driver: native-0.2
Logging Driver: json-file
Kernel Version: 4.3.3-coreos
Operating System: CoreOS 899.1.0
CPUs: 1
Total Memory: 997.4 MiB
Name: core-01
ID: RGVQ:VDUC:Z5LU:IE7I:J6UJ:TFBJ:SSCO:EWG2:QKAW:5FY6:EIAV:MROK
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;using-the-tls-certificates-with-docker-swarm&#34;&gt;Using the TLS certificates with Docker Swarm&lt;/h2&gt;

&lt;p&gt;To secure Docker Swarm using these TLS certificates you will need to create TLS certificate/key pairs for each server using the same CA.&lt;/p&gt;

&lt;p&gt;to add some arguments to the &lt;code&gt;docker run&lt;/code&gt; command that you start Swarm Manager with the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d --name swarm-manager \
    -v /etc/docker/ssl:/etc/docker/ssl \
    --net=host swarm:latest manage \
    --tlsverify \
    --tlscacert=/etc/docker/ssl/ca.pem \
    --tlscert=/etc/docker/ssl/cert.pem \
    --tlskey=/etc/docker/ssl/key.pem \
    etcd://127.0.0.1:2379
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which you can then access using the docker client:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ export DOCKER_HOST=tcp://127.0.0.1:2375
$ export DOCKER_TLS_VERIFY=1
$ export DOCKER_CERT_PATH=~/.docker

$ docker info
Containers: 6
Images: 5
Role: primary
Strategy: spread
Filters: health, port, dependency, affinity, constraint
Nodes: 3
 core-01: 172.17.8.101:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.023 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.3.3-coreos, operatingsystem=CoreOS 899.1.0, storagedriver=overlay
 core-02: 172.17.8.102:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.023 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.3.3-coreos, operatingsystem=CoreOS 899.1.0, storagedriver=overlay
 core-03: 172.17.8.103:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.023 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.3.3-coreos, operatingsystem=CoreOS 899.1.0, storagedriver=overlay
CPUs: 3
Total Memory: 3.068 GiB
Name: core-01
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Deploying a HA Docker Swarm Cluster</title>
      <link>http://tech.paulcz.net/2016/01/running-ha-docker-swarm/</link>
      <pubDate>Sat, 02 Jan 2016 14:44:30 -0600</pubDate>
      
      <guid>http://tech.paulcz.net/2016/01/running-ha-docker-swarm/</guid>
      <description>

&lt;p&gt;Given Docker&amp;rsquo;s propensity for creating easy to use tools it shouldn&amp;rsquo;t come as a surprise that Docker Swarm is one of the easier to understand and run of the &amp;ldquo;Docker Clustering&amp;rdquo; options currently out there. I recently built some &lt;a href=&#34;http://terraform.io&#34;&gt;Terraform&lt;/a&gt; configs for deploying a &lt;a href=&#34;https://github.com/openstack/osops-tools-contrib/tree/master/terraform/dockerswarm-coreos&#34;&gt;Highly Available Docker Swarm cluster on Openstack&lt;/a&gt; and learned a fair bit about Swarm in the process.&lt;/p&gt;

&lt;p&gt;This guide is meant to be a platform agnostic howto on installing and running a Highly Available Docker Swarm to show you the ideas and concepts that may not be as easy to understand from just reading some config management code.&lt;/p&gt;

&lt;h2 id=&#34;coreos&#34;&gt;CoreOS&lt;/h2&gt;

&lt;p&gt;The reason for using &lt;a href=&#34;http://coreos.com&#34;&gt;CoreOS&lt;/a&gt; here is that to make Swarm run in High Availability mode as well as being able to support docker networking between hosts we need to use service discovery.  We can choose to use &lt;code&gt;etcd&lt;/code&gt;, &lt;code&gt;consul&lt;/code&gt;, or &lt;code&gt;zookeeper&lt;/code&gt; here, CoreOS comes with &lt;code&gt;etcd&lt;/code&gt; thus makes it an excellent choice for running Docker Swarm.&lt;/p&gt;

&lt;p&gt;You will need three servers capable of running &lt;a href=&#34;http://coreos.com&#34;&gt;CoreOS&lt;/a&gt;.  See the &amp;ldquo;Try Out CoreOS&amp;rdquo; section of their website for various installation methods for different infrastructure. For this guide I will use the official &lt;a href=&#34;https://github.com/coreos/coreos-vagrant&#34;&gt;CoreOS Vagrant Example&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;skip the rest of this section if you install CoreOS for a different platform&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Clone down the Vagrant example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/coreos/coreos-vagrant.git vagrant-docker-swarm 
Cloning into &#39;vagrant-docker-swarm&#39;...
remote: Counting objects: 411, done.
remote: Total 411 (delta 0), reused 0 (delta 0), pack-reused 411
Receiving objects: 100% (411/411), 100.33 KiB | 0 bytes/s, done.
Resolving deltas: 100% (181/181), done.
Checking connectivity... done.
cd vagrant-docker-swarm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Edit the &lt;code&gt;Vagrantfile&lt;/code&gt; to set &lt;code&gt;$num_instances = 3&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;on Unix-like systems you can do this easily with sed&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sed -i &#39;s/\$num_instances = 1/\$num_instances = 3/&#39; Vagrantfile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Get a new etcd discovery-url:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;if you are on a windows box and don&amp;rsquo;t have curl you can paste the url into a web browser to get the discovery-url&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl https://discovery.etcd.io/new\?size\=3
https://discovery.etcd.io/6a9c62105f04dac40a29b90fbed322ef
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create a cloud-init file called &lt;code&gt;user-data&lt;/code&gt; in the base of the repo using the discovery-url from above:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#cloud-config

coreos:
  etcd2:
    discovery: https://discovery.etcd.io/888fd1e440faf680a7abb3fd934da6fd
    advertise-client-urls: http://$public_ipv4:2379
    initial-advertise-peer-urls: http://$public_ipv4:2380
    listen-client-urls: http://0.0.0.0:2379,http://0.0.0.0:4001
    listen-peer-urls: http://$public_ipv4:2380,http://$public_ipv4:7001
  units:
    - name: etcd2.service
      command: start

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Start up the CoreOS VMs and log into the first one to check everything worked ok:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vagrant up
Bringing machine &#39;core-01&#39; up with &#39;virtualbox&#39; provider...
Bringing machine &#39;core-02&#39; up with &#39;virtualbox&#39; provider...
Bringing machine &#39;core-03&#39; up with &#39;virtualbox&#39; provider...
...
$ vagrant ssh core-01
$ etcdctl member list
3c5901a3db54efa3: name=f1bae7bba7714ed7b4585c6b1256ddb2 peerURLs=http://172.17.8.101:2380 clientURLs=http://172.17.8.101:2379
9eeb141350af8439: name=5c8e57890d114d7d9d7aef662033a6e0 peerURLs=http://172.17.8.103:2380 clientURLs=http://172.17.8.103:2379
ebcc652087dfe6e8: name=de426249d3b34e23a5706d99b4900665 peerURLs=http://172.17.8.102:2380 clientURLs=http://172.17.8.102:2379
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;docker-swarm&#34;&gt;Docker Swarm&lt;/h2&gt;

&lt;p&gt;Now that we have several CoreOS servers with a working etcd cluster we can move on to setting up Docker Swarm.&lt;/p&gt;

&lt;p&gt;We need to modify docker to listen on tcp port &lt;code&gt;2376&lt;/code&gt; as well as registering itself to service discovery (which will allow us to set up overlay networking later on).  We do this by creating a file &lt;code&gt;custom.conf&lt;/code&gt; in &lt;code&gt;/etc/systemd/system/docker.service.d/&lt;/code&gt; on each server.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;if not using vagrant change &lt;code&gt;eth1&lt;/code&gt; to match the primary interface for your server&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Service]
Environment=&amp;quot;DOCKER_OPTS=-H=0.0.0.0:2376 -H unix:///var/run/docker.sock --cluster-advertise eth1:2376 --cluster-store etcd://127.0.0.1:2379&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We then need to reload the &lt;code&gt;systemctl&lt;/code&gt; daemon and then restart docker for these changes to take effect.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo systemctl daemon-reload
sudo systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Check that you can access docker via tcp on one of your hosts:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker -H tcp://172.17.8.101:2376 info
Containers: 0
Images: 0
Engine Version: 1.9.1
Storage Driver: overlay
 Backing Filesystem: extfs
Execution Driver: native-0.2
Logging Driver: json-file
Kernel Version: 4.3.3-coreos
Operating System: CoreOS 899.1.0
CPUs: 1
Total Memory: 997.4 MiB
Name: core-01
ID: BK64:WF3J:5JU6:VYLI:YJSO:CAQH:HPYM:MPTG:FMTA:VLE3:HSMP:F4VQ
Cluster store: etcd://127.0.0.1:2379/docker

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;re now ready to run Docker Swarm itself. There are two extra components to running Docker Swarm, a Swarm Agent and a Swarm Manager.&lt;/p&gt;

&lt;p&gt;The Swarm Agent watches the local Docker service via it&amp;rsquo;s TCP port and registers it into service discovery (etcd in our case).  We will run this on each server like so:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;set the &amp;ndash;addr= argument to match the primary IP of each node&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d --name swarm-agent \
    --net=host swarm:latest \
        join --addr=172.17.8.101:2376 \
        etcd://127.0.0.1:2379
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The Swarm Manager watches service discovery and exposes a TCP port (2375) which when accessed by a Docker client will perform actions and schedule containers across the Swarm cluster.&lt;/p&gt;

&lt;p&gt;To ensure High Availability of our cluster we&amp;rsquo;ll run a Swarm Manager on each server:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d --name swarm-manager 
    --net=host swarm:latest manage \
    etcd://127.0.0.1:2379
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assuming everything went smoothly we can now access the swarm cluster via the Swarm Managers TCP port on any of the servers:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker -H tcp://172.17.8.101:2375 info
Containers: 6
Images: 5
Role: primary
Strategy: spread
Filters: health, port, dependency, affinity, constraint
Nodes: 3
 core-01: 172.17.8.101:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.023 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.3.3-coreos, operatingsystem=CoreOS 899.1.0, storagedriver=overlay
 core-02: 172.17.8.102:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.023 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.3.3-coreos, operatingsystem=CoreOS 899.1.0, storagedriver=overlay
 core-03: 172.17.8.103:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.023 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.3.3-coreos, operatingsystem=CoreOS 899.1.0, storagedriver=overlay
CPUs: 3
Total Memory: 3.068 GiB
Name: core-01
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our next step is to create an overlay network using the &lt;code&gt;docker network&lt;/code&gt; command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker -H tcp://172.17.8.101:2375 network create --driver overlay my-net
614913b275dee43a63b48d08b4f5e52f7c0e531d70c63eeb8bb35624470da0c4

$ docker -H tcp://172.17.8.101:2375 network ls                            
NETWORK ID          NAME                DRIVER
86ecb0cf32c6        core-02/none        null                
c7a291ed8366        core-01/host        host                
3747364c5961        core-03/none        null                
8245d6d3ac67        core-02/host        host                
614913b275de        my-net              overlay             
61ead145e9dd        core-01/bridge      bridge              
c9457c4f4588        core-03/bridge      bridge              
b8a6c75cb3b9        core-03/host        host                
bdc4d5ccd778        core-02/bridge      bridge              
66afdc892361        core-01/none        null
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally we&amp;rsquo;ll create a Container on one host and then check that it is accessible from another:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;replace the node==XXXX argument with the hostname of one of your hosts, make sure to use a different node for each docker command&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -it --name=web --net=my-net \
    -H tcp://172.17.8.101:2375 \
    --env=&amp;quot;constraint:node==core-01&amp;quot; nginx
e0fe18c946a5692806608f939d4d6f31c670e3f42bf3942a77142bed2095983e

$ docker run -it --rm --net=my-net \
    -H tcp://172.17.8.101:2375 \
    --env=&amp;quot;constraint:node==core02&amp;quot; busybox wget -O- http://web
Connecting to web (10.0.0.2:80)
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you&amp;rsquo;ve been following along you have successfully deployed a Highly Available Docker Swarm cluster.  From here you could use a load balancer to load balance the Swarm Manager port (2375) or even use Round Robin DNS.&lt;/p&gt;

&lt;p&gt;You may have notice there is no authentication or authorization on this and anybody with a Docker binary and TCP access to your hosts could spin up docker containers. This is fairly easily fixed by using Docker&amp;rsquo;s TLS cert based authorization.&lt;/p&gt;

&lt;p&gt;To read how to secure both Docker and Docker Swarm with TLS read the followup post &lt;a href=&#34;http://tech.paulcz.net/2016/01/secure-docker-with-tls/&#34;&gt;Secure Docker with TLS&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Openstacks and Ecosystems</title>
      <link>http://tech.paulcz.net/2016/01/openstacks-and-ecosystems/</link>
      <pubDate>Sat, 02 Jan 2016 13:00:42 -0600</pubDate>
      
      <guid>http://tech.paulcz.net/2016/01/openstacks-and-ecosystems/</guid>
      <description>&lt;p&gt;I have recently had a number of lengthy discussions on the &lt;a href=&#34;https://twitter.com/zehicle/status/678736665792356352&#34;&gt;Twitter&lt;/a&gt; about Interop, Users, and Ecosystems. Specifically about our need to focus on the OpenStack ecosystem to extend the OpenStack IaaS user experience to something a bit more platform[ish].&lt;/p&gt;

&lt;p&gt;I wrote a post for &lt;a href=&#34;http://sysadvent.blogspot.com/2015/12/day-16-merry-paasmas-and-very.html&#34;&gt;SysAdvent&lt;/a&gt; this year on developing applications on top of OpenStack using a collection of OpenSource tools to create a PaaS and CI/CD pipelines. I think it turned out quite well and really helped reinforce my beliefs on the subject.&lt;/p&gt;

&lt;p&gt;My buddy and future OpenStack Board member &lt;a href=&#34;https://twitter.com/jjasghar&#34;&gt;JJ Asghar&lt;/a&gt; has been spearheading a new &lt;a href=&#34;https://wiki.openstack.org/wiki/Osops&#34;&gt;OpenStack Operators Project&lt;/a&gt;. I plan to contribute to this project by creating some examples of deploying tools that provide higher level services on top of the OpenStack IaaS layer.&lt;/p&gt;

&lt;p&gt;Given that I am very bullish about the &lt;a href=&#34;http://docker.com&#34;&gt;Docker&lt;/a&gt; ecosystem it makes sense that my first contribution would be focussed on running one of the several &amp;ldquo;Docker container scheduling/cluster&amp;rdquo; tools.&lt;/p&gt;

&lt;p&gt;After playing around with a few of them, I settled on starting with Docker Swarm as its one of the easier to understand and run and doesn&amp;rsquo;t require any special tooling other than a recent install of the Docker binary to use.&lt;/p&gt;

&lt;p&gt;To increase simplicity I chose to use Hashicorp&amp;rsquo;s &lt;a href=&#34;http://terraform.io&#34;&gt;Terraform&lt;/a&gt; and use only the most basic of the OpenStack services to ensure a fairly high likelyhood that it will run on most fairly up to date OpenStack clouds.&lt;/p&gt;

&lt;p&gt;Based on the project&amp;rsquo;s suggestion I posted the Terraform files up to the &lt;a href=&#34;https://github.com/openstack/osops-tools-contrib/tree/master/terraform/dockerswarm-coreos&#34;&gt;osops-tools-contrib&lt;/a&gt; along with fairly comprehensive documentation on using it.&lt;/p&gt;

&lt;p&gt;I hope this and future work I plan to do to create similar examples will help the OpenStack Community out in some small way.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Optimizing your Dockerfiles</title>
      <link>http://tech.paulcz.net/blog/Optimizing%20your%20Dockerfiles/</link>
      <pubDate>Sat, 07 Mar 2015 13:25:29 -0600</pubDate>
      
      <guid>http://tech.paulcz.net/blog/Optimizing%20your%20Dockerfiles/</guid>
      <description>

&lt;p&gt;Docker images are &amp;ldquo;supposed&amp;rdquo; to be small and fast. However unless you&amp;rsquo;re precompiling GO binaries and dropping them in the &lt;code&gt;busybox&lt;/code&gt; image they can get quite large and complicated. Without a well constructed &lt;code&gt;Dockerfile&lt;/code&gt; to improve build cache hits your docker builds can become unnecessarily slow.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Dockerfile&lt;/code&gt;&amp;rsquo;s are regularly [and incorrectly] treated like &lt;code&gt;bash&lt;/code&gt; scripts and therefore are often written out as a series of commands which you would &lt;code&gt;curl | sudo bash&lt;/code&gt; from a website to install.  This usually makes for an inefficient and slow &lt;code&gt;Dockerfile&lt;/code&gt;&lt;/p&gt;

&lt;!--more --&gt;

&lt;h2 id=&#34;order-matters&#34;&gt;Order Matters&lt;/h2&gt;

&lt;p&gt;When you&amp;rsquo;re building a new &lt;code&gt;Dockerfile&lt;/code&gt; for an application there can be a lot of trial and error in determining what packages are needed and what commands need to run. Optimizing your &lt;code&gt;Dockerfile&lt;/code&gt; ensures that the build cache will hit more often and each build between changes will be faster.&lt;/p&gt;

&lt;p&gt;The general rule of thumb is to sort your commands by frequency of change, the time it takes to run the command and how sharable it is with other images.&lt;/p&gt;

&lt;p&gt;This means that commands like &lt;code&gt;WORKDIR&lt;/code&gt;, &lt;code&gt;CMD&lt;/code&gt;, &lt;code&gt;ENV&lt;/code&gt; should go towards the bottom while a &lt;code&gt;RUN apt-get -y update&lt;/code&gt; should go towards the top as it takes longer to run and can be shared with all of your images.&lt;/p&gt;

&lt;p&gt;Finally any &lt;code&gt;ADD&lt;/code&gt; ( or other commands that invalidate cache ) commands should go as far down the bottom as possible as this is where you&amp;rsquo;re likely to make lots of changes that will invalidate the cache of subsequent commands.&lt;/p&gt;

&lt;h2 id=&#34;choose-your-base-image-wisely&#34;&gt;Choose your base image wisely&lt;/h2&gt;

&lt;p&gt;There&amp;rsquo;s a lot of base images to choose from from the bare OS images like &lt;code&gt;ubuntu:trusty&lt;/code&gt; to application specific ones for &lt;code&gt;python:2&lt;/code&gt; or &lt;code&gt;java:7&lt;/code&gt;.  Common sense might tell you to use &lt;code&gt;ruby:2&lt;/code&gt; to run an ruby based app and &lt;code&gt;python:3&lt;/code&gt; to run a python app.  However now you have two base images with little in common that you need to download and build.  Instead if you use &lt;code&gt;ubuntu:trusty&lt;/code&gt; for both then you only need to download the base image once.&lt;/p&gt;

&lt;h2 id=&#34;use-layers-to-your-advantage&#34;&gt;Use Layers to your advantage&lt;/h2&gt;

&lt;p&gt;Each command in a &lt;code&gt;Dockerfile&lt;/code&gt; is an extra layer. You can very quickly end up with an image that&amp;rsquo;s 30+ layers.  This is not necessarily a problem, but by joining &lt;code&gt;RUN&lt;/code&gt; commands together, and using a single &lt;code&gt;EXPOSE&lt;/code&gt; line to list all of your open ports you can reduce the number of layers.&lt;/p&gt;

&lt;p&gt;By grouping &lt;code&gt;RUN&lt;/code&gt; commands together intelligently you can share more layers between containers.  Of course if you have a common set of packages across multiple containers then you should look at creating a seperate base image containing these that all of your images are built from.&lt;/p&gt;

&lt;p&gt;For each layer that you can share across multiple images you can save a ton of disk space.&lt;/p&gt;

&lt;h2 id=&#34;volume-contaimers&#34;&gt;Volume contaimers&lt;/h2&gt;

&lt;p&gt;If you use Volume containers,  don&amp;rsquo;t bother trying to save space by using a small image,  Use the image of the application you&amp;rsquo;ll be serving data to.  If you do that and &lt;code&gt;docker commit&lt;/code&gt; the data volume you not only have your data commited to the container, but the actual application as well which is very useful for debugging.&lt;/p&gt;

&lt;h2 id=&#34;cheat&#34;&gt;Cheat&lt;/h2&gt;

&lt;p&gt;If you&amp;rsquo;ve built an image and discover when you run it that there&amp;rsquo;s a package missing add it to the bottom of your &lt;code&gt;Dockerfile&lt;/code&gt; rather than in the &lt;code&gt;RUN apt-get&lt;/code&gt; command at the top.  This means you can rebuild the image faster.  Once your image is correct and working you can reorganize your &lt;code&gt;Dockerfile&lt;/code&gt; to clean such changes up before commiting it to source control.&lt;/p&gt;

&lt;h2 id=&#34;example&#34;&gt;Example&lt;/h2&gt;

&lt;p&gt;A &lt;code&gt;Dockerfile&lt;/code&gt; for installing graphite would look something like this if it was written like a &lt;code&gt;bash&lt;/code&gt; script:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM ubuntu:trusty
MAINTAINER Paul Czarkowski &amp;quot;paul@paulcz.net&amp;quot;

RUN apt-get -yq update

# Apache
RUN \
  apt-get -yqq install \
    apache2 \
    apache2-utils \
    libapache2-mod-python \
    python-dev \
    python-pip \
    python-cairo \
    python-pysqlite2 \
    python-mysqldb \
    python-jinja2
    sqlite3 \
    curl \ 
    wget \
    git \
    software-properties-common

RUN \
  curl -sSL https://bootstrap.pypa.io/get-pip.py | python &amp;amp;&amp;amp; \
    pip install whisper \
    carbon \
    graphite-web \
    &#39;Twisted&amp;lt;12.0&#39; \
    &#39;django&amp;lt;1.6&#39; \
    django-tagging

# Add start scripts etc
ADD . /app

RUN mkdir -p /app/wsgi
RUN useradd -d /app -c &#39;application&#39; -s &#39;/bin/false&#39; graphite
RUN chmod +x /app/bin/*
RUN chown -R graphite:graphite /app
RUN chown -R graphite:graphite /opt/graphite
RUN rm -f /etc/apache2/sites-enabled/*

ADD ./apache-graphite.conf /etc/apache2/sites-enabled/apache-graphite.conf

# Expose ports.
EXPOSE 80 
EXPOSE 2003 
EXPOSE 2004 
EXPOSE 7002

ENV APACHE_CONFDIR /etc/apache2
ENV APACHE_ENVVARS $APACHE_CONFDIR/envvars
ENV APACHE_RUN_USER www-data
ENV APACHE_RUN_GROUP www-data
ENV APACHE_RUN_DIR /var/run/apache2
ENV APACHE_PID_FILE $APACHE_RUN_DIR/apache2.pid
ENV APACHE_LOCK_DIR /var/lock/apache2
ENV APACHE_LOG_DIR /var/log/apache2

WORKDIR /app

# Define default command.
CMD [&amp;quot;/app/bin/start_graphite&amp;quot;]

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However an optmized version of this same Dockerfile based on what was discussed earlier would look like the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 1 - Common Header / Packages
FROM ubuntu:trusty
MAINTAINER Paul Czarkowski &amp;quot;paul@paulcz.net&amp;quot;

RUN apt-get -yq update \
  &amp;amp;&amp;amp; apt-get -yqq install \
    wget \
    curl \
    git \
    software-properties-common

# 2 - Python
RUN \
  apt-get -yqq install \
    python-dev \
    python-pip \
    python-pysqlite2 \
    python-mysqldb

# 3 - Apache
RUN \
  apt-get -yqq install \
    apache2 \
    apache2-utils

# 4 - Apache ENVs
ENV APACHE_CONFDIR /etc/apache2
ENV APACHE_ENVVARS $APACHE_CONFDIR/envvars
ENV APACHE_RUN_USER www-data
ENV APACHE_RUN_GROUP www-data
ENV APACHE_RUN_DIR /var/run/apache2
ENV APACHE_PID_FILE $APACHE_RUN_DIR/apache2.pid
ENV APACHE_LOCK_DIR /var/lock/apache2
ENV APACHE_LOG_DIR /var/log/apache2

# 5 - Graphite and Deps
RUN \
  apt-get -yqq install \
    libapache2-mod-python \
    python-cairo \
    python-jinja2 \
    sqlite3

RUN \
    pip install whisper \
    carbon \
    graphite-web \
    &#39;Twisted&amp;lt;12.0&#39; \
    &#39;django&amp;lt;1.6&#39; \
    django-tagging

# 6 - Other
EXPOSE 80 2003 2004 7002

WORKDIR /app

VOLUME /opt/graphite/data

# Define default command.
CMD [&amp;quot;/app/bin/start_graphite&amp;quot;]

# 7 - First use of ADD
ADD . /app

# 8 - Final setup
RUN mkdir -p /app/wsgi \
  &amp;amp;&amp;amp; useradd -d /app -c &#39;application&#39; -s &#39;/bin/false&#39; graphite \
  &amp;amp;&amp;amp; chmod +x /app/bin/* \
  &amp;amp;&amp;amp; chown -R graphite:graphite /app \
  &amp;amp;&amp;amp; chown -R graphite:graphite /opt/graphite \
  &amp;amp;&amp;amp; rm -f /etc/apache2/sites-enabled/* \
  &amp;amp;&amp;amp; mv /app/apache-graphite.conf /etc/apache2/sites-enabled/apache-graphite.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;1-common-header-packages&#34;&gt;1 - Common Header / Packages&lt;/h3&gt;

&lt;p&gt;This is our most shareable layer.  All the images running on the same host should start with this.  You can see I&amp;rsquo;ve added a few things like &lt;code&gt;curl&lt;/code&gt; and &lt;code&gt;git&lt;/code&gt; which while they&amp;rsquo;re not necessarily needed they&amp;rsquo;re useful for debugging and because they&amp;rsquo;re in such a shareable layer,  they don&amp;rsquo;t take up much room.&lt;/p&gt;

&lt;h3 id=&#34;2-python-3-apache&#34;&gt;2 - Python, 3 - Apache&lt;/h3&gt;

&lt;p&gt;Here we get to our language specifications.   I&amp;rsquo;ve included the Python and Apache sections here because it&amp;rsquo;s not super clear which should go first.&lt;/p&gt;

&lt;p&gt;If we put python first,  then any other image that uses Apache can get a few free python packages,  If we put Apache first then we could have a Ruby app that also includes that layer and get Apache for free ( hell you can just give it python for free anyways ).&lt;/p&gt;

&lt;h3 id=&#34;4-apache-envs&#34;&gt;4 - Apache Envs&lt;/h3&gt;

&lt;p&gt;I&amp;rsquo;m calling these out seperately for a few reasons.&lt;/p&gt;

&lt;p&gt;Firstly, they should come either directly directly after the Apache section so that it&amp;rsquo;s easier to make them common ( and cached ) between multiple images.   You might not think it matters since calls like &lt;code&gt;ENV&lt;/code&gt; are so cheap, but I have seen random &lt;code&gt;ENV&lt;/code&gt; calls take 10 seconds or so.  If you have a lot, then its good to keep them cached, but you also don&amp;rsquo;t want a changed &lt;code&gt;ENV&lt;/code&gt; to invalidated the cache of installing Apache.&lt;/p&gt;

&lt;p&gt;They&amp;rsquo;re a pretty good example of something you might want to start with at the bottom of your container and move them up higher once you&amp;rsquo;re unlikely to change them again.&lt;/p&gt;

&lt;p&gt;Secondly, to mention that I really wish Docker provided a way to specify multiple ENVS on the same line so that I can reduce the number of layers I end up with.&lt;/p&gt;

&lt;h3 id=&#34;5-graphite-and-deps&#34;&gt;5 - Graphite and Deps&lt;/h3&gt;

&lt;p&gt;This contains some Graphite specific &lt;code&gt;apt&lt;/code&gt; and &lt;code&gt;pip&lt;/code&gt; packages.  You could join them into a single command by joining them with &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; but I kept them seperate so that if &lt;code&gt;pip&lt;/code&gt; package requirements change it won&amp;rsquo;t need to also reget the &lt;code&gt;apt&lt;/code&gt; packages.&lt;/p&gt;

&lt;h3 id=&#34;6-other&#34;&gt;6 - Other&lt;/h3&gt;

&lt;p&gt;This contains a bunch of cheap commands like &lt;code&gt;ADD&lt;/code&gt; and &lt;code&gt;VOLUME&lt;/code&gt; they&amp;rsquo;re probably less likely to change than the previous package installs, but are also cheaper to run, so its less important if their cache is invalidated.&lt;/p&gt;

&lt;p&gt;Keep them towards the bottom though as you don&amp;rsquo;t want any changes to them to invalidate the cache for a more costly command.&lt;/p&gt;

&lt;h3 id=&#34;7-first-add&#34;&gt;7 - First ADD&lt;/h3&gt;

&lt;p&gt;You should wait until the last possible moment to use the &lt;code&gt;ADD&lt;/code&gt; command as any commands after it are never cached.&lt;/p&gt;

&lt;h3 id=&#34;8-final-setup&#34;&gt;8 - Final setup&lt;/h3&gt;

&lt;p&gt;I have grouped these final commands into a single layer and they&amp;rsquo;re after the &lt;code&gt;ADD&lt;/code&gt; commands as they manipulate files that come from the &lt;code&gt;ADD&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;fin&#34;&gt;FIN.&lt;/h2&gt;

&lt;p&gt;Hopefully this has given you some insight into how to build a better &lt;code&gt;Dockerfile&lt;/code&gt;.  These are all things I have learned from experience in building my own Docker images and while they may not apply to all situations ( or may be flat out wrong ) they defintely seem to improve my development experience.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Factorish and The Twelve-Fakter App</title>
      <link>http://tech.paulcz.net/blog/factorish_and_the_12_fakter_app/</link>
      <pubDate>Tue, 06 Jan 2015 13:29:27 -0600</pubDate>
      
      <guid>http://tech.paulcz.net/blog/factorish_and_the_12_fakter_app/</guid>
      <description>&lt;p&gt;Unless you&amp;rsquo;ve been living under a rock (in which case I envy you) you&amp;rsquo;ve heard a fair bit about The &lt;a href=&#34;http://12factor.net&#34;&gt;Twelve-Factor App&lt;/a&gt;. A wonderful stateless application that is completely disposable and can run anywhere from your own physical servers to &lt;a href=&#34;http://deis.io&#34;&gt;Deis&lt;/a&gt;, &lt;a href=&#34;http://cloudfoundry.org&#34;&gt;Cloud Foundry&lt;/a&gt; or &lt;a href=&#34;http://heroku.com&#34;&gt;Heroku&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Chances are you&amp;rsquo;re stuck writing and running an application that is decidely not 12Factor, nor will it ever be.  In a perfect world you&amp;rsquo;d scrap it and rewrite it as a dozen microservices that are loosely coupled but run and work indepently of eachother. The reality however is you could never get the okay to do that.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Fortunately with the rise of &lt;a href=&#34;http://docker.com&#34;&gt;Docker&lt;/a&gt; and its ecosystem it has become easier to not only write 12Factor apps, but also to fake it by producing a Docker container that acts like a 12Factor app, but contains something that is decidedly not.  I call this the 12Fakter app.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve been playing with this concept for a while, but over Christmas I spent a bunch of time trying to figure out the best ways to fake out the 12 Factors and feel that I&amp;rsquo;ve come up with something that works pretty well and in the process created a Vagrant based development sandbox called &lt;a href=&#34;http://github.com/paulczar/factorish&#34;&gt;Factorish&lt;/a&gt; which I used to create &lt;a href=&#34;http://github.com/paulczar/12fakter-wordpress&#34;&gt;12fakter-wordpress&lt;/a&gt; and &lt;a href=&#34;https://github.com/paulczar/docker-elk_confd&#34;&gt;elk_confd&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;fakter-i-codebase&#34;&gt;Fakter I. Codebase&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;One codebase tracked in revision control, many deploys&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The goal here is to have both your app and deployment tooling in the same codebase which is stored in source control.  This means adding a &lt;code&gt;Dockerfile&lt;/code&gt;, and &lt;code&gt;Vagrantfile&lt;/code&gt; and other pieces of tooling into your codebase.  If however you have a monolithic codebase that contains more than just your app you can create a seperate codebase ( use git! ) containing this tooling and have that tooling collect the application from its existing codebase.&lt;/p&gt;

&lt;p&gt;You should be able to achieve this by either merging &lt;a href=&#34;http://github.com/paulczar/factorish&#34;&gt;Factorish&lt;/a&gt; into your existing git repo,  or fork it and use the &lt;code&gt;Dockerfile&lt;/code&gt; in it to pull the actual application code in as part of the build process.&lt;/p&gt;

&lt;h2 id=&#34;fakter-ii-dependencies&#34;&gt;Fakter II. Dependencies&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Explicitly declare and isolate dependencies&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is a really easy win with Docker,  The very nature of Docker both Explicitly declares your dependencies in the form of the &lt;code&gt;Dockerfile&lt;/code&gt; and Isolates them in the form of the built Docker image.&lt;/p&gt;

&lt;h3 id=&#34;declaration&#34;&gt;Declaration&lt;/h3&gt;

&lt;h4 id=&#34;app-example-dockerfile&#34;&gt;/app/example/Dockerfile&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;FROM python:2

# Base deps layer
RUN \
  apt-get update &amp;amp;&amp;amp; apt-get install -yq \
  make \
  ca-certificates \
  net-tools \
  sudo \
  wget \
  vim \
  strace \
  lsof \
  netcat \
  lsb-release \
  locales \
  socat \
  supervisor \
  --no-install-recommends &amp;amp;&amp;amp; \
  locale-gen en_US.UTF-8

# etcdctl and confd layer
RUN \
  curl -sSL -o /usr/local/bin/etcdctl https://s3-us-west-2.amazonaws.com/opdemand/etcdctl-v0.4.6 \
  &amp;amp;&amp;amp; chmod +x /usr/local/bin/etcdctl \
  &amp;amp;&amp;amp; curl -sSL -o /usr/local/bin/confd https://github.com/kelseyhightower/confd/releases/download/v0.7.1/confd-0.7.1-linux-amd64 \
  &amp;amp;&amp;amp; chmod +x /usr/local/bin/confd

ADD . /app
WORKDIR /app

# app layer
RUN \
  useradd -d /app -c &#39;application&#39; -s &#39;/bin/false&#39; app &amp;amp;&amp;amp; \
  chmod +x /app/bin/* &amp;amp;&amp;amp; \
  pip install -r /app/example/requirements.txt

# Define default command.
CMD [&amp;quot;/app/bin/boot&amp;quot;]

# Expose ports.
EXPOSE 8080
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You might notice I have sets of commands joined together with &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; in my &lt;code&gt;Dockerfile&lt;/code&gt;, I do this to control the docker layers more to try and end up with fewer more meaningful layers.&lt;/p&gt;

&lt;h3 id=&#34;isolation&#34;&gt;Isolation&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker build -t factorish/example example
Sending build context to Docker daemon 20.99 kB
Sending build context to Docker daemon
Step 0 : FROM python:2
 ---&amp;gt; 96e13ecb4dba
...
...
Step 8 : EXPOSE 8080
 ---&amp;gt; Running in 8dc9a04eaf78
 ---&amp;gt; 374cb835239c
Removing intermediate container 8dc9a04eaf78
Successfully built 374cb835239c
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;fakter-iii-configuration&#34;&gt;Fakter III. Configuration&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Store config in the environment&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Another easy win with Docker.   You can pass in environment variables in the &lt;code&gt;Dockerfile&lt;/code&gt; as we as when running the docker container using the &lt;code&gt;-e&lt;/code&gt; option like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d -e TEXT=bacon factorish/example
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However chances are your app reads from a config file rather than environment variables. There are [at least] two fairly simple ways to achieve this.&lt;/p&gt;

&lt;h3 id=&#34;sed-inline-replacement&#34;&gt;sed inline replacement&lt;/h3&gt;

&lt;p&gt;use a startup script to edit your config file and replace values in it with the values of the environment variables using &lt;code&gt;sed&lt;/code&gt; before runnin your app:&lt;/p&gt;

&lt;h4 id=&#34;app-bin-boot&#34;&gt;/app/bin/boot&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/bash
sed -i &amp;quot;s/xxxTEXTxxx/${TEXT}&amp;quot; /app/example/example.conf
python /app/example/app.py
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;confd-templating&#34;&gt;confd templating&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kelseyhightower/confd&#34;&gt;confd&lt;/a&gt; is a tool written specifically for templating config files from data sources such as environment variables.  This is a much better option as it also opens up the ability to use service discovery tooling like &lt;a href=&#34;https://coreos.com/using-coreos/etcd/&#34;&gt;etcd&lt;/a&gt; (also supported in Factorish) rather than environment variables.&lt;/p&gt;

&lt;h4 id=&#34;app-conf-d-example-conf-toml&#34;&gt;/app/conf.d/example.conf.toml&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;[template]
src   = &amp;quot;example.conf&amp;quot;
dest  = &amp;quot;/app/example/example.conf&amp;quot;
keys = [&amp;quot;/services/example&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;app-templates-example-conf&#34;&gt;/app/templates/example.conf&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;[example]
text: {{ getv &amp;quot;/services/example/text&amp;quot; }}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;The &lt;code&gt;{{ }}&lt;/code&gt; syntax above is the golang/confd macros used to perform tasks like fetching variables from etcd or environment.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;app-bin-boot-1&#34;&gt;/app/bin/boot&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/bash
confd -onetime
python /app/example/app.py
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;fakter-iv-backing-services&#34;&gt;Fakter IV. Backing Services&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Treat backing services as attached resources&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Anything that is needed to store persistent data should be treated as an external dependency to your application.  As far as your app is concerned there should be no difference between a local MySQL server or Amazon&amp;rsquo;s RDS.&lt;/p&gt;

&lt;p&gt;This is easier for some backing services than others.  For example if your app requires a MySQL database its relatively straight forward.  Whereas a local filesystem for storing images is harder, but can be solved:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Docker: volume mounts, data containers&lt;/li&gt;
&lt;li&gt;Remote Storage: netapp, nfs, fuse-s3fs&lt;/li&gt;
&lt;li&gt;Clustered FS: drdb, gluster&lt;/li&gt;
&lt;li&gt;Ghetto: rsync + concerned&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The docker volume mounts actually work really well in a vagrant based development environment because you can pass your code all the way into the container from your workstation,  however there are definitely some security considerations to think about if you want to do volume mounts in production.&lt;/p&gt;

&lt;h3 id=&#34;example&#34;&gt;Example&lt;/h3&gt;

&lt;p&gt;A fictional &lt;strong&gt;PHP&lt;/strong&gt; based blog about bacon requires a database and a filestore:&lt;/p&gt;

&lt;h4 id=&#34;app-templates-config-php&#34;&gt;/app/templates/config.php&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;define(&#39;DB_NAME&#39;, &#39;{{ getv &amp;quot;/db/name&amp;quot; }}&#39;);
define(&#39;DB_USER&#39;, &#39;{{ getv &amp;quot;/db/user&amp;quot; }}&#39;);
define(&#39;DB_PASSWORD&#39;, &#39;{{ getv &amp;quot;/db/pass&amp;quot; }}&#39;);
define(&#39;DB_HOST&#39;, &#39;{{ getv &amp;quot;/db/host&amp;quot; }}&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;docker-run-command&#34;&gt;Docker Run command&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d -e DB_NAME=bacon -e DB_USER=bacon \
  -e DB_PASSWORD=bacon $DB_HOST=my.database.com \
  -v /mnt/nfs/bacon:/app/bacon factorish/bacon-blog
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;confd will use the environment variables passed in via the &lt;code&gt;docker run&lt;/code&gt; command to fill out the variables called in the &lt;code&gt;{{ }}&lt;/code&gt; macros.  Note that confd transforms the environment variables so that the environment variable &lt;code&gt;DB_USER&lt;/code&gt; will be read by &lt;code&gt;{{ getv &amp;quot;/db/user&amp;quot; }}&lt;/code&gt;.  This is done to normalize the macro across the various data source options.&lt;/p&gt;

&lt;h2 id=&#34;fakter-v-build-release-run&#34;&gt;Fakter V. Build, Release, Run&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Strictly separate build and run stages&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;build&#34;&gt;Build&lt;/h3&gt;

&lt;p&gt;Converts a code repo into an executable bundle. Sound familiar?  Yup, we&amp;rsquo;ve already solved this with our &lt;code&gt;Dockerfile&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;release&#34;&gt;Release&lt;/h3&gt;

&lt;p&gt;Takes the build and combines it with the current configuration. In a purely docker based system this can be split between the &lt;strong&gt;Build&lt;/strong&gt; (versioning and defaults) and &lt;strong&gt;Run&lt;/strong&gt; (current config) stages. However systems like Heroku and Deis have a seperate step for this which they handle internally.&lt;/p&gt;

&lt;h3 id=&#34;run&#34;&gt;Run&lt;/h3&gt;

&lt;p&gt;Runs the application by launching a set of the app&amp;rsquo;s processes against a selected release.  In a docker based system this is simply the &lt;code&gt;$ docker run&lt;/code&gt; command which can be called via a deploy script, or a init script (systemd/runit) or a scheduler like &lt;a href=&#34;https://coreos.com/using-coreos/clustering/&#34;&gt;fleet&lt;/a&gt; or &lt;a href=&#34;http://mesos.apache.org/&#34;&gt;mesos&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;fakter-vi-processes&#34;&gt;Fakter VI. Processes&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Execute the app as one or more stateless processes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Your application inside the docker container should behave like a standard linux process running in the foreground and be stateless and share-nothing.  Being inside a docker container means that this is hidden and therefore we can fairly easily fake this but you do need to think about process management and logging which are discussed later and is further explored &lt;a href=&#34;http://tech.paulcz.net/2014/12/multi-process-docker-images-done-right/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;fakter-vii-port-binding&#34;&gt;Fakter VII. Port binding&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Export services via port binding&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Your application should appear to be completely self contained and not require runtime injection of a webserver.  Thankfully this is pretty easy to fake in a docker container as any extra processes are isolated in the container and effectively invisible to the outside.&lt;/p&gt;

&lt;p&gt;It is still preferable to use a native language based web library such as jetty (java) or flask (python) but for languages like PHP using apache or nginx is ok.&lt;/p&gt;

&lt;p&gt;Docker itself takes care of the port binding by use of the &lt;code&gt;-p&lt;/code&gt; option on the command line.  It&amp;rsquo;s useful to register the port and host IP to somewhere ( etcd ) to allow for loadbalancers and other services to easily locate your application.&lt;/p&gt;

&lt;h2 id=&#34;fakter-viii-concurrency&#34;&gt;Fakter VIII. Concurrency&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Scale out via the process model&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We should be able to scale up or down simply by creating or destroying docker containers containing the application.  Any upstream load balancers as an external dependency would need to be notified of the container starting ( usually a fairly easy API call) and stopping.  But these are external dependencies and should be solved outside of your application itself.&lt;/p&gt;

&lt;p&gt;Inside the container your application should not daemonize or write pid files (if unavoidable, not too difficult to script around) and use tooling like &lt;code&gt;upstart&lt;/code&gt; or &lt;code&gt;supervisord&lt;/code&gt; if there is more than one process that needs to be run.&lt;/p&gt;

&lt;h2 id=&#34;fakter-ix-disposability&#34;&gt;Fakter IX. Disposability&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Maximize robustness with fast startup and graceful shutdown&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Docker helps a lot with this.   We want to ensure that we&amp;rsquo;re optimized for fast yet reliable startup as well as graceful shutdown.  Your app should be able to be shut down gracefully when &lt;code&gt;docker kill&lt;/code&gt; is called and just as importantly there should be minimal if any external effect if the application crashes or stops ungracefully.&lt;/p&gt;

&lt;p&gt;The container itself should kill itself if the app inside it stops working right.  If your app is running behind a &lt;a href=&#34;http://tech.paulcz.net/2014/12/multi-process-docker-images-done-right/&#34;&gt;supervisor&lt;/a&gt; this can be a achieved with a really lightweight healthcheck script like this.&lt;/p&gt;

&lt;h4 id=&#34;app-bin-healhthcheck&#34;&gt;/app/bin/healhthcheck&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/bash
while [[ ! -z $(netstat -lnt | awk &amp;quot;\$6 == \&amp;quot;LISTEN\&amp;quot; &amp;amp;&amp;amp; \$4 ~ \&amp;quot;.$PORT\&amp;quot; &amp;amp;&amp;amp; \$1 ~ \&amp;quot;tcp.?\&amp;quot;&amp;quot;) ]] ; do
  [[ -n $ETCD_HOST ]] &amp;amp;&amp;amp; etcdctl set /service/web/hosts/$HOST $PORT --ttl 10 &amp;gt;/dev/null
  sleep 5
done
kill `cat /var/run/supervisord.pid`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You&amp;rsquo;ll note that I&amp;rsquo;m also publishing host and port values to etcd if &lt;code&gt;$ETCD_HOST&lt;/code&gt; is set.  This can then be used to notify loadbalancers and the like when services start or stop.&lt;/p&gt;

&lt;h2 id=&#34;fakter-x-dev-prod-parity&#34;&gt;Fakter X. Dev/prod parity&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Keep development, staging, and production as similar as possible&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;By following the previous fackters we&amp;rsquo;ve done most of the work to make this possible.  We use Vagrant in development to deploy your app (and any backing services) using the appropriate provisioning methodology ( the same ones we&amp;rsquo;d use for production).&lt;/p&gt;

&lt;p&gt;By wrapping the application in a docker container it is portable across just about any system that is capable of running docker.&lt;/p&gt;

&lt;p&gt;By provisioning with the same tooling to both dev and prod (and any other envs),  any deployment of development (should happen frequently) is also a test of most of the tooling used to deploy to production.&lt;/p&gt;

&lt;h2 id=&#34;fakter-xi-logs&#34;&gt;Fakter XI. Logs&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Treat logs as event streams&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Your application ( even inside the container ) should always log to stdout. By writing to stdout of your process we can utilize the docker logging subsystem which when combined with tooling like &lt;a href=&#34;https://registry.hub.docker.com/u/progrium/logspout/&#34;&gt;logspout&lt;/a&gt; makes it very easy to push all logs to a central system.&lt;/p&gt;

&lt;p&gt;If your app &lt;em&gt;has&lt;/em&gt; to write to a logfile you should be able to configure that log file to be &lt;code&gt;/dev/stdout&lt;/code&gt; which should cause it to write to stdout of the process. If your app only writes to syslog then configure it to write to a remote syslog. Basically do whatever you can to ensure you don&amp;rsquo;t log to the local filesystem.&lt;/p&gt;

&lt;h3 id=&#34;example-1&#34;&gt;Example&lt;/h3&gt;

&lt;p&gt;This example shows running &lt;code&gt;Supervisord&lt;/code&gt; as your primary process in the docker container and &lt;code&gt;nginx&lt;/code&gt; writing logs to stdout which in turn are written to the containers &lt;code&gt;stdout&lt;/code&gt;.  A more thorough writeup on using &lt;a href=&#34;http://tech.paulcz.net/2014/12/multi-process-docker-images-done-right/&#34;&gt;supervisor&lt;/a&gt; inside docker containers can be found &lt;a href=&#34;http://tech.paulcz.net/2014/12/multi-process-docker-images-done-right/&#34;&gt;here&lt;/a&gt;:&lt;/p&gt;

&lt;h4 id=&#34;etc-supervisor-conf-d-nginx&#34;&gt;/etc/supervisor/conf.d/nginx&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;[supervisord]
logfile=/dev/null
pidfile=/var/run/supervisord.pid
nodaemon=true

[program:nginx]
command=/usr/sbin/nginx
redirect_stderr=true
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
auto_start=true
autorestart=true
user=root
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;etc-nginx-sites-enabled-app&#34;&gt;/etc/nginx/sites-enabled/app&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;worker_processes 1;
daemon off;
error_log /dev/stdout;
http {
  access_log /dev/stdout;
  server {
    listen            *:8080;
    root              /app/bacon-blog;
    index             index.php;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For a more detailed post on using logspout to produce consumable logs check out &lt;a href=&#34;https://twitter.com/behemphi&#34;&gt;@behemphi&lt;/a&gt;&amp;rsquo;s blog post - &lt;a href=&#34;http://stackengine.com/docker-logs-aggregating-ease/&#34;&gt;Docker Logs – Aggregating with Ease&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;fakter-xii-admin-processes&#34;&gt;Fakter XII. Admin processes&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Run admin/management tasks as one-off processes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This one is pretty easy.  Tasks such as database migrates should be run in one off throw-away containers.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -t -e DB_SERVER=user@pass:db.server.com myapp:1.3.2 rake db:migrate
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Most of the fakters above are relatively straight forward to utilize and can be built upon slowly, no need to perfect things before working on them.  They can also be utilized with any existing provisioning / config management tooling that you already have.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re already using &lt;a href=&#34;http://chef.io&#34;&gt;chef&lt;/a&gt; for deploying your application you can use the &lt;a href=&#34;https://supermarket.chef.io/cookbooks/docker&#34;&gt;docker cookbook&lt;/a&gt; to start running docker containers instead and write out confd templates rather than the final config file which confd will then use to do the final configuration of your app from the environment variables you pass through to the &lt;code&gt;docker_run&lt;/code&gt; resource in the cookbook.&lt;/p&gt;

&lt;p&gt;Making your application act like a 12Factor app may not be enough to run it on a purely hosted PAAS like Heroku, but chances are you&amp;rsquo;ll be able to run it on a Docker based PAAS like Deis.  You can go full stack with Mesos or CoreOS+Fleet+ETCD or you can stick to Ubuntu servers running docker.&lt;/p&gt;

&lt;p&gt;The flexibility that the 12fakter application gives you means that you can move to a more modern infrastructure at your own pace when it makes sense without having to abandon or completely rewrite your existing applications.&lt;/p&gt;

&lt;p&gt;Please check out &lt;a href=&#34;http://github.com/paulczar/factorish&#34;&gt;Factorish&lt;/a&gt; and some of the example 12fakter apps like &lt;a href=&#34;http://github.com/paulczar/12fakter-wordpress&#34;&gt;12fakter-wordpress&lt;/a&gt; and &lt;a href=&#34;https://github.com/paulczar/docker-elk_confd&#34;&gt;elk_confd&lt;/a&gt;. to see how easy it can be to start making your applications act like 12Factor apps.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Multi Process Docker Images Done Right</title>
      <link>http://tech.paulcz.net/blog/multi-process-docker-images-done-right/</link>
      <pubDate>Mon, 22 Dec 2014 21:31:03 -0600</pubDate>
      
      <guid>http://tech.paulcz.net/blog/multi-process-docker-images-done-right/</guid>
      <description>&lt;h2 id=&#34;for-some-values-of-right&#34;&gt;For some values of &amp;lsquo;right&amp;rsquo;&lt;/h2&gt;

&lt;p&gt;Almost since &lt;a href=&#34;http://docker.com&#34;&gt;Docker&lt;/a&gt; was first introduced to the world there has been a fairly strong push to keeping containers to be single process.   This makes a lot of sense and definitely plays into the &lt;a href=&#34;http://12factor.net&#34;&gt;12 Factor&lt;/a&gt; way of thinking where all application output should be pushed to &lt;code&gt;stdout&lt;/code&gt; and docker itself with tools like &lt;a href=&#34;https://github.com/progrium/logspout&#34;&gt;logspout&lt;/a&gt; now has fairly strong tooling to deal with those logs.&lt;/p&gt;

&lt;p&gt;Sometimes however it just makes sense to run more than one process in a container,  a perfect example would be running &lt;a href=&#34;https://github.com/kelseyhightower/confd&#34;&gt;confd&lt;/a&gt; as well as your application in order to modify the application&amp;rsquo;s config file based on changes in service discovery systems like &lt;a href=&#34;https://github.com/coreos/etcd&#34;&gt;etcd&lt;/a&gt;.   The &lt;a href=&#34;https://docs.docker.com/articles/ambassador_pattern_linking/&#34;&gt;ambassador&lt;/a&gt; container way of working can achieve similar things, but I&amp;rsquo;m not sure that running two containers with a process each to run your application is any better than running one container with two processes.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re going run multiple processes you have a few options to do it.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Start the container with the first process adnd then use the new &lt;code&gt;docker exec&lt;/code&gt; command to start the second.&lt;/li&gt;
&lt;li&gt;Start them in sequence in a &lt;code&gt;bash&lt;/code&gt; script and background all but the last process with a &lt;code&gt;&amp;amp;&lt;/code&gt; at the end of the line.&lt;/li&gt;
&lt;li&gt;Use a Process Supervisor such as Supervisord or Runit.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I haven&amp;rsquo;t really messed around with the first option, maybe it could work out, but you&amp;rsquo;d lose the logs from the second process as it would need to output via the first process&amp;rsquo; &lt;code&gt;stdout&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;the-bash-script&#34;&gt;The Bash Script&lt;/h2&gt;

&lt;p&gt;Up until recently the way I have been running multiple processes is via the &lt;code&gt;bash&lt;/code&gt; script method, but it feels really clumsy and fragile and while it works I&amp;rsquo;ve never been particularly fond of it.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s an snippet from such a script from my &lt;a href=&#34;https://github.com/paulczar/docker-elk_confd&#34;&gt;docker-elk_confd&lt;/a&gt; project which builds out the [ELK]() stack using values in &lt;code&gt;etcd&lt;/code&gt; to orchestrate clustering and configuration via &lt;code&gt;confd&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo Starting ${APP_NAME}

confd -node $ETCD -config-file /app/confd.toml -confdir /app &amp;amp;
/opt/elasticsearch/bin/elasticsearch -p /app/elasticsearch.pid &amp;amp;

# while the port is listening, publish to etcd
while [[ ! -z $(netstat -lnt | awk &amp;quot;\$6 == \&amp;quot;LISTEN\&amp;quot; &amp;amp;&amp;amp; \$4 ~ \&amp;quot;.$PUBLISH\&amp;quot; &amp;amp;&amp;amp; \$1 ~ \&amp;quot;$PROTO.?\&amp;quot;&amp;quot;) ]] ; do
  publish_to_etcd
  sleep 5 # sleep for half the TTL
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see I&amp;rsquo;ve started two processes &lt;code&gt;elasticsearch&lt;/code&gt; and &lt;code&gt;confd&lt;/code&gt; both backgrounded and then I finish with a loop which publishes data to etcd every 5 seconds until the &lt;code&gt;elasticsearch&lt;/code&gt; process quits listening on its published tcp port.  This works, but it leaves me feeling a bit icky.&lt;/p&gt;

&lt;h2 id=&#34;process-supervisor&#34;&gt;Process Supervisor&lt;/h2&gt;

&lt;p&gt;I have used various supervisors in containers before but never really liked the experience as I could never get all the logs out to &lt;code&gt;stdout&lt;/code&gt; and using the standard docker logging mechanisms so I&amp;rsquo;ve always gone back to the &lt;code&gt;bash&lt;/code&gt; script method.  Recently while working on the ELK project mentioned above I decided to give using a process supervisor another chance.&lt;/p&gt;

&lt;p&gt;My primary measure of success for using a supervisor going forward was to come up with a way to push all output to the supervisor&amp;rsquo;s stdout so that I can use the regular docker logging.&lt;/p&gt;

&lt;p&gt;I decided to try with &lt;a href=&#34;http://supervisord.org&#34;&gt;supervisor&lt;/a&gt; as a starting point because it is a fairly small install and has an easily templatable config.   At about the same time I was looking at this I found a &lt;a href=&#34;http://supervisord.org&#34;&gt;blog post&lt;/a&gt; ( I believe it was linked in a recent Docker Weekly ) that talked about using &lt;code&gt;supervisor&lt;/code&gt; in docker containers.  They had even (sortof) solved the logging problem,  however the logging was appended with debug lines and made it messy and difficult to read.  I figured there had to be a cleaner way.&lt;/p&gt;

&lt;p&gt;Reading through the documentation I saw that you can specify a file to log each supervised process to.   I just needed a way to hijack that config item to write to supervisor&amp;rsquo;s stdout instead.   Turns out that&amp;rsquo;s quite easy as there&amp;rsquo;s a special device &lt;code&gt;/dev/stdout&lt;/code&gt; which links to &lt;code&gt;/dev/self/fd/1&lt;/code&gt; which is the &lt;code&gt;stdout&lt;/code&gt; for the running application.   I quickly threw together a test and it did indeed pipe the logs from the process through &lt;code&gt;stdout&lt;/code&gt; of supervisor.&lt;/p&gt;

&lt;p&gt;I end up with a &lt;code&gt;/etc/supervisord.conf&lt;/code&gt; ( which is written out by confd before supervisor is started ) file that looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[supervisord]
logfile=/dev/null
pidfile=/var/run/supervisord.pid
nodaemon=true

[program:publish_etcd]
command=/app/bin/publish_etcd
redirect_stderr=true
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
auto_start=true
autorestart=true

[program:confd]
command=confd -node %(ENV_ETCD)s -config-file /app/confd.toml -confdir /app
redirect_stderr=true
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
auto_start=true
autorestart=true

[program:elasticsearch]
command=/opt/elasticsearch/bin/elasticsearch
redirect_stderr=true
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
auto_start=true
autorestart=true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and my boot script that docker runs the following to launch my app:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo Starting ${APP_NAME}
/usr/bin/supervisord -c /etc/supervisor/supervisord.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All output from &lt;code&gt;Elasticsearch&lt;/code&gt;, &lt;code&gt;confd&lt;/code&gt;, &lt;code&gt;supervisord&lt;/code&gt; now output via the docker logging systems so that I can see what is going on by running:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker logs elasticsearch
docker logs -f 7270755ce94c03dda930fbdedeee7722dddf6fdbbf8902aaee52c9f94f2147ca
2014-12-23T04:46:02Z 7270755ce94c confd[37]: INFO /opt/elasticsearch/config/elasticsearch.yml has md5sum 08a09998560b7b786eca1e594b004ddc should be d83b49b485b5acad2666aa03b1ee90a0
2014-12-23T04:46:02Z 7270755ce94c confd[37]: INFO Target config /opt/elasticsearch/config/elasticsearch.yml out of sync
2014-12-23T04:46:02Z 7270755ce94c confd[37]: INFO Target config /opt/elasticsearch/config/elasticsearch.yml has been updated
2014-12-23T04:46:02Z 7270755ce94c confd[37]: INFO /etc/supervisor/supervisord.conf has mode -rw-r--r-- should be -rwxr-xr-x
2014-12-23T04:46:02Z 7270755ce94c confd[37]: INFO /etc/supervisor/supervisord.conf has md5sum 99dc7e8a1178ede9ae9794aaecbca436 should be ad9bc3735991d133a09f4fc665e2305f
2014-12-23T04:46:02Z 7270755ce94c confd[37]: INFO Target config /etc/supervisor/supervisord.conf out of sync
2014-12-23T04:46:02Z 7270755ce94c confd[37]: INFO Target config /etc/supervisor/supervisord.conf has been updated
Starting elasticsearch
2014-12-23 04:46:02,245 CRIT Supervisor running as root (no user in config file)
2014-12-23 04:46:02,251 INFO supervisord started with pid 51
2014-12-23 04:46:03,255 INFO spawned: &#39;publish_etcd&#39; with pid 54
2014-12-23 04:46:03,258 INFO spawned: &#39;elasticsearch&#39; with pid 55
2014-12-23 04:46:03,260 INFO spawned: &#39;confd&#39; with pid 56
==&amp;gt; sleeping for 20 seconds, then testing if elasticsearch is up.
[2014-12-23 04:46:04,146][INFO ][node                     ] [Sultan] version[1.4.2], pid[55], build[927caff/2014-12-16T14:11:12Z]
[2014-12-23 04:46:04,149][INFO ][node                     ] [Sultan] initializing ...
[2014-12-23 04:46:04,156][INFO ][plugins                  ] [Sultan] loaded [], sites []
2014-12-23 04:46:05,158 INFO success: publish_etcd entered RUNNING state, process has stayed up for &amp;gt; than 1 seconds (startsecs)
2014-12-23 04:46:05,159 INFO success: elasticsearch entered RUNNING state, process has stayed up for &amp;gt; than 1 seconds (startsecs)
2014-12-23 04:46:05,161 INFO success: confd entered RUNNING state, process has stayed up for &amp;gt; than 1 seconds (startsecs)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;One last thing that I should mention.  the &lt;code&gt;publish_etcd&lt;/code&gt; talk in the supervisor config is running a script that contains the &lt;code&gt;while&lt;/code&gt; loop to make sure that &lt;code&gt;elasticsearch&lt;/code&gt; is listening on the approriate port, If that loop is broken it means that&lt;code&gt;elasticsearch&lt;/code&gt; is not responding and it sends a kill signal to &lt;code&gt;supervisor&lt;/code&gt; which then causes the container to shoot itself in the head because the rest of the  processes running are useless without &lt;code&gt;elasticsearch&lt;/code&gt; running.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>BreadOps - Continuous Delivery of Fresh Baked Bread</title>
      <link>http://tech.paulcz.net/blog/breadops-continous-delivery-of-fresh-baked-bread/</link>
      <pubDate>Wed, 03 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tech.paulcz.net/blog/breadops-continous-delivery-of-fresh-baked-bread/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://lh3.googleusercontent.com/-rMMuR_Itcmk/VH9eSsVZ18I/AAAAAAAAOc8/bJBp9UaoMI0/s1024/20141203_124907.jpg&#34; alt=&#34;the best way to eat fresh bread&#34; /&gt;
&amp;ldquo;See how this sparkly devop princess bakes bread every day with almost no effort at all with this one weird trick&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Store bought bread is shit.  Even the  &amp;ldquo;artisanal&amp;rdquo; bread at most supermarkets is little better than cake baked in a bread shaped mold ( seriously check next time you&amp;rsquo;re at a supermarket ).  You might be lucky and have a really good bread baker near you,  but like butchers and other important crafts they have all but disappeared.  My solution to this was to start baking bread myself.  I did a ton of research, started my own sourdough starter ( 5 years and going strong! ) and started baking bread regularly.&lt;/p&gt;

&lt;p&gt;Reading Boyd&amp;rsquo;s excellent blog post on &lt;a href=&#34;http://stackengine.com/laundryops-practical-devops-at-home/&#34;&gt;LaundryOps&lt;/a&gt; made me realize that I should write this up as I had somewhat unwittingly applied these DevOps practices to baking bread.&lt;/p&gt;

&lt;!--more --&gt;

&lt;p&gt;For a while it was tough going making bread all the time,  starters and doughs are fickle beasts and required constant care and feeding ( literally, you have to feed a sourdough starter at least twice a day ).   After almost giving up several times I started to apply what I now know as &lt;em&gt;devops techniques&lt;/em&gt;. Over time I worked to constantly improve my processes specifically optimizing for my time.  I can even apply CAMS across it:&lt;/p&gt;

&lt;h2 id=&#34;culture&#34;&gt;Culture&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Lactobacillus &amp;hellip; HAHAHAHA Bakers joke!&lt;/li&gt;
&lt;li&gt;A long fermentation time which converts more of the sugars into gas and makes the proteins more digestible&amp;hellip; Wait still wrong culture.&lt;/li&gt;
&lt;li&gt;Minimal human interaction ( approx 5 minutes per loaf ) reduces impact on normal life.&lt;/li&gt;
&lt;li&gt;Healthy Fresh bread for you and your family&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;automation&#34;&gt;Automation&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Slow ferment reduces requirement to knead to almost zero.&lt;/li&gt;
&lt;li&gt;Refrigerating the dough allows me to take control of the timetable.&lt;/li&gt;
&lt;li&gt;Usable for 5-7 days from the fridge.  &lt;strong&gt;Multiple loaves from the one batch.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;measurement&#34;&gt;Measurement&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;How much active time did I spend on it ?&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;How long did it take to ferment?&lt;/li&gt;
&lt;li&gt;How is the crust?  How is the crumb ?&lt;/li&gt;
&lt;li&gt;Is it better or worse than the previous iteration ?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;sharing&#34;&gt;Sharing&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;A &lt;em&gt;lot&lt;/em&gt; of people have received loaves of bread from me during experimentation.&lt;/li&gt;
&lt;li&gt;Ensure this process is approachable by others.&lt;/li&gt;
&lt;li&gt;This blog post.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The final technique that I came up with is not exactly unique and is similar to a number of several hundred page thirty dollar books aimed at making baking bread more accessible to the home cook, where it differs is that this is just a short blog post and is free as in beer and speech.  It&amp;rsquo;s fairly descriptive and may seem like a lot of work, but I tend to average a little over 5 minutes of active time per loaf of bread which is a negligible amount of time.&lt;/p&gt;

&lt;h2 id=&#34;ingredients-and-tools&#34;&gt;Ingredients and Tools&lt;/h2&gt;

&lt;p&gt;I worked hard to ensure that you don&amp;rsquo;t need to use any specialized tools.   No need for a standmixer or other expensive tools.  There are only two things (listed first) that you might not have in your kitchen, and they&amp;rsquo;re both so versatile that you &lt;em&gt;should&lt;/em&gt; have them.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://lh4.googleusercontent.com/v_kKOKFKupOdtI2_44MImjl5L8GYzq7QYMs1BxRyGgc=w1229-h692-no&#34; alt=&#34;things what you need to make bread&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Kitchen Scale[1]

&lt;ul&gt;
&lt;li&gt;capable of measuring to the gram&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Baking Stone[2]

&lt;ul&gt;
&lt;li&gt;large square one, the biggest that will fit in your oven&lt;/li&gt;
&lt;li&gt;A cast iron pan or dutch oven will do in a pinch.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;One large and one small mixing bowl&lt;/li&gt;
&lt;li&gt;Plastic Wrap

&lt;ul&gt;
&lt;li&gt;always cover your dough.&lt;/li&gt;
&lt;li&gt;a showercap makes a great reusable cover.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Flour

&lt;ul&gt;
&lt;li&gt;almost any flour will work, even All Purpose&lt;/li&gt;
&lt;li&gt;I recomend you start with King Arthur Bread Flour.&lt;/li&gt;
&lt;li&gt;I usually do a mix of KABF and stone ground whole wheat.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Salt

&lt;ul&gt;
&lt;li&gt;any salt as long as its not iodized.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Water

&lt;ul&gt;
&lt;li&gt;tap water is fine.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Yeast ( if using )

&lt;ul&gt;
&lt;li&gt;I used Fleischmansn&amp;rsquo;s Active Dry.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Olive Oil

&lt;ul&gt;
&lt;li&gt;For oiling the bowls used in the final shaping.&lt;/li&gt;
&lt;li&gt;I usually line the bowl with floured cheesecloth instead.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[1] Measuring by volume is a mugs game.  Flour and Salt across different brands have different sized grains and this are different weights for the same volume.&lt;/p&gt;

&lt;p&gt;[2] you could get away with using a baking tray, but a baking stone or a cast iron skillet will give you the best results.&lt;/p&gt;

&lt;h2 id=&#34;the-starter&#34;&gt;The Starter&lt;/h2&gt;

&lt;p&gt;I use a &lt;a href=&#34;http://www.sourdoughhome.com/index.php?content=startermyway2&#34;&gt;sourdough starter&lt;/a&gt;, and I would recommend that you do the same &amp;hellip; But unless you already have a starter or have a friend who will give you some ( I&amp;rsquo;d be happy to give you some of mine ) You&amp;rsquo;ll probably want to use regular yeast which is what I&amp;rsquo;ll describe below.  If you have a sourdough starter then skip this step.&lt;/p&gt;

&lt;p&gt;Mix 50g Flour, 50g Water, 3g yeast until it forms a paste and then cover with plastic wrap:
&lt;img src=&#34;https://lh3.googleusercontent.com/-IKFdhJcTr7c/VHtUZeGewaI/AAAAAAAAObE/NQpFh4jQiCs/w1228-h691-no/20141124_123134.jpg&#34; alt=&#34;Starter&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After 4-6 hours it should be all bubby and smell yeasty and ready for The Mix:
&lt;img src=&#34;https://lh6.googleusercontent.com/-_ap54clqH38/VH9em5xPMRI/AAAAAAAAOdk/syJCBF_2AJA/s640/20141201_085112.jpg&#34; alt=&#34;fermented starter&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-mix&#34;&gt;The Mix&lt;/h2&gt;

&lt;p&gt;Add the Starter and 375g of water to the large bowl and mix with a fork until it looks like milk:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Metric protip: a gram of water is the same as a milliliter of water&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://lh4.googleusercontent.com/-0Se5tsoJoH4/VHtUWeoTVdI/AAAAAAAAOa0/57hyMA0sBPk/w1228-h691-no/20141124_140942.jpg&#34; alt=&#34;don&#39;t drink it silly!&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Add 500g of flour and 15g salt.  Mix it until fully incorporated ( we&amp;rsquo;re not kneading here, just making sure there is no dry flour left ):
&lt;img src=&#34;https://lh5.googleusercontent.com/-FGpOS40YpWM/VH9elHUFGCI/AAAAAAAAOdc/tKkrmoXplWw/s640/20141201_085637.jpg&#34; alt=&#34;mixed&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;These quantities form a ratio that can be used to make batches as big or as small as your want.  I usually double it which gives me a decent sized loaf every two days.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-warm-ferment&#34;&gt;The Warm Ferment&lt;/h2&gt;

&lt;p&gt;Cover the bowl and leave it at room temperature for 4 to 8 hours.  The timing doesn&amp;rsquo;t have to be precise,  you&amp;rsquo;re just looking for sings of the yeast to start fermenting the flour and creating air bubbles.  Cover and refrigerate for at least 24 hours, up to 5 days:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://lh3.googleusercontent.com/-DRtoK892ZEI/VH-U6UZeLFI/AAAAAAAAOd8/pmbYgIUPmJU/s640/20141105_101952.jpg&#34; alt=&#34;fermentation activated&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-shaping&#34;&gt;The Shaping&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Whenever you are working with the dough, it is important to try to lose as little air as possible.  Do not punch it down.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://lh6.googleusercontent.com/-bXb_SAwYxSY/VHtUTmXk2SI/AAAAAAAAOak/ME5g9N5mkpM/w1228-h691-no/20141129_143244.jpg&#34; alt=&#34;ready for shaping&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Lightly flour the bench and turn out your dough.   Cut off a piece to use and put the rest back in the bowl and back into the fridge:
&lt;img src=&#34;https://lh6.googleusercontent.com/-B3N3OIQFnsA/VHtUSAIq2OI/AAAAAAAAOac/GsZeRXf4yjk/w1228-h691-no/20141129_143342.jpg&#34; alt=&#34;fresh from the cold ferment&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Protip: You can use the final piece of dough as the starter for the next batch and skip a step.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Gently stretch the piece dough out into a squaring shape and then fold each edge into the middle:
&lt;img src=&#34;https://lh3.googleusercontent.com/-jU4S-UI5kvw/VHtUQoyLJYI/AAAAAAAAOaU/VyQFf1qb06Y/w1228-h691-no/20141129_143427.jpg&#34; alt=&#34;folding&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Turn the dough over and shape it into a ball:
&lt;img src=&#34;https://lh3.googleusercontent.com/-wHWpKg-1IVM/VHtUPA1T5QI/AAAAAAAAOaM/ANaEWZyDuJ0/w1228-h691-no/20141129_143521.jpg&#34; alt=&#34;dough balls&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Watch this &lt;a href=&#34;https://www.youtube.com/watch?feature=player_detailpage&amp;amp;v=4VdVrib2PQo#t=20&#34;&gt;video&lt;/a&gt; (not mine) for the technique used to shape the dough into balls.
&lt;div class=&#34;embed video-player&#34;&gt;
&lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;640&#34; height=&#34;385&#34; src=&#34;http://www.youtube.com/embed/4VdVrib2PQo&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;Oil your shaping bowl and flip your ball over so that the top of the dough is facing down in the bowl and cover it:
&lt;img src=&#34;https://lh5.googleusercontent.com/-xbzq6cwYJis/VHtUNHuDbiI/AAAAAAAAOaE/8EdixPbGN1k/w1228-h691-no/20141129_144021.jpg&#34; alt=&#34;final shaping&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can easily make Ciabatta ( just fold it over itself in one direction and crimp the edges ), or Baguettes ( harder to explain, but youtube has plenty of guides ), or any other style of bread that you prefer.   Even works great for pizza bases!&lt;/p&gt;

&lt;h2 id=&#34;the-final-ferment&#34;&gt;The Final Ferment&lt;/h2&gt;

&lt;p&gt;Let the dough warm back up to room temperature and the yeasts to wake up and get active again.   This will probably take about two hours.  Crank the oven on to 450F after about an hour.  This gives the oven a good solid hour to get up to temperature and stabilize.&lt;/p&gt;

&lt;h2 id=&#34;the-bake&#34;&gt;The Bake&lt;/h2&gt;

&lt;p&gt;Turn the oven up to 500F, open the door, and slide the rack with the pizza stone out so that you can get to it without burning yourself.   upend the bowl onto the stone and run a knife quickly over the top to create a shallow cut:
&lt;img src=&#34;https://lh3.googleusercontent.com/-Pzk8zAWIWt0/VHtULim3WvI/AAAAAAAAOZ8/NTrxiDnOXmk/w1228-h691-no/20141129_155656.jpg&#34; alt=&#34;ready for baking&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Bake for 5 minutes, then turn the oven back down to 450F and bake for another 20 minutes:
&lt;img src=&#34;https://lh4.googleusercontent.com/-hX_Gpo4YIOE/VHtTrWwzT8I/AAAAAAAAOZ0/EY1snf5ymew/w1228-h691-no/20141129_180734.jpg&#34; alt=&#34;baked&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-cooldown&#34;&gt;The Cooldown&lt;/h2&gt;

&lt;p&gt;Avoid the tempation to cut into the bread while its still hot.  Bread continues to cook as it cools down and its important to not allow steam and heat to escape.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://lh4.googleusercontent.com/-8v2AonhRmTE/VH9eUSh3hxI/AAAAAAAAOdE/kx4in89KNTk/s640/20141202_184332.jpg&#34; alt=&#34;some other styles&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-eatening&#34;&gt;The Eatening&lt;/h2&gt;

&lt;p&gt;Fresh bread is best enjoyed simply with some high quality extra virgin olive oil and balsamic vinegar:
&lt;img src=&#34;https://lh3.googleusercontent.com/-_AuYSwAc_8A/VHtTnddC1CI/AAAAAAAAOZc/9cgRejB_s4g/w1228-h691-no/20141129_181010.jpg&#34; alt=&#34;ready to eat&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;tips-and-tricks&#34;&gt;Tips and Tricks&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Make your starter from Ikea&amp;rsquo;s &lt;a href=&#34;http://www.ikea.com/us/en/catalog/products/00229031/&#34;&gt;BRÖDMIX FLERKORN&lt;/a&gt; which contains all sorts of interesting grains as well as Yeast and &amp;ldquo;Sourdough Powder&amp;rdquo; whatever that is.&lt;/li&gt;
&lt;li&gt;Make &lt;a href=&#34;http://food.paulcz.net/2010/05/sourdough-pancakes.html&#34;&gt;sourdough pancakes&lt;/a&gt; from your leftover starter.&lt;/li&gt;
&lt;li&gt;Shape your dough into a &lt;a href=&#34;http://food.paulcz.net/2013/02/austin-style-pizza.html&#34;&gt;pizza dough&lt;/a&gt; and bake it in a cast iron skillet.&lt;/li&gt;
&lt;li&gt;You don&amp;rsquo;t have to make round loafs. use a sandwhich loaf tin, or make ciabatta or baguettes.  It&amp;rsquo;s all it the shaping.&lt;/li&gt;
&lt;li&gt;If you&amp;rsquo;re brave make your dough wetter and ferment for longer.   you&amp;rsquo;ll get cazy large holes in your crumb.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>EZBake - A new way to converge docker containers with chef</title>
      <link>http://tech.paulcz.net/blog/ezbake-a-new-way-to-converge-docker-containers-with-chef/</link>
      <pubDate>Tue, 13 May 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tech.paulcz.net/blog/ezbake-a-new-way-to-converge-docker-containers-with-chef/</guid>
      <description>&lt;p&gt;&lt;code&gt;EZ Bake&lt;/code&gt; came from an idea I had while watching the &lt;a href=&#34;https://twitter.com/hangops&#34;&gt;HangOps&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=clLFKIeSADo&amp;amp;feature=youtu.be&#34;&gt;episode 2014-04-11&lt;/a&gt; in which they were talking about &lt;code&gt;Docker&lt;/code&gt; and Config Management being complementary rather than adversary.&lt;/p&gt;

&lt;p&gt;I have expermented with using &lt;code&gt;Chef&lt;/code&gt; and &lt;code&gt;Docker&lt;/code&gt; together in the &lt;a href=&#34;http://tech.paulcz.net/2013/09/creating-immutable-servers-with-chef-and-docker-dot-io.html&#34;&gt;past&lt;/a&gt; but wanted to tackle the problem from a slightly different angle.  I&amp;rsquo;ve recently been working on some PAAS stuff, both &lt;a href=&#34;http://deis.io&#34;&gt;Deis&lt;/a&gt; and &lt;a href=&#34;http://solum.io&#34;&gt;Solum&lt;/a&gt; these both utilize the tooling from &lt;a href=&#34;https://github.com/flynn/flynn&#34;&gt;Flynn&lt;/a&gt; which builds heroku style &lt;code&gt;buildpacks&lt;/code&gt; in &lt;code&gt;Docker&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;EZ Bake takes chef recipes designed for &lt;code&gt;chef-solo&lt;/code&gt; ( but could easily be extended to do the same for &lt;code&gt;chef-zero&lt;/code&gt;, or &lt;code&gt;chef-client&lt;/code&gt; with a server) in a tarball via &lt;code&gt;stdin&lt;/code&gt; and converges a docker node using that recipe.&lt;/p&gt;

&lt;p&gt;This methodology seems a little weird at first,  but it gives you the ability to ship your Chef cookbooks as self-contained tarballs, or even more interestingly use the &lt;code&gt;git archive&lt;/code&gt; command from your git repository to do this automatically and then pipe that directly to the &lt;code&gt;docker run&lt;/code&gt; command.&lt;/p&gt;

&lt;p&gt;In order to recognize and run your cookbook ( or repo ) it needs to contain the following files: &lt;code&gt;Berksfile&lt;/code&gt;, &lt;code&gt;solo.json&lt;/code&gt;, &lt;code&gt;solo.rb&lt;/code&gt; in the root of your cookbook.   There is some provision for providing different locations for these via environment variables.   This is pre-ChefDK and will probably become easier with ChefDK.&lt;/p&gt;

&lt;p&gt;I have provided an example in the ezbake repo that will install Java7 in the container.&lt;/p&gt;

&lt;p&gt;This example shows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Converging a container using a local chef recipe&lt;/li&gt;
&lt;li&gt;Committing the container to an image on completion&lt;/li&gt;
&lt;li&gt;Removing the build container&lt;/li&gt;
&lt;li&gt;Running the new image&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ git clone paulczar/ezbake
$ cd ezbake/examples
$ ID=$(tar cf - . | sudo docker run -i -a stdin paulczar/ezbake) \
  &amp;amp;&amp;amp; sudo docker attach $ID \
  &amp;amp;&amp;amp; sudo docker commit $ID java7 
  &amp;amp;&amp;amp; sudo docker rm $ID

Running Berkshelf to collect your cookbooks:
Installing java (1.22.0) from site: &#39;http://cookbooks.opscode.com/api/v1/cookbooks&#39;
Converging your container:
[2014-04-12T22:10:24+00:00] INFO: Forking chef instance to converge...
....
[2014-04-12T22:16:52+00:00] INFO: Chef Run complete in 154.563192281 seconds
[2014-04-12T22:16:52+00:00] INFO: Running report handlers
[2014-04-12T22:16:52+00:00] INFO: Report handlers complete

$ sudo docker run -t java7 java -version
java version &amp;quot;1.7.0_51&amp;quot;
Java(TM) SE Runtime Environment (build 1.7.0_51-b13)
Java HotSpot(TM) 64-Bit Server VM (build 24.51-b03, mixed mode)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This could easily be built into a CI pipeline.   a git webhook could call jenkins which would clone the repo and then use a command like  &lt;code&gt;git archive master | docker run -i -a stdin paulczar/ezbake&lt;/code&gt; to converge a container from it.&lt;/p&gt;

&lt;p&gt;It could also very easily be used in &lt;code&gt;Deis&lt;/code&gt; or &lt;code&gt;Solum&lt;/code&gt; as an alternative to a Heroku buildpack.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Running DEIS.IO on Rackspace Cloud</title>
      <link>http://tech.paulcz.net/blog/running-deis-io-on-rackspace-cloud/</link>
      <pubDate>Sun, 23 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tech.paulcz.net/blog/running-deis-io-on-rackspace-cloud/</guid>
      <description>&lt;p&gt;I recently did a presentation at the Cloud Austin meetup titled &lt;a href=&#34;http://tech.paulcz.net/presentation-cloud-austin-deis/#/&#34;&gt;Docking with Unicorns&lt;/a&gt; about new PAAS on the block &lt;a href=&#34;http://deis.io&#34;&gt;DEIS&lt;/a&gt;.   Building out DEIS is quite easy,  make more easy by some tight integration they have with Rackspace Cloud.    If you&amp;rsquo;re interested in what deis is go through my slides linked above, and the documentation on their website.    If you want to build out an environment to kick the tires a bit,  then click &amp;lsquo;Read on&amp;rsquo; below and follow me down the rabbit hole.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;chef-setup&#34;&gt;Chef setup&lt;/h2&gt;

&lt;p&gt;Chef offers a free hosted service for up to five servers.  That&amp;rsquo;s plenty for this exercise so go to the &lt;a href=&#34;https://www.getchef.com/account&#34;&gt;registration page&lt;/a&gt; and create yourself a user.  At some point it will prompt you to generate and save a key, do that and download it.&lt;/p&gt;

&lt;p&gt;Once you have signed up you can download a knife config file and generate a validation key from the &lt;a href=&#34;https://manage.opscode.com/organizations&#34;&gt;Organizations&lt;/a&gt; page.  We can save those down and then move them to a local working directory.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://lh5.googleusercontent.com/-3R-Z-bRi_s0/UwpipiLhhWI/AAAAAAAAN0Q/W6q_Rb7NFy8/w1240-h663-no/opscode-org-page.png&#34; alt=&#34;chef org setup&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;prepare-working-environment&#34;&gt;Prepare Working Environment&lt;/h3&gt;

&lt;p&gt;Create a &lt;code&gt;~/paas&lt;/code&gt; working directory and configure your local chef tools like this ( change the Download location to match the files you downloaded above ) :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir -p ~/paas/.chef
$ cd ~/paas
$ mv ~/Downloads/&amp;lt;username&amp;gt;.pem .chef/
$ mv ~/Downloads/knife.rb .chef/
$ mv ~/Downloads/&amp;lt;username&amp;gt;-validator.pem .chef/

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;clone-the-deis-repository&#34;&gt;Clone the Deis Repository&lt;/h3&gt;

&lt;p&gt;Clone the deis project into your paas working directory:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cd ~/paas
$ git clone https://github.com/opdemand/deis.git
Cloning into &#39;deis&#39;...
remote: Reusing existing pack: 5651, done.
Receiving objects: 100% (5651/5651), 2.16 MiB | 1.37 MiB/s, done.
remote: Total 5651 (delta 0), reused 0 (delta 0)
Resolving deltas: 100% (3131/3131), done.
Checking connectivity... done

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;install-pre-reqs&#34;&gt;Install Pre-reqs&lt;/h3&gt;

&lt;p&gt;Assuming you have a working &lt;code&gt;Ruby 1.9.3+&lt;/code&gt; and the &lt;code&gt;bundler&lt;/code&gt; gem installed you should be able to use the &lt;code&gt;Gemfile&lt;/code&gt; from the deis project to ensure you have all the necessary tools:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cd ~/paas/deis
$ bundle install
bundle install
Fetching gem metadata from https://rubygems.org/.......
Fetching additional metadata from https://rubygems.org/..
Using i18n (0.6.9)
Using multi_json (1.8.4)
Using activesupport (3.2.16)
Using addressable (2.3.5)
...
Using bundler (1.5.2)
Your bundle is complete!
Use `bundle show [gemname]` to see where a bundled gem is installed.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;I had some errors installing the eventmachine gem and had to follow &lt;a href=&#34;https://github.com/gitlabhq/gitlabhq/issues/1051#issuecomment-9176547&#34;&gt;this fix&lt;/a&gt; to get bundle install to work&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;test-chef-connectivity&#34;&gt;Test Chef Connectivity&lt;/h3&gt;

&lt;p&gt;To make sure we configured chef correctly and installed knife as part of the bundle we can run a quick knife command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bundle exec knife client list
&amp;lt;USERNAME&amp;gt;-validator
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;create-an-environment-for-deis&#34;&gt;Create an Environment for Deis&lt;/h3&gt;

&lt;p&gt;Deis is currently hardcoded to use the &lt;code&gt;_default&lt;/code&gt; chef environment.    There is a current &lt;a href=&#34;https://github.com/opdemand/deis/issues/523&#34;&gt;issue&lt;/a&gt; on their github to resolve this.   Once that is done I&amp;rsquo;ll update these instructions to create a &lt;code&gt;deis&lt;/code&gt; environment.&lt;/p&gt;

&lt;h3 id=&#34;upload-the-deis-cookbooks&#34;&gt;Upload the Deis Cookbooks&lt;/h3&gt;

&lt;p&gt;If that went well we can upload our cookbooks:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd ~/paas/deis
$ bundle exec berks install
Installing apt (2.3.8) from site: &#39;http://cookbooks.opscode.com/api/v1/cookbooks&#39;
Installing docker (0.31.0) from site: &#39;http://cookbooks.opscode.com/api/v1/cookbooks&#39;
Installing rsyslog (1.10.2) from site: &#39;http://cookbooks.opscode.com/api/v1/cookbooks&#39;
Installing sudo (2.3.0) from site: &#39;http://cookbooks.opscode.com/api/v1/cookbooks&#39;
...
$ bundle exec berks upload
Using apt (2.3.8)
Using docker (0.31.0)
Using rsyslog (1.10.2)
Using sudo (2.3.0)
Installing deis (0.5.1) from git: &#39;https://github.com/opdemand/deis-cookbook.git&#39; with branch: &#39;master&#39; at ref: &#39;6361706a1d3245d2a061ed55f5dd4b7cb60d5e5c&#39;
Using git (2.7.0)
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;create-deis-databags&#34;&gt;Create Deis Databags&lt;/h3&gt;

&lt;p&gt;Deis uses some databags to help manage application state.  We can create them like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bundle exec knife data bag create deis-formations
Created data_bag[deis-formations]
$ bundle exec knife data bag create deis-apps
Created data_bag[deis-apps]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;prepare-infrastructure&#34;&gt;Prepare Infrastructure&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;m using Rackspace cloud servers for this as I have the (&lt;a href=&#34;http://developer.rackspace.com/blog/developer-love-welcome-to-the-rackspace-cloud-developer-discount.html)[Rackspace&#34;&gt;http://developer.rackspace.com/blog/developer-love-welcome-to-the-rackspace-cloud-developer-discount.html)[Rackspace&lt;/a&gt; Developer Discount] which is enough discount to host this for free.&lt;/p&gt;

&lt;p&gt;Since Deis will want your rackspace credentials to configure worker nodes I recomment creating a user under (&lt;a href=&#34;https://mycloud.rackspace.com/account#users/create)[User&#34;&gt;https://mycloud.rackspace.com/account#users/create)[User&lt;/a&gt; Management] in your account to use for this.&lt;/p&gt;

&lt;h3 id=&#34;create-a-cloud-load-balancer&#34;&gt;Create a Cloud Load Balancer&lt;/h3&gt;

&lt;p&gt;Log into mycloud.rackspace.com and click on the (&lt;a href=&#34;https://mycloud.rackspace.com/load_balancers)[Load&#34;&gt;https://mycloud.rackspace.com/load_balancers)[Load&lt;/a&gt; Balancers] button.  Select the Dallas Region (DFW) and hit &lt;code&gt;Create Load Balancer&lt;/code&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Set the Name to &lt;code&gt;deis&lt;/code&gt; and check the region is set to &lt;code&gt;Dallas (DFW)&lt;/code&gt; and hit &lt;code&gt;Create Load Balancer&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://lh4.googleusercontent.com/-E4cZvoKWlYU/Uwpiqr9xOKI/AAAAAAAAN0o/P3vGqPC8A98/w793-h592-no/rackspace-create-lb.png&#34; alt=&#34;creating load balancer&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Take note of the public IP of the Load Balancer, we&amp;rsquo;ll need it later.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://lh4.googleusercontent.com/-ORvf6nzEduU/Uwpiqk5eP0I/AAAAAAAAN0k/WZ-NaJn3eJg/w770-h567-no/rackspace-lb.png&#34; alt=&#34;load balancer created&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;wildcard-dns&#34;&gt;Wildcard DNS&lt;/h3&gt;

&lt;p&gt;Deis&amp;rsquo; proxy layer requires you to set up Wildcard DNS to point to your proxy layer.  There are many ways to achieve this here are two options:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Rackspace Cloud DNS can host wildcard DNS entries, if you already have DNS hosted by rackspace using Cloud DNS simply add an A record for &lt;code&gt;*.deis&lt;/code&gt; under your domain and point it to the IP of your load balancer.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The (&lt;a href=&#34;http://xip.io)[xip.io&#34;&gt;http://xip.io)[xip.io&lt;/a&gt;] domain does wildcard DNS based on your IP.  We can use this with our Cloud Load Balancer to load balance our applications.   My Load Balancer has a public IP of &lt;code&gt;50.56.167.26&lt;/code&gt; therefore my wildcard domain will be &lt;code&gt;50.56.167.26.xip.io&lt;/code&gt;.   Remember this.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;configure-knife-for-rackspace&#34;&gt;Configure Knife for Rackspace&lt;/h3&gt;

&lt;p&gt;The bundle install above already installed the rackspace knife plugin so we just need to add some details to &lt;code&gt;.chef/knife.rb&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat &amp;lt;&amp;lt;&#39;EOF&#39; &amp;gt;&amp;gt; $HOME/.chef/knife.rb
knife[:rackspace_api_username] = &amp;quot;#{ENV[&#39;OS_USERNAME&#39;]}&amp;quot;
knife[:rackspace_api_key]      = &amp;quot;#{ENV[&#39;OS_PASSWORD&#39;]}&amp;quot;
knife[:rackspace_version]      = &#39;v2&#39;
knife[:rackspace_region]       = :dfw
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;install-rackspace-nova-client&#34;&gt;Install Rackspace Nova Client&lt;/h3&gt;

&lt;p&gt;We also need the Nova client:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo pip install rackspace-novaclient
$ cat &amp;lt;&amp;lt;&#39;EOF&#39; &amp;gt;&amp;gt; ~/paas/.chef/openrc
export OS_AUTH_URL=https://identity.api.rackspacecloud.com/v2.0/
export OS_AUTH_SYSTEM=rackspace
export OS_REGION_NAME=DFW
export OS_USERNAME=&amp;lt;RACKSPACE_USERNAME&amp;gt;
export NOVA_RAX_AUTH=1
export OS_PASSWORD=&amp;lt;RACKSPACE_API_KEY&amp;gt;
export OS_NO_CACHE=1
export OS_TENANT_NAME=&amp;lt;RACKSPACE_USERNAME&amp;gt;
EOF
$ source ~/paas/.chef/openrc
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;test-rackspace-connectivity&#34;&gt;Test Rackspace Connectivity&lt;/h3&gt;

&lt;p&gt;Make sure you can connect to Rackspace with Knife:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bundle exec knife rackspace server list
Instance ID  Name  Public IP  Private IP  Flavor  Image  State
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Make sure you can connect to Rackspace with nova:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ nova list
+--------------------------------------+-----------------+--------+------------+-------------+----------------------------------------------------------------------------------------+
| ID                                   | Name            | Status | Task State | Power State | Networks                                                                               |
+--------------------------------------+-----------------+--------+------------+-------------+----------------------------------------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;build-base-images-for-controller-and-nodes&#34;&gt;Build base images for Controller and Nodes.&lt;/h2&gt;

&lt;p&gt;This isn&amp;rsquo;t strictly necessary,  but will help build your nodes quicker on subsequent builds.&lt;/p&gt;

&lt;h3 id=&#34;launce-a-new-instance&#34;&gt;Launce a new instance:&lt;/h3&gt;

&lt;p&gt;If we create a base image and pre-install some software we&amp;rsquo;ll get a faster booting system for auto-provisioning:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bundle exec knife rackspace server create \
  --image &#39;80fbcb55-b206-41f9-9bc2-2dd7aac6c061&#39; \
  --node-name &#39;deis-base-image&#39; \
  --flavor &#39;performance1-1&#39;
...
...
Instance ID: 56760bf1-b977-405e-9348-f70b15a14b87
Host ID: 97da00a12312a7e455bda70c6dfab8833953e2a03b081aeedfd68152
Name: deis-base-image
Flavor: 1 GB Performance
Image: Ubuntu 12.04 
Metadata: []
Public DNS Name: 23-253-69-98.xip.io
Public IP Address: 23.253.69.98
Private IP Address: 10.208.101.31
Password: **************
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Take note of the &lt;code&gt;Instance ID&lt;/code&gt;, &lt;code&gt;Public IP Address&lt;/code&gt; and &lt;code&gt;Password&lt;/code&gt;.  We&amp;rsquo;ll need them later.&lt;/p&gt;

&lt;h3 id=&#34;add-users-keys-to-instance&#34;&gt;Add users / keys to instance&lt;/h3&gt;

&lt;p&gt;We&amp;rsquo;re going to add our ssh key as well as a local &lt;code&gt;deis-ops&lt;/code&gt; user to the image to make it easier to manage and troubleshoot later:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ DEIS_IP=&amp;lt;IP_OF_SERVER&amp;gt;
$ ssh-copy-id root@$DEIS_IP
root@162.242.144.193&#39;s password: 
Number of key(s) added: 1
Now try logging into the machine, with:   &amp;quot;ssh &#39;root@162.242.144.193&#39;&amp;quot;
and check to make sure that only the key(s) you wanted were added.
$ ssh root@$DEIS_IP
Welcome to Ubuntu 12.04.3 LTS (GNU/Linux 3.2.0-55-virtual x86_64)

 * Documentation:  https://help.ubuntu.com/

  System information as of Sun Feb 23 18:34:40 UTC 2014

  System load:  0.08              Processes:           60
  Usage of /:   5.5% of 19.68GB   Users logged in:     0
  Memory usage: 6%                IP address for eth0: 162.242.144.193
  Swap usage:   0%                IP address for eth1: 10.208.135.114

  Graph this data and manage this system at https://landscape.canonical.com/

Last login: Sun Feb 23 18:33:02 2014 from cpe-24-27-47-27.austin.res.rr.com
root@deis-base-image:~# useradd --comment &#39;deis ops user&#39; --home-dir &#39;/home/deis-ops&#39; \
  --shell &#39;/bin/bash&#39; --create-home deis-ops
root@deis-base-image:~# mkdir -p /home/deis-ops/.ssh &amp;amp;&amp;amp; \
   cp /root/.ssh/authorized_keys /home/deis-ops/.ssh/authorized_keys &amp;amp;&amp;amp; \
  chown -R deis-ops:deis-ops /home/deis-ops &amp;amp;&amp;amp; \
  chmod 0700 /home/deis-ops/.ssh &amp;amp;&amp;amp; \
  chmod 0600 /home/deis-ops/.ssh/authorized_keys &amp;amp;&amp;amp; \
  echo &#39;deis-ops ALL=(ALL) NOPASSWD:ALL&#39; &amp;gt; /etc/sudoers.d/deis-ops &amp;amp;&amp;amp; \
  chmod 0440 /etc/sudoers.d/deis-ops
root@deis-base-image:~# exit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Check that you can log in with these new creds:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh deis-ops@$DEIS_IP
deis$ sudo bash
root@deis$ exit
deis$ exit
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;finish-preparing-node-image&#34;&gt;Finish preparing node image&lt;/h3&gt;

&lt;p&gt;Next we&amp;rsquo;re going to update the kernel and prepare the base node image.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh deis-ops@$DEIS_IP &#39;sudo apt-get update&#39;
$ scp contrib/rackspace/*.sh deis-ops@$DEIS_IP:~/
$ ssh deis-ops@$DEIS_IP &#39;sudo ~/prepare-node-image.sh&#39;
$ ssh deis-ops@$DEIS_IP &#39;sudo apt-get install -yq linux-image-generic-lts-raring linux-headers-generic-lts-raring&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;create-an-image-from-this-server&#34;&gt;Create an image from this server&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ nova image-create deis-base-image deis-node-image
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After a few minutes you should see this response to running &lt;code&gt;nova image-list&lt;/code&gt;, if you&amp;rsquo;re impatient like me wrap your command with a &lt;code&gt;watch&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ watch &#39;nova image-list | grep deis&#39;
| df958d26-6515-4dd9-a449-920e74ea93a2 | deis-base-image                                              | ACTIVE | 0fc7f68b-176d-49a9-82ff-2d5893d32acd |

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once the image is active we can move onto the next steps.&lt;/p&gt;

&lt;h3 id=&#34;prepare-controller-image&#34;&gt;Prepare controller image&lt;/h3&gt;

&lt;p&gt;Next we want to prepare the VM for the controller image:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh deis-ops@$DEIS_IP &#39;sudo ~/prepare-controller-image.sh&#39;
$ ssh deis-ops@$DEIS_IP &#39;sudo apt-get install -yq linux-image-generic-lts-raring linux-headers-generic-lts-raring&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;create-an-image-from-this-server-1&#34;&gt;Create an image from this server&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ nova image-create deis-base-image deis-base-image
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After a few minutes you should see this response to running &lt;code&gt;nova image-list&lt;/code&gt;, if you&amp;rsquo;re impatient like me wrap your command with a &lt;code&gt;watch&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ watch &#39;nova image-list | grep deis-node&#39;
| f2236fa6-1e2d-4746-ac87-a3dd6b2de811 | deis-node-image                                              | ACTIVE | 633d5d88-54b3-463c-80fe-c119f4eb33a3 |

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;delete-the-instance&#34;&gt;Delete the instance&lt;/h3&gt;

&lt;p&gt;No need to keep the instance around and keep paying for it once you have the image:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bundle exec knife rackspace server list | grep deis  
42899699-68e7-4785-9f49-e0050f86249a  deis-base-image  162.242.144.193  10.208.135.114  performance1-1  80fbcb55-b206-41f9-9bc2-2dd7aac6c061  active
$ bundle exec knife rackspace server delete 42899699-68e7-4785-9f49-e0050f86249a --purge
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;create-the-deis-controller-server&#34;&gt;Create the Deis Controller server&lt;/h2&gt;

&lt;h3 id=&#34;launch-the-server&#34;&gt;Launch the Server&lt;/h3&gt;

&lt;p&gt;Launch the server from the image you created earlier:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ nova image-list | grep  deis-base-image
| a58c9895-6349-442a-bba7-99611900209d | deis-base-image
$ knife rackspace server create \
  --image a58c9895-6349-442a-bba7-99611900209d \
  --rackspace-metadata &amp;quot;{\&amp;quot;Name\&amp;quot;: \&amp;quot;deis-controller\&amp;quot;}&amp;quot; \
  --rackspace-disk-config MANUAL \
  --server-name deis-controller \
  --node-name deis-controller \
  --flavor &#39;performance1-2&#39;
Instance ID: bb713170-9322-424a-8837-863a4b396705
Name: deis-controller
Flavor: 2 GB Performance
Image: deis-base-image
...
Public IP Address: 23.253.104.13
Private IP Address: 10.208.132.190
Password: CQwDU4m97nvF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Take note of the &lt;code&gt;Instance ID&lt;/code&gt; and &lt;code&gt;Public IP Address&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If you have an easy to manage domain add an A record for &lt;code&gt;deis&lt;/code&gt; to it for the Public IP address.  If not
add an entry to your hosts file ( or do both! I did ):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo sh -c &amp;quot;echo &#39;&amp;lt;IP_OF_SERVER&amp;gt; deis&#39; &amp;gt;&amp;gt; /etc/hosts&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;modify-chef-admin-group&#34;&gt;Modify Chef Admin Group&lt;/h3&gt;

&lt;p&gt;On the Chef management website click (&lt;a href=&#34;https://manage.opscode.com/groups/admins/edit)[Groups&#34;&gt;https://manage.opscode.com/groups/admins/edit)[Groups&lt;/a&gt;] and add the &lt;code&gt;deis-controller&lt;/code&gt; client and your validator client to the &lt;code&gt;admins&lt;/code&gt; group.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://lh5.googleusercontent.com/-oSqB1Tdnn4c/UwpioPAXpJI/AAAAAAAANz4/xa8BdmRuTzQ/w579-h580-no/chef-admins.png&#34; alt=&#34;chef admins group&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;converge-the-deis-controller-server&#34;&gt;Converge the Deis Controller Server&lt;/h3&gt;

&lt;p&gt;Edit the &lt;code&gt;deis-controller&lt;/code&gt; node via this command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ EDITOR=vi knife node edit deis-controller
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;make it look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;deis-controller&amp;quot;,
  &amp;quot;chef_environment&amp;quot;: &amp;quot;_default&amp;quot;,
  &amp;quot;normal&amp;quot;: {
    &amp;quot;tags&amp;quot;: [

    ]
  },
  &amp;quot;run_list&amp;quot;: [
    &amp;quot;recipe[deis::controller]&amp;quot;
  ]
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;then converge the node by running chef client on it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh deis-ops@deis sudo chef-client
[2014-02-23T19:25:32+00:00] INFO: Forking chef instance to converge...
[2014-02-23T19:25:32+00:00] INFO: *** Chef 11.6.2 ***
[2014-02-23T19:25:33+00:00] INFO: Run List is [recipe[deis::controller]]
[2014-02-23T19:25:33+00:00] INFO: Run List expands to [deis::controller]
[2014-02-23T19:25:33+00:00] INFO: Starting Chef Run for deis-controller
[2014-02-23T19:25:33+00:00] INFO: Running start handlers
[2014-02-23T19:25:33+00:00] INFO: Start handlers complete.
...
$
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;testing-deis&#34;&gt;Testing Deis&lt;/h2&gt;

&lt;h3 id=&#34;install-the-deis-client-with-pip&#34;&gt;Install the Deis Client with pip&lt;/h3&gt;

&lt;p&gt;The Deis client is written in python and can be installed by &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo pip install deis  
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;register-admin-user&#34;&gt;Register Admin User&lt;/h3&gt;

&lt;p&gt;First user to register becomes the Admin:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ deis register http://deis:8000
username: admin
password: 
password (confirm): 
email: admin@example.com
Registered admin
Logged in as admin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Push your public key to deis:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ deis keys:add ~/.ssh/id_rsa.pub 
Uploading SSH_KEY to Deis...done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;check the web server is serving content by browsing to (&lt;a href=&#34;http://deis)[http://deis&#34;&gt;http://deis)[http://deis&lt;/a&gt;] and entering your admin credentials.&lt;/p&gt;

&lt;h3 id=&#34;teach-deis-your-provider-credentials&#34;&gt;Teach Deis your provider credentials&lt;/h3&gt;

&lt;p&gt;Deis will automatically provision worker nodes if you teach it your credentials.&lt;/p&gt;

&lt;p&gt;We already have our Rackspace credentials saved to &lt;code&gt;~/paas/.chef/openrc&lt;/code&gt; but Deis wants them named differently:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ export RACKSPACE_USERNAME=$OS_USERNAME
$ export RACKSPACE_API_KEY=$OS_PASSWORD
$ deis providers:discover
No EC2 credentials discovered.
Discovered Rackspace credentials: ****************
Import Rackspace credentials? (y/n) : y
Uploading Rackspace credentials... done
No DigitalOcean credentials discovered.
No Vagrant VMs discovered.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;deploy-formations-layers&#34;&gt;Deploy Formations &amp;amp; Layers&lt;/h2&gt;

&lt;h3 id=&#34;formation&#34;&gt;Formation&lt;/h3&gt;

&lt;p&gt;Formations are collections of infrastructure for serving applications.   We&amp;rsquo;ll call our first Formation &lt;code&gt;dev&lt;/code&gt; for development.&lt;/p&gt;

&lt;p&gt;Create formation (using the wildcard domain from our cloud load balancer created earlier in the &lt;code&gt;--domain&lt;/code&gt; argument):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ deis formations:create dev --domain=50.56.167.26.xip.io
Creating formation... done, created dev
See `deis help layers:create` to begin building your formation
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;layers&#34;&gt;Layers&lt;/h3&gt;

&lt;p&gt;Layers are a heterogenerous collection of nodes that perform one of two function:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Proxy - Directs traffic to the appropriate container running the application.&lt;/li&gt;
&lt;li&gt;Runtime - Runs the containers that hold the applications.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We&amp;rsquo;re going to create a layer called &lt;code&gt;nodes&lt;/code&gt; that will perform both the proxy and runtime functions:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ deis layers:create dev nodes rackspace-dfw --proxy=y --runtime=y
Creating nodes layer... done in 4s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;note&lt;/em&gt; There&amp;rsquo;s currently a &lt;a href=&#34;https://github.com/opdemand/deis/issues/541&#34;&gt;bug&lt;/a&gt; that causes the first creation of a layer to fail.  if that happens run the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;deis formations:create dev --domain=50.56.167.26.xip.io
Creating formation... done, created dev

See `deis help layers:create` to begin building your formation
$ deis layers:create dev nodes rackspace-dfw --proxy=y --runtime=y
Creating nodes layer... 500 INTERNAL SERVER ERROR
&amp;lt;h1&amp;gt;Server Error (500)&amp;lt;/h1&amp;gt;
$ deis layers:destroy dev nodes
Destroying nodes layer... done in 0s
$ deis layers:create dev nodes rackspace-dfw --proxy=y --runtime=y
Creating nodes layer... done in 2s

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;build-nodes&#34;&gt;Build Nodes&lt;/h3&gt;

&lt;p&gt;Next we tell deis to spin up two Cloud Servers which will become members of the &lt;code&gt;nodes&lt;/code&gt; layer.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ deis nodes:scale dev nodes=2
Scaling nodes... but first, coffee!
done in 345s
Use `deis create --formation=dev` to create an application
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This can sometimes take longer than the &lt;code&gt;deis&lt;/code&gt; cli timeout.   Don&amp;rsquo;t fear,  just wait a bit longer, this could be a great time to explore the &lt;code&gt;deis&lt;/code&gt; cli by running &lt;code&gt;deis help&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;update-cloud-load-balancer&#34;&gt;Update Cloud Load Balancer&lt;/h2&gt;

&lt;p&gt;Add these two nodes to the (&lt;a href=&#34;https://mycloud.rackspace.com/load_balancers)[Cloud&#34;&gt;https://mycloud.rackspace.com/load_balancers)[Cloud&lt;/a&gt; Load Balancer] we created earlier.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://lh6.googleusercontent.com/-yaJfxoyDk4M/UwpioEndiOI/AAAAAAAANz0/aXannmisdbE/w903-h407-no/cloud-servers-list.png&#34; alt=&#34;cloud server list&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This is simple to do through the GUI:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Click on your load balancer and under &lt;code&gt;Nodes&lt;/code&gt; click the &lt;code&gt;Add Cloud Servers&lt;/code&gt; button.&lt;/li&gt;
&lt;li&gt;Check the box beside the two &lt;code&gt;dev-nodes&lt;/code&gt; servers and click &lt;code&gt;Add Selected Servers&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://lh6.googleusercontent.com/-zm6sB7l7YVk/Uwpin4BNJPI/AAAAAAAANzw/b-_J2ieyIuE/w773-h476-no/cloud-lb-nodes.png&#34; alt=&#34;cloud lb servers&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;deploy-an-application&#34;&gt;Deploy an Application&lt;/h2&gt;

&lt;p&gt;So great, you have a PaaS, but what do you do now?  Deploy some apps of course!&lt;/p&gt;

&lt;h3 id=&#34;nodejs-example-app&#34;&gt;NodeJS Example App&lt;/h3&gt;

&lt;p&gt;Download the NodeJS example application so like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir -p ~/paas/apps
$ cd ~paas/apps
$ git clone https://github.com/opdemand/example-nodejs-express.git
$ cd example-nodejs-express
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;create-an-application-in-deis&#34;&gt;Create an Application in Deis&lt;/h3&gt;

&lt;p&gt;Use the Deis command line tool to create a new application:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ deis create      
Creating application... done, created exotic-sandwich
Git remote deis added
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;push-your-application-to-deis&#34;&gt;Push your Application to Deis&lt;/h3&gt;

&lt;p&gt;This will push, deploy and Launch the app.  The first one will take some time as deis has to download some docker images,  subsequent apps will be much faster:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git push deis master                     
git push deis master
Counting objects: 184, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (89/89), done.
Writing objects: 100% (184/184), 28.77 KiB | 0 bytes/s, done.
Total 184 (delta 103), reused 165 (delta 92)
-----&amp;gt; Node.js app detected
-----&amp;gt; Requested node range: 0.10.x
-----&amp;gt; Resolved node version: 0.10.26
-----&amp;gt; Downloading and installing node
-----&amp;gt; Installing dependencies
       npm WARN package.json example-nodejs-express@0.0.1 No repository field.
       npm http GET https://registry.npmjs.org/express
       npm http 200 https://registry.npmjs.org/express
...
-----&amp;gt; Caching node_modules directory for future builds
-----&amp;gt; Cleaning up node-gyp and npm artifacts
-----&amp;gt; Building runtime environment
-----&amp;gt; Discovering process types
       Procfile declares types -&amp;gt; web
-----&amp;gt; Compiled slug size is 5.5M
-----&amp;gt; Building Docker image
Uploading context 5.698 MB
Uploading context 
Step 0 : FROM deis/slugrunner
 ---&amp;gt; bb0a27915014
Step 1 : RUN mkdir -p /app
 ---&amp;gt; Running in 1ae5cdeaad9a
 ---&amp;gt; 6e6467466d48
Step 2 : ADD slug.tgz /app
 ---&amp;gt; 191a4345b1e4
Step 3 : ENTRYPOINT [&amp;quot;/runner/init&amp;quot;]
 ---&amp;gt; Running in d322512d5865
 ---&amp;gt; 2866cf3e37c9
Successfully built 2866cf3e37c9
-----&amp;gt; Pushing image to private registry
       Launching... done, v2

-----&amp;gt; exotic-sandwich deployed to Deis
       http://exotic-sandwich.50.56.167.26.xip.io

       To learn more, use `deis help` or visit http://deis.io

To ssh://git@deis:2222/exotic-sandwich.git
 * [new branch]      master -&amp;gt; master

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;did-it-work&#34;&gt;Did it work ?&lt;/h2&gt;

&lt;p&gt;Open your web browser to the URL in the output of the previous command.  In my case this was &lt;code&gt;http://exotic-sandwich.50.56.167.26.xip.io&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If everything worked the text in the browser window should read &lt;code&gt;Powered by Deis&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://lh6.googleusercontent.com/-cxuysxM_oM8/UwpipfiKFMI/AAAAAAAAN0U/M7T9dC6xJ-E/w446-h171-no/deis-app-1.png&#34; alt=&#34;deis app&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;configure-and-scale-your-application&#34;&gt;Configure and Scale your application&lt;/h2&gt;

&lt;p&gt;We can set config parameters for our apps by running &lt;code&gt;deis config&lt;/code&gt;.   The example app we&amp;rsquo;re using has a config paramater &amp;lsquo;POWERED_BY&amp;rsquo; so we can set that by running:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ deis config:set POWERED_BY=&#39;DEIS and Rackspace&#39;
=== exotic-sandwich
POWERED_BY: DEIS and Rackspace
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://lh6.googleusercontent.com/-J5AcNytZLOQ/UwpipEdpeBI/AAAAAAAAN0E/WXWC08rxsBU/w507-h157-no/deis-app-2.png&#34; alt=&#34;deis app2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Expecting visitors?  Let&amp;rsquo;s scale your app to 5 nodes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ deis scale web=5
Scaling containers... but first, coffee!
done in 54s

=== exotic-sandwich Containers

--- web: `node server.js`
web.1 up 2014-02-23T20:22:07.241Z (dev-nodes-2)
web.2 up 2014-02-23T20:28:21.778Z (dev-nodes-1)
web.3 up 2014-02-23T20:28:21.788Z (dev-nodes-2)
web.4 up 2014-02-23T20:28:21.799Z (dev-nodes-1)
web.5 up 2014-02-23T20:28:21.810Z (dev-nodes-2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can see what your app is doing by running &lt;code&gt;deis info&lt;/code&gt; and &lt;code&gt;deis logs&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ deis info
=== exotic-sandwich Application
{
  &amp;quot;updated&amp;quot;: &amp;quot;2014-02-23T20:28:21.812Z&amp;quot;, 
  &amp;quot;uuid&amp;quot;: &amp;quot;ef618db6-f5a8-4cab-a7d9-d01e78036e3a&amp;quot;, 
  &amp;quot;created&amp;quot;: &amp;quot;2014-02-23T20:16:51.931Z&amp;quot;, 
  &amp;quot;formation&amp;quot;: &amp;quot;dev&amp;quot;, 
  &amp;quot;owner&amp;quot;: &amp;quot;admin&amp;quot;, 
  &amp;quot;id&amp;quot;: &amp;quot;exotic-sandwich&amp;quot;, 
  &amp;quot;containers&amp;quot;: &amp;quot;{\&amp;quot;web\&amp;quot;: 5}&amp;quot;
}

=== exotic-sandwich Containers

--- web: `node server.js`
web.1 up 2014-02-23T20:22:07.241Z (dev-nodes-2)
web.2 up 2014-02-23T20:28:21.778Z (dev-nodes-1)
web.3 up 2014-02-23T20:28:21.788Z (dev-nodes-2)
web.4 up 2014-02-23T20:28:21.799Z (dev-nodes-1)
web.5 up 2014-02-23T20:28:21.810Z (dev-nodes-2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ deis logs
Feb 23 20:22:57 dev-nodes exotic-sandwich[web.1]: Server listening on port 10001 in development mode
Feb 23 20:25:38 dev-nodes exotic-sandwich[web.1]: Server listening on port 10001 in development mode
Feb 23 20:26:49 dev-nodes exotic-sandwich[web.1]: Server listening on port 10001 in development mode
Feb 23 20:28:28 dev-nodes exotic-sandwich[web.3]: Server listening on port 10003 in development mode
Feb 23 20:28:29 dev-nodes exotic-sandwich[web.5]: Server listening on port 10005 in development mode
Feb 23 20:29:11 dev-nodes exotic-sandwich[web.2]: Server listening on port 10002 in development mode
Feb 23 20:29:12 dev-nodes exotic-sandwich[web.4]: Server listening on port 10004 in development mode
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Congratulations!  You&amp;rsquo;ve successfully built out your own cost effective PAAS and deployed your first application to it.&lt;/p&gt;

&lt;p&gt;Speaking of costs &amp;hellip;  How much would this cost to run per month ?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Cloud Load Balancer - $10.95 / month&lt;/li&gt;
&lt;li&gt;Deis Controller - $57.60 / month&lt;/li&gt;
&lt;li&gt;Deis Nodes (x2) - $115.20 / month&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Total:  $183.75 / month.&lt;/p&gt;

&lt;p&gt;You could run all of this on a single server without a load balancer,  which means it would be just $57.60/month, which with the &lt;a href=&#34;http://developer.rackspace.com/devtrial/&#34;&gt;Rackspace Developer Discount&lt;/a&gt; would reduce down to just $7.60/month.&lt;/p&gt;

&lt;h1 id=&#34;epilogue&#34;&gt;Epilogue&lt;/h1&gt;

&lt;h2 id=&#34;cleanup&#34;&gt;Cleanup&lt;/h2&gt;

&lt;p&gt;Destroy your app:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ deis destroy

 !    WARNING: Potentially Destructive Action
 !    This command will destroy the application: exotic-sandwich
 !    To proceed, type &amp;quot;exotic-sandwich&amp;quot; or re-run this command with --confirm=exotic-sandwich

&amp;gt; exotic-sandwich
Destroying exotic-sandwich... done in 21s
Git remote deis removed
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;list your servers:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bundle exec knife rackspace server list
Instance ID                           Name             Public IP       Private IP      Flavor          Image                                 State 
7c43ecb9-1ba3-454c-a5f4-637b56961d68  dev-nodes        23.253.102.184  10.208.135.137  performance1-2  2d59cbce-92fa-412b-8a5e-6eb426ce7dc9  active
f89c4b25-6486-422a-907a-16b3b3223a5e  dev-nodes        23.253.102.158  10.208.137.18   performance1-2  2d59cbce-92fa-412b-8a5e-6eb426ce7dc9  active
bb713170-9322-424a-8837-863a4b396705  deis-controller  23.253.104.13   10.208.132.190  performance1-2  a58c9895-6349-442a-bba7-99611900209d  active
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Delete your servers by running the following command for each:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bundle exec knife rackspace server delete 7c43ecb9-1ba3-454c-a5f4-637b56961d68 --purge
Instance ID: 7c43ecb9-1ba3-454c-a5f4-637b56961d68
Host ID: e0da0172f321babe99aec9686c7b99ac7fa5ff8fa1ada934f5fae842
Name: dev-nodes
Flavor: 2 GB Performance
Image: deis-node-image
Public IP Address: 23.253.102.184
Private IP Address: 10.208.135.137

Do you really want to delete this server? (Y/N) y
[WARNING] Error Parsing response json - Yajl::ParseError
WARNING: Deleted server 7c43ecb9-1ba3-454c-a5f4-637b56961d68
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Clean up your chef:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ bundle exec knife data bag delete deis-apps
$ bundle exec knife data bag delete deis-formations
$ bundle exec knife client delete dev-nodes-1
$ bundle exec knife client delete dev-nodes-2
$ bundle exec knife node delete dev-nodes-1
$ bundle exec knife node delete dev-nodes-2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Delete your glance images:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ nova image-delete deis-base-image
$ nova image-delete deis-node-image
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally delete your Cloud Load Balancer from the &lt;a href=&#34;https://mycloud.rackspace.com/load_balancers&#34;&gt;Rackspace UI&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Managing docker services with this one easy trick</title>
      <link>http://tech.paulcz.net/blog/managing-docker-services-with-this-one-easy-trick/</link>
      <pubDate>Sun, 20 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>http://tech.paulcz.net/blog/managing-docker-services-with-this-one-easy-trick/</guid>
      <description>&lt;p&gt;I have been having a lot of internal debate about the idea of running more than one service in a docker container.   A Docker container is built to run a single process in the foreground and to live for only as long as that process is running.  This is great in a utopian world where servers are immutable and sysadmins drink tiki drinks on the beach,  however it doesn&amp;rsquo;t always translate well to the real world.&lt;/p&gt;

&lt;p&gt;Examples where you might want to be able to run multiple servers span from the simple use case of running &lt;code&gt;sshd&lt;/code&gt; as well as your application to running a web app such as &lt;code&gt;wordpress&lt;/code&gt; where you might want both &lt;code&gt;apache&lt;/code&gt; and &lt;code&gt;mysql&lt;/code&gt; running in the same container.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Wrapping your applications in a supervisor daemon such as &lt;code&gt;runit&lt;/code&gt; seems like a perfect fit for this.  All you need to do is install &lt;code&gt;runit&lt;/code&gt; as part of your &lt;code&gt;dockerfile&lt;/code&gt; and then create appropriate service directories for the apps you want to run in the container.    I was doing some testing of this when I realized a quirk of &lt;code&gt;runit&lt;/code&gt; which I could exploit for evil.&lt;/p&gt;

&lt;p&gt;To start or stop a service with &lt;code&gt;runit&lt;/code&gt; is simply a matter of creating or deleting a symlink in a service directory,   so in theory if you could expose that directory to the server hosting the container you could exploit that to start and stop services from outside of the container.  &lt;code&gt;Docker&lt;/code&gt; volume mapping allows exactly this!&lt;/p&gt;

&lt;p&gt;Below you will find examples of running three services (logstash,elasticsearch,kibana) that make up the &lt;code&gt;logstash&lt;/code&gt; suite.&lt;/p&gt;

&lt;h2 id=&#34;start-by-cloning-the-demo-git-repository-and-run-demo-sh&#34;&gt;Start by cloning the demo git repository and run demo.sh&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/paulczar/docker-runit-demo.git
$ cd docker-runit-demo
$ ./demo.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;demo-sh-script&#34;&gt;demo.sh script&lt;/h3&gt;

&lt;h4 id=&#34;step-1-build-the-container&#34;&gt;Step 1:  Build the container&lt;/h4&gt;

&lt;p&gt;The script uses the below &lt;code&gt;Dockerfile&lt;/code&gt; to build the base container that we&amp;rsquo;ll be running.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Installs runit for service management
#
# Author: Paul Czarkowski
# Date: 10/20/2013

FROM paulczar/jre7
MAINTAINER Paul Czarkowski &amp;quot;paul@paulcz.net&amp;quot;

RUN apt-get update

RUN apt-get -y install curl wget git nginx
RUN apt-get -y install runit || echo

CMD [&amp;quot;/usr/sbin/runsvdir-start&amp;quot;]

&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;step-2-install-the-applications&#34;&gt;Step 2: Install the applications&lt;/h4&gt;

&lt;p&gt;This will take a few minutes the first time as it needs to download &lt;code&gt;logstash&lt;/code&gt;, &lt;code&gt;kibana&lt;/code&gt;, and &lt;code&gt;elasticsearch&lt;/code&gt; and stage them in a local &lt;code&gt;./opt&lt;/code&gt;directory.&lt;/p&gt;

&lt;h4 id=&#34;step-3-start-the-docker-container&#34;&gt;Step 3: Start the Docker container&lt;/h4&gt;

&lt;p&gt;Starts the &lt;code&gt;Docker&lt;/code&gt; container with the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -d -p 8080:80 -p 5014:514 -p 9200:9200 \
  -v $BASE/opt:/opt \
  -v $BASE/sv:/etc/sv \
  -v $BASE/init:/etc/init \
  -v $BASE/service:/etc/service \
  demo/runit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The container should be up and running&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker ps
ID                  IMAGE               COMMAND                CREATED             STATUS              PORTS
eb495ad92ba0        demo/runit:latest   /usr/sbin/runsvdir-s   4 seconds ago       Up 3 seconds        5014-&amp;gt;514, 8080-&amp;gt;80, 9200-&amp;gt;9200   
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However there aren&amp;rsquo;t any services running!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:8080
curl: (56) Recv failure: Connection reset by peer
$ curl localhost:9200
curl: (56) Recv failure: Connection reset by peer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can start the services with the following commands&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cd service
$ ln -s ../sv/elasticsearch
$ ln -s ../sv/logstash
$ ln -s ../sv/kibana
cd ..
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can now see the services are running, test the ports and send some data to logstash.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:8080      
&amp;lt;!DOCTYPE html&amp;gt;&amp;lt;!--[if IE 8]&amp;gt;&amp;lt;html class=&amp;quot;no-js lt-ie9&amp;quot; lang=&amp;quot;en&amp;quot;&amp;gt;&amp;lt;![endif]--&amp;gt;&amp;lt;!--[if gt IE 8]&amp;gt;&amp;lt;!--&amp;gt;&amp;lt;html class=&amp;quot;no-js&amp;quot; lang=&amp;quot;en&amp;quot;&amp;gt;
...
curl localhost:9200
{
  &amp;quot;ok&amp;quot; : true,
  &amp;quot;status&amp;quot; : 200,
...
$tail -100 /var/log/syslog | nc localhost 5014
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Stop a service ?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ rm service/elasticsearch
$ rm service/logstash
$ rm service/kibana
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;bonus-round-logs&#34;&gt;Bonus Round: Logs!&lt;/h2&gt;

&lt;p&gt;The beautify of doing this is that we&amp;rsquo;re actually logging the application output to a mounted volume.   This means we now have access to their logs from the host machine.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tail opt/logstash/logs/current
$ tail opt/elasticsearch-0.90.5/logs/current
$ tail opt/kibana/logs/access.log
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;cleanup&#34;&gt;Cleanup&lt;/h2&gt;

&lt;p&gt;Unfortunately any files created inside the docker instance are owned by root ( an artifact of docker daemon running as root ).   If you&amp;rsquo;re in The following script will clean out any such files after you&amp;rsquo;ve stopped the docker container.&lt;/p&gt;

&lt;p&gt;It will delete any files/dirs inside your current directory that are owned by root.  Obviously it can be very dangerous to run &amp;hellip; so be careful where you run it from!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo find . -uid 0   -exec rm -rfv {} \;
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
  </channel>
</rss>