<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Post-rsses on Paul Czarkowski</title>
    <link>http://tech.paulcz.net/post/index.xml</link>
    <description>Recent content in Post-rsses on Paul Czarkowski</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 10 Jan 2016 10:22:22 -0600</lastBuildDate>
    <atom:link href="http://tech.paulcz.net/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Flexible Private Docker Registry Infrastructure</title>
      <link>http://tech.paulcz.net/2016/01/flexible-docker-registry-infrastructure/</link>
      <pubDate>Sun, 10 Jan 2016 10:22:22 -0600</pubDate>
      
      <guid>http://tech.paulcz.net/2016/01/flexible-docker-registry-infrastructure/</guid>
      <description>

&lt;p&gt;Previously I showed how to run a &lt;a href=&#34;http://tech.paulcz.net/2016/01/deploying-a-secure-docker-registry/&#34;&gt;basic secure Docker Registry&lt;/a&gt;.  I am now going to expand on this to show you something that you might use in production as part of your CI/CD infrastructure.&lt;/p&gt;

&lt;p&gt;The beauty of running Docker is that you &lt;em&gt;can&lt;/em&gt; push an image from a developer&amp;rsquo;s laptop all the way into production which helps ensure that what you see in development and your various test/qa/stage environments are exactly the same as what you run in production.&lt;/p&gt;

&lt;p&gt;So they tell you anyway. The reality is that you don&amp;rsquo;t ever want to push an image built on a developer&amp;rsquo;s machine into production as you can&amp;rsquo;t be sure what is in it.  Instead you want to have a trusted build server build images from a &lt;code&gt;Dockerfile&lt;/code&gt; in your git repository and have it promoted through your environments from there.&lt;/p&gt;

&lt;p&gt;To ensure the integrity of your images you&amp;rsquo;ll want to run a Docker Registry that can be reached by all of your servers (and potentially people), but can only be written to by your build server (and/or an administrative user).&lt;/p&gt;

&lt;p&gt;You could run your &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; behind a &lt;a href=&#34;https://docs.docker.com/registry/recipes/&#34;&gt;complicated reverse proxy&lt;/a&gt; and create rules about who can GET/POST/etc through to the &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; however we can use the magic of &amp;ldquo;&lt;a href=&#34;https://github.com/panicsteve/cloud-to-butt&#34;&gt;The Cloud&lt;/a&gt;&amp;rdquo; to reduce the complexity and thus the need for a reverse proxy.&lt;/p&gt;

&lt;p&gt;You will want to use either the &lt;a href=&#34;https://wiki.openstack.org/wiki/Swift&#34;&gt;Openstack Swift&lt;/a&gt; or the &lt;a href=&#34;https://aws.amazon.com/s3/&#34;&gt;Amazon S3&lt;/a&gt; object storage driver for the &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt;. I will demonstrate using Swift, but using S3 should be very similar.&lt;/p&gt;

&lt;p&gt;You will of course want to also build all of these servers with Configuration Management including the commands to actually run the &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;build-server-s&#34;&gt;Build Server(s)&lt;/h2&gt;

&lt;p&gt;For your build server(s) you&amp;rsquo;ll want to be running an OS with Docker installed on it. I use the &lt;a href=&#34;https://hub.docker.com/_/jenkins/&#34;&gt;Jenkins&lt;/a&gt; Docker image on &lt;a href=&#34;http://coreos.com/&#34;&gt;CoreOS&lt;/a&gt; for both my Jenkins Master and Slaves, however this is just personal preference.&lt;/p&gt;

&lt;p&gt;On each server you want to run a &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; with your Swift credentials passed through to it. Since we&amp;rsquo;re only accessing this via &lt;code&gt;127.0.0.1&lt;/code&gt; we do not need to secure it with TLS or authentication.&lt;/p&gt;

&lt;p&gt;Run the following on each build server to run the Registry backed by Swift, replacing the OpenStack credentials with your own:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;build01$ docker run -d \
              -p 127.0.0.1:5000:5000 \
              --name registry \
              --restart always \
              -e REGISTRY_STORAGE=swift \
              -e REGISTRY_STORAGE_SWIFT_USERNAME=${OS_USERNAME} \
              -e REGISTRY_STORAGE_SWIFT_PASSWORD=${OS_PASSWORD} \
              -e REGISTRY_STORAGE_SWIFT_TENANT=${OS_TENANT} \
              -e REGISTRY_STORAGE_SWIFT_AUTHURL=${OS_AUTH_URL} \
              -e REGISTRY_STORAGE_SWIFT_CONTAINER=docker-registry \
              registry:2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Push an image to make sure it worked:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;build01$ docker pull alpine
Using default tag: latest
latest: Pulling from library/alpine
Digest: sha256:78a756d480bcbc35db6dcc05b08228a39b32c2b2c7e02336a2dcaa196547a41d
Status: Downloaded newer image for alpine:latest
$ docker tag alpine 127.0.0.1:5000/alpine
$ docker push 127.0.0.1:5000/alpine
The push refers to a repository [127.0.0.1:5000/alpine] (len: 1)
74e49af2062e: Pushed 
latest: digest: sha256:a96155be113bb2b4b82ebbc11cf1b511726c5b41617a70e0772f8180afc72fa5 size: 1369
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you have more that one build server try to pull the image from one of the others, since we&amp;rsquo;re backing the &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; with an object store they should retrieve it just fine:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;build02$ docker pull 127.0.0.1:5000/alpine
Using default tag: latest
latest: Pulling from alpine

340b2f9a2643: Already exists 
Digest: sha256:a96155be113bb2b4b82ebbc11cf1b511726c5b41617a70e0772f8180afc72fa5
Status: Downloaded newer image for 127.0.0.1:5000/alpine:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;regular-server-s&#34;&gt;Regular Server(s)&lt;/h2&gt;

&lt;p&gt;We have a couple of options here.  You can run a &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; on each server listening only on localhost, or you can run one or more of them on their own servers that will listen on an IP and be secured with TLS.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll cover the former use case, for the latter use case you can adapt the instructions found &lt;a href=&#34;http://tech.paulcz.net/2016/01/deploying-a-secure-docker-registry/&#34;&gt;at my previous blog post&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The important step in either case is to start the Registry as read-only so that regular servers cannot alter the contents of the Registry.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; is fairly light-weight when the files are in external storage and thus will use a neglible amount of your system resources and provides the advantages and security of running the registry on localhost and not needed to set &lt;code&gt;--insecure-registry&lt;/code&gt; settings or worrying about TLS certs for the docker daemon.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d \
      -p 127.0.0.1:5000:5000 \
      --name registry \
      --restart always \
      -e REGISTRY_STORAGE_MAINTENANCE_READONLY=&#39;enabled: true&#39; \
      -e REGISTRY_STORAGE=swift \
      -e REGISTRY_STORAGE_SWIFT_USERNAME=${OS_USERNAME} \
      -e REGISTRY_STORAGE_SWIFT_PASSWORD=${OS_PASSWORD} \
      -e REGISTRY_STORAGE_SWIFT_TENANT=${OS_TENANT} \
      -e REGISTRY_STORAGE_SWIFT_AUTHURL=${OS_AUTH_URL} \
      -e REGISTRY_STORAGE_SWIFT_CONTAINER=docker-registry \
      registry:2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With &lt;code&gt;REGISTRY_STORAGE_MAINTENANCE_READONLY=&#39;enabled: true&lt;/code&gt; set, when we try to push to the registry it should fail:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker push 127.0.0.1:5000/alpine
The push refers to a repository [127.0.0.1:5000/alpine] (len: 1)
f4fddc471ec2: Preparing 
Error parsing HTTP response: invalid character &#39;M&#39; looking for beginning of value: &amp;quot;Method not allowed\n&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;user-access-to-registry&#34;&gt;User Access to Registry:&lt;/h2&gt;

&lt;p&gt;If you want to provide access to regular users and don&amp;rsquo;t mind maintaining the password files locally you can adapt my &lt;a href=&#34;http://tech.paulcz.net/2016/01/deploying-a-secure-docker-registry/&#34;&gt;basic secure Docker Registry&lt;/a&gt; blog post to use the object storage backend.&lt;/p&gt;

&lt;p&gt;Assuming you&amp;rsquo;ve followed the instructions provided to create the TLS certificates you can run two &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt;s each pointing at a different &lt;code&gt;htpasswd&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;These can run on the same server, or on seperate servers.  They can also be run on multiple servers that are load balanced via an external load balancer or via round-robin-dns for high availability.&lt;/p&gt;

&lt;h3 id=&#34;read-only-users&#34;&gt;Read only Users&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d \
      -p 443:5000 \
      --name registry \
      --restart always \
      -v /opt/registry \
      -e REGISTRY_STORAGE_MAINTENANCE_READONLY=&#39;enabled: true&#39; \
      -e REGISTRY_STORAGE=swift \
      -e REGISTRY_STORAGE_SWIFT_USERNAME=${OS_USERNAME} \
      -e REGISTRY_STORAGE_SWIFT_PASSWORD=${OS_PASSWORD} \
      -e REGISTRY_STORAGE_SWIFT_TENANT=${OS_TENANT} \
      -e REGISTRY_STORAGE_SWIFT_AUTHURL=${OS_AUTH_URL} \
      -e REGISTRY_STORAGE_SWIFT_CONTAINER=docker-registry \
      -e REGISTRY_AUTH=htpasswd \
      -e &amp;quot;REGISTRY_AUTH_HTPASSWD_REALM=Admin Registry Realm&amp;quot; \
      -e REGISTRY_AUTH_HTPASSWD_PATH=/opt/registry/auth/admin.htpasswd \
      -e REGISTRY_HTTP_SECRET=qerldsljckjqr \
      -e REGISTRY_HTTP_TLS_CERTIFICATE=/opt/registry/ssl/cert.pem \
      -e REGISTRY_HTTP_TLS_KEY=/opt/registry/ssl/key.pem \
      registry:2
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;admin-read-write&#34;&gt;Admin Read/Write&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d \
      -p 444:5000 \
      --name registry \
      --restart always \
      -v /opt/registry \
      -e REGISTRY_STORAGE=swift \
      -e REGISTRY_STORAGE_SWIFT_USERNAME=${OS_USERNAME} \
      -e REGISTRY_STORAGE_SWIFT_PASSWORD=${OS_PASSWORD} \
      -e REGISTRY_STORAGE_SWIFT_TENANT=${OS_TENANT} \      
      -e REGISTRY_STORAGE_SWIFT_AUTHURL=${OS_AUTH_URL} \
      -e REGISTRY_STORAGE_SWIFT_CONTAINER=docker-registry \
      -e REGISTRY_AUTH=htpasswd \
      -e &amp;quot;REGISTRY_AUTH_HTPASSWD_REALM=Read Only Registry Realm&amp;quot; \
      -e REGISTRY_AUTH_HTPASSWD_PATH=/opt/registry/auth/users.htpasswd \
      -e REGISTRY_HTTP_SECRET=hlyrehbrvgszd \
      -e REGISTRY_HTTP_TLS_CERTIFICATE=/opt/registry/ssl/cert.pem \
      -e REGISTRY_HTTP_TLS_KEY=/opt/registry/ssl/key.pem \
      registry:2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Before pushing or pull images to these registries you&amp;rsquo;ll need to log in using &lt;code&gt;docker login myregistrydomain.com:443&lt;/code&gt; or &lt;code&gt;docker login myregistrydomain.com:444&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;By using external storage for the Registry we have increased our ability to run a resiliant Docker Registry with no single points of failure. All of the servers access the registry itself via localhost which means they have almost no reliance on external systems (except for a very robust object storage platform) and no need for complicated authentication systems.&lt;/p&gt;

&lt;p&gt;We also provide access to both Admin (read/write) and Regular (read-only) users via &lt;code&gt;htpasswd&lt;/code&gt; files and &lt;code&gt;TLS&lt;/code&gt; certificates/encryption which can be managed by Configuration Management.&lt;/p&gt;

&lt;p&gt;It goes without saying that you should further lock down all of these services with network based access restrictions in the form of Firewall/IPTables/Security-Groups so that only certain trusted networks can access any of the public endpoints we have created.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deploying a Simple and Secure Docker Registry</title>
      <link>http://tech.paulcz.net/2016/01/deploying-a-secure-docker-registry/</link>
      <pubDate>Sun, 10 Jan 2016 05:22:22 -0600</pubDate>
      
      <guid>http://tech.paulcz.net/2016/01/deploying-a-secure-docker-registry/</guid>
      <description>

&lt;p&gt;There comes a time in everybody&amp;rsquo;s life where they realize they have to run their own &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt;. Unfortunately there&amp;rsquo;s not a lot of good information on how to run one. &lt;a href=&#34;http://docker.com&#34;&gt;Docker&lt;/a&gt;&amp;rsquo;s documentation is pretty good, but is verbose and across a lot of different pages which means having half a dozen tabs open and searching for the right information.&lt;/p&gt;

&lt;p&gt;While it&amp;rsquo;s pretty common to run the &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; itself with little to no security settings and fronting it with NGINX or Apache to provide this security I wanted to show how it can be done with just the &lt;a href=&#34;http://docker.com&#34;&gt;Docker&lt;/a&gt; Registry. If you need to do really clever stuff like authenticate against LDAP then you&amp;rsquo;ll want to go down the reverse proxy road.&lt;/p&gt;

&lt;p&gt;This example will demonstrate using just the &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; itself with both TLS certificate backed encryption and Certificate based endpoint authorization.&lt;/p&gt;

&lt;p&gt;For simplicity it will assume a single registry running on the local filesystem and will avoid using OS specific init (systemd/upstart/etc) systems by focusing just on the docker commands themselves.  This should work on any system capable of running &lt;a href=&#34;http://docker.com&#34;&gt;Docker&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;

&lt;p&gt;Boot a server that has &lt;a href=&#34;http://docker.com&#34;&gt;Docker&lt;/a&gt; installed. For an OS with &lt;a href=&#34;http://docker.com&#34;&gt;Docker&lt;/a&gt; already installed I recommend &lt;a href=&#34;http://coreos.com/&#34;&gt;CoreOS&lt;/a&gt;. However you could just as easily boot Ubuntu or CentOS and run &lt;code&gt;curl -sSL get.docker.com | sudo bash&lt;/code&gt; if you&amp;rsquo;re into that sort of thing.&lt;/p&gt;

&lt;p&gt;SSH into the server and ensure &lt;a href=&#34;http://docker.com&#34;&gt;Docker&lt;/a&gt; is working:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh core@xx.xx.xx.xx
$ docker info
Containers: 0
Images: 0
Server Version: 1.9.1
Storage Driver: overlay
 Backing Filesystem: extfs
Execution Driver: native-0.2
Logging Driver: json-file
Kernel Version: 4.3.3-coreos
Operating System: CoreOS 899.1.0
CPUs: 1
Total Memory: 997.4 MiB
Name: core-01
ID: C5XV:CZ3H:EAO4:ATJ3:ARSO:UOGD:XH3X:UKLZ:V3FO:2LRF:6E3X:CV5K
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;create-certificates&#34;&gt;Create Certificates&lt;/h2&gt;

&lt;p&gt;To keep this as simple as possible I will demonstrate using the &lt;a href=&#34;https://github.com/paulczar/omgwtfssl&#34;&gt;paulczar/omgwtfssl&lt;/a&gt; image to create certificates. If you would rather create them manually via the &lt;code&gt;openssl&lt;/code&gt; cli see my blog post on &lt;a href=&#34;http://tech.paulcz.net/2016/01/secure-docker-with-tls/&#34;&gt;Securing Docker with TLS&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We need to create a place on the filesystem to store the data for the registry as well as certificates and config data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mkdir -p /opt/registry/{data,ssl,config}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can create the certificates, add any IPs and DNS that you might address your registry with including that of any loadbalancer or floating IP that you might have:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run --rm \
  -v /opt/registry/ssl:/certs \
  -e SSL_IP=172.17.8.101 \
  -e SSL_DNS=registry.local \
  paulczar/omgwtfssl
----------------------------
| OMGWTFSSL Cert Generator |
----------------------------

--&amp;gt; Certificate Authority
====&amp;gt; Generating new CA key ca-key.pem
Generating RSA private key, 2048 bit long modulus
................+++
.................................+++
e is 65537 (0x10001)
====&amp;gt; Generating new CA Certificate ca.pem
====&amp;gt; Generating new config file openssl.cnf
====&amp;gt; Generating new SSL KEY key.pem
Generating RSA private key, 2048 bit long modulus
..........................................................+++
.............................................+++
e is 65537 (0x10001)
====&amp;gt; Generating new SSL CSR key.csr
====&amp;gt; Generating new SSL CERT cert.pem
Signature ok
subject=/CN=example.com
Getting CA Private Key

core@core-01 ~ $ ls /opt/registry/ssl/
ca-key.pem  ca.pem  ca.srl  cert.pem  key.csr  key.pem  openssl.cnf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our next step is to create a config file &lt;code&gt;/opt/registry/config/registry.env&lt;/code&gt; which will contain a list of Environment Variables that will be passed into the container:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;For this example I&amp;rsquo;m using the same CA certificate for clients as I did for the server, in reality it should probably be a different CA.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# location of registry data
REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY=/opt/registry/data

# location of TLK key/cert
REGISTRY_HTTP_TLS_KEY=/opt/registry/ssl/key.pem
REGISTRY_HTTP_TLS_CERTIFICATE=/opt/registry/ssl/cert.pem

# location of CA of trusted clients
REGISTRY_HTTP_TLS_CLIENTCAS_0=/opt/registry/ssl/ca.pem
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All that is left to do now is start the registry container, bind mount in the &lt;code&gt;/opt/registry&lt;/code&gt; directory, pass in the config file, and expose port &lt;code&gt;443&lt;/code&gt; to the internal registry port:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d --name registry \
  -v /opt/registry:/opt/registry \
  -p 443:5000 --restart always \
  --env-file /opt/registry/config/registry.env \
  registry:2
Unable to find image &#39;registry:2&#39; locally
2: Pulling from library/registry
Digest: sha256:a842b52833778977f7b4466b90cc829e0f9aae725aebe3e32a5a6c407acd2a03
Status: Downloaded newer image for registry:2
d0106555b2d0aa30691c75c50b279e6a8bd485aa4ba2f203773e971988253169  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can check that we can access it from the server itself by tagging and pushing the &lt;code&gt;alpine&lt;/code&gt; image to it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker pull alpine
Using default tag: latest
latest: Pulling from library/alpine
Digest: sha256:78a756d480bcbc35db6dcc05b08228a39b32c2b2c7e02336a2dcaa196547a41d
Status: Downloaded newer image for alpine:latest
$ docker tag alpine 127.0.0.1/alpine
$ docker push 127.0.0.1/alpine
The push refers to a repository [127.0.0.1/alpine] (len: 1)
74e49af2062e: Pushed 
latest: digest: sha256:a96155be113bb2b4b82ebbc11cf1b511726c5b41617a70e0772f8180afc72fa5 size: 1369
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To check the security settings worked we&amp;rsquo;ll try to access the docker registry from a remote host:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Anywhere you see &lt;code&gt;172.17.8.101&lt;/code&gt; you will want to replace it with the IP or hostname of your docker registry.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker pull 172.17.8.101/alpine
Using default tag: latest
Error response from daemon: unable to ping registry endpoint https://172.17.8.101/v0/
v2 ping attempt failed with error: Get https://172.17.8.101/v2/: x509: certificate signed by unknown authority
 v1 ping attempt failed with error: Get https://172.17.8.101/v1/_ping: x509: certificate signed by unknown authority
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;On the server we can see this failure in the docker logs:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker logs registry
2016/01/10 16:18:47 http: TLS handshake error from 172.17.8.1:44096: remote error: bad certificate
2016/01/10 16:18:47 http: TLS handshake error from 172.17.8.1:44098: remote error: bad certificate
2016/01/10 16:18:47 http: TLS handshake error from 172.17.8.1:44099: remote error: bad certificate
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are two things causing this failure. The first is that the remote server does not trust the client because it cannot provide the trusted CA certificate as specified in &lt;code&gt;REGISTRY_HTTP_TLS_CLIENTCAS_0&lt;/code&gt;. The second reason for failure is that the client doesn&amp;rsquo;t trust the &lt;code&gt;CA&lt;/code&gt; of the server.&lt;/p&gt;

&lt;p&gt;If we didn&amp;rsquo;t have &lt;code&gt;REGISTRY_HTTP_TLS_CLIENTCAS_0&lt;/code&gt; set we could simply add &lt;code&gt;--insecure-registry 172.17.8.101&lt;/code&gt; to &lt;code&gt;DOCKER_OPTS&lt;/code&gt; in &lt;code&gt;/etc/default/docker&lt;/code&gt;, however since we do have this set we&amp;rsquo;ll want to take the &lt;code&gt;CA.pem&lt;/code&gt; and save it as &lt;code&gt;/etc/docker/certs.d/172.17.8.101/ca.crt&lt;/code&gt; on the remote machine that you want to trust the registry server.&lt;/p&gt;

&lt;p&gt;I do this with the following commands, you may need to do it differently based on how your server is set up for access:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mkdir -p /etc/docker/certs.d/172.17.8.101
$ sudo scp core@172.17.8.101:/opt/docker/registry/ca.pem \
    /etc/docker/certs.d/172.17.8.101/ca.crt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have established trust in both directions we can try to access the docker registry again:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker pull 172.17.8.101/alpine
Using default tag: latest
latest: Pulling from alpine

340b2f9a2643: Already exists 
Digest: sha256:a96155be113bb2b4b82ebbc11cf1b511726c5b41617a70e0772f8180afc72fa5
Status: Downloaded newer image for 172.17.8.101/alpine:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Success!   We know have a &lt;a href=&#34;https://www.docker.com/docker-registry&#34;&gt;Docker Registry&lt;/a&gt; that is secured both with Encryption and an authorization based on each client having a specific CA certificate.  This setup is ideal for providing secure access to a private registry for remote servers.&lt;/p&gt;

&lt;p&gt;If you want to do this in a more automated fashion you can look at the various configuration management communities such as &lt;a href=&#34;https://supermarket.chef.io/cookbooks/docker_registry&#34;&gt;chef&lt;/a&gt; for examples.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Securing Docker with TLS certificates</title>
      <link>http://tech.paulcz.net/2016/01/secure-docker-with-tls/</link>
      <pubDate>Sun, 03 Jan 2016 14:44:30 -0600</pubDate>
      
      <guid>http://tech.paulcz.net/2016/01/secure-docker-with-tls/</guid>
      <description>

&lt;p&gt;By default Docker (and by extension Docker Swarm) has no authentication or authorization on its API, relying instead on the filesystem security of its unix socket &lt;code&gt;/var/run/docker.sock&lt;/code&gt; which by default is only accessible by the root user.&lt;/p&gt;

&lt;p&gt;This is fine for the basic use case of the default behavior of only accessing the Docker API on the local machine via the socket as the root user. However if you wish to use the Docker API over TCP then you&amp;rsquo;ll want to secure it so that you don&amp;rsquo;t give out root access to anyone that happens to poke you on the TCP port.&lt;/p&gt;

&lt;p&gt;Docker supports using TLS certificates (both on the server and the client) to provide proof of identity. When set up correctly it will only allow clients/servers with a certificate signed by a specific CA to talk to eachother. While not providing fine grained access permissions it does at least allow us to listen on a TCP socket and restrict access with a bonus of also providing encryption.&lt;/p&gt;

&lt;p&gt;Here I will detail what is required to secure Docker (and in turn Docker Swarm) running on a &lt;a href=&#34;http://coreos.com/&#34;&gt;CoreOS&lt;/a&gt; server. I will assume you already have a &lt;a href=&#34;http://coreos.com/&#34;&gt;CoreOS&lt;/a&gt; server running as described in my Docker Swarm &lt;a href=&#34;http://tech.paulcz.net/2016/01/running-ha-docker-swarm/&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you are only interested in securing Docker itself and not Docker Swarm then this should apply to any server with Docker installed that uses systemd.  Even on systems without systemd it should provide enough details to secure Docker.&lt;/p&gt;

&lt;h2 id=&#34;creating-certificates&#34;&gt;Creating Certificates&lt;/h2&gt;

&lt;p&gt;I will offer two methods to create the certificates, the first by using &lt;code&gt;openssl&lt;/code&gt; to create a CA and then sign a key/cert pair, the second by using the &lt;a href=&#34;https://hub.docker.com/r/paulczar/omgwtfssl/&#34;&gt;paulczar/omgwtfssl&lt;/a&gt; Docker Image which automates the certificate creation process.&lt;/p&gt;

&lt;p&gt;Either way you&amp;rsquo;ll want to start off by creating directories for both the server and client certificate sets:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mkdir -p /etc/docker/ssl
$ mkdir -p ~/.docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;For this example we&amp;rsquo;re creating the keys and certificates on the server itself, ideally you would do this on your laptop or via configuration management and never store the CA key on a public server.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;openssl&#34;&gt;OpenSSL&lt;/h3&gt;

&lt;p&gt;First run &lt;code&gt;openssl&lt;/code&gt; to create and sign a CA key and certificate and copy the CA certificate into &lt;code&gt;/etc/docker/ssl&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openssl genrsa -out ~/.docker/ca-key.pem 2048
.+++
..........................................................................................................+++
e is 65537 (0x10001)

$ openssl req -x509 -new -nodes -key ~/.docker/ca-key.pem \
    -days 10000 -out ~/.docker/ca.pem -subj &#39;/CN=docker-CA&#39;

$ ls ~/.docker/
ca-key.pem  ca.pem

$ sudo cp ~/.docker/ca.pem /etc/docker/ssl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we&amp;rsquo;ll need an openssl configuration file for the Docker client &lt;code&gt;~/.docker/openssl.cnf&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[req]
req_extensions = v3_req
distinguished_name = req_distinguished_name
[req_distinguished_name]
[ v3_req ]
basicConstraints = CA:FALSE
keyUsage = nonRepudiation, digitalSignature, keyEncipherment
extendedKeyUsage = serverAuth, clientAuth
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Followed by a configuration file for the Docker server &lt;code&gt;/etc/docker/ssl/openssl.cnf&lt;/code&gt;.  Add any DNS or IPs that you might use to access the Docker Server with, this is critical as the Golang SSL libraries are very strict:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[req]
req_extensions = v3_req
distinguished_name = req_distinguished_name
[req_distinguished_name]
[ v3_req ]
basicConstraints = CA:FALSE
keyUsage = nonRepudiation, digitalSignature, keyEncipherment
extendedKeyUsage = serverAuth, clientAuth
subjectAltName = @alt_names

[alt_names]
DNS.1 = docker.local
IP.1 = 172.17.8.101
IP.2 = 127.0.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next create and sign a certificate for the client:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ openssl genrsa -out ~/.docker/key.pem 2048
....................................+++
.............+++
e is 65537 (0x10001)

$ openssl req -new -key ~/.docker/key.pem -out ~/.docker/cert.csr \
    -subj &#39;/CN=docker-client&#39; -config ~/.docker/openssl.cnf

$ openssl x509 -req -in ~/.docker/cert.csr -CA ~/.docker/ca.pem \
    -CAkey ~/.docker/ca-key.pem -CAcreateserial \
    -out ~/.docker/cert.pem -days 365 -extensions v3_req \
    -extfile ~/.docker/openssl.cnf
Signature ok
subject=/CN=docker-client
Getting CA Private Key
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then do the same for the server:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo openssl genrsa -out /etc/docker/ssl/key.pem 2048
................................................................................+++
....................................+++
e is 65537 (0x10001)

$ sudo openssl req -new -key /etc/docker/ssl/key.pem \
    -out /etc/docker/ssl/cert.csr \
    -subj &#39;/CN=docker-server&#39; -config /etc/docker/ssl/openssl.cnf

$ sudo openssl x509 -req -in /etc/docker/ssl/cert.csr -CA ~/.docker/ca.pem \
    -CAkey ~/.docker/ca-key.pem -CAcreateserial \
    -out /etc/docker/ssl/cert.pem -days 365 -extensions v3_req \
    -extfile /etc/docker/ssl/openssl.cnf
Signature ok
subject=/CN=docker-client
Getting CA Private Key
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;omgwtfssl&#34;&gt;OMGWTFSSL&lt;/h3&gt;

&lt;p&gt;If you want to skip manually creating the certificates you can use the &lt;a href=&#34;https://hub.docker.com/r/paulczar/omgwtfssl/&#34;&gt;paulczar/omgwtfssl&lt;/a&gt; image which is a small (&amp;lt; 10mb) Docker image built specifically for creating certificates for situations like this.&lt;/p&gt;

&lt;p&gt;First we&amp;rsquo;ll create our client certs and use a docker volume binding to put the CA and certs into &lt;code&gt;~/.docker&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run --rm -v $(pwd)/.docker:/certs \
    paulczar/omgwtfssl
----------------------------
| OMGWTFSSL Cert Generator |
----------------------------

--&amp;gt; Certificate Authority
====&amp;gt; Using existing CA Key ca-key.pem
====&amp;gt; Using existing CA Certificate ca.pem
====&amp;gt; Generating new config file openssl.cnf
====&amp;gt; Generating new SSL KEY key.pem
Generating RSA private key, 2048 bit long modulus
.............+++
..........+++
e is 65537 (0x10001)
====&amp;gt; Generating new SSL CSR key.csr
====&amp;gt; Generating new SSL CERT cert.pem
Signature ok
subject=/CN=example.com
Getting CA Private Key
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we&amp;rsquo;ll take ownership of them back from root (because of the docker volume binding) and then create the server certificates using the same CA using a second volume binding to &lt;code&gt;/etc/docker/ssl&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Since this is a server certificate we need to pass the IP and DNS that the server may respond to via the -e command line arguments.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo cp ~/.docker/ca.pem /etc/docker/ssl/ca.pem
$ chown -R $USER ~/.docker
$ docker run --rm -v /etc/docker/ssl:/server \
    -v $(pwd)/.docker:/certs \
    -e SSL_IP=127.0.0.1,172.17.8.101 \
    -e SSL_DNS=docker.local -e SSL_KEY=/server/key.pem \
    -e SSL_CERT=/server/cert.pem paulczar/omgwtfssl
----------------------------
| OMGWTFSSL Cert Generator |
----------------------------

--&amp;gt; Certificate Authority
====&amp;gt; Using existing CA Key ca-key.pem
====&amp;gt; Using existing CA Certificate ca.pem
====&amp;gt; Generating new config file openssl.cnf
====&amp;gt; Generating new SSL KEY /server/key.pem
Generating RSA private key, 2048 bit long modulus
.................................+++
..................+++
e is 65537 (0x10001)
====&amp;gt; Generating new SSL CSR key.csr
====&amp;gt; Generating new SSL CERT /server/cert.pem
Signature ok
subject=/CN=example.com
Getting CA Private Key
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;using-the-tls-certificates-with-docker&#34;&gt;Using the TLS certificates with Docker&lt;/h2&gt;

&lt;p&gt;Now we have our TLS certificates created and in the correct locations you need to tell Docker to use the TLS certificate and also verify the client.  You do this by creating a drop in systemd unit to modify the existing Docker systemd unit.&lt;/p&gt;

&lt;p&gt;Create the file &lt;code&gt;custom.conf&lt;/code&gt; in &lt;code&gt;/etc/systemd/system/docker.service.d/&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;If you want to restrict local users from using the docker unix socket remove the second -H command line option, if you already have a custom drop in unit you can add the -H and &amp;ndash;tls* arguments to it.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Service]
Environment=&amp;quot;DOCKER_OPTS=-H=0.0.0.0:2376 -H unix:///var/run/docker.sock --tlsverify --tlscacert=/etc/docker/ssl/ca.pem --tlscert=/etc/docker/ssl/cert.pem --tlskey=/etc/docker/ssl/key.pem&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Reload systemd and the Docker service:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo systemctl daemon-reload
$ sudo systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now when you try to access Docker via the TCP port you should get a TLS error:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker -H tcp://127.0.0.1:2376 info
Get http://127.0.0.1:2376/v1.21/containers/json: malformed HTTP response &amp;quot;\x15\x03\x01\x00\x02\x02&amp;quot;.
* Are you trying to connect to a TLS-enabled daemon without TLS?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is because the Docker client does not know to use TLS to communicate with the server.  We can set some environment variables to enable TLS for the client and use the client key we created:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ export DOCKER_HOST=tcp://127.0.0.1:2376
$ export DOCKER_TLS_VERIFY=1
$ export DOCKER_CERT_PATH=~/.docker
$ docker info
docker info
Containers: 0
Images: 0
Server Version: 1.9.1
Storage Driver: overlay
 Backing Filesystem: extfs
Execution Driver: native-0.2
Logging Driver: json-file
Kernel Version: 4.3.3-coreos
Operating System: CoreOS 899.1.0
CPUs: 1
Total Memory: 997.4 MiB
Name: core-01
ID: RGVQ:VDUC:Z5LU:IE7I:J6UJ:TFBJ:SSCO:EWG2:QKAW:5FY6:EIAV:MROK
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;using-the-tls-certificates-with-docker-swarm&#34;&gt;Using the TLS certificates with Docker Swarm&lt;/h2&gt;

&lt;p&gt;To secure Docker Swarm using these TLS certificates you will need to create TLS certificate/key pairs for each server using the same CA.&lt;/p&gt;

&lt;p&gt;to add some arguments to the &lt;code&gt;docker run&lt;/code&gt; command that you start Swarm Manager with the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d --name swarm-manager \
    -v /etc/docker/ssl:/etc/docker/ssl \
    --net=host swarm:latest manage \
    --tlsverify \
    --tlscacert=/etc/docker/ssl/ca.pem \
    --tlscert=/etc/docker/ssl/cert.pem \
    --tlskey=/etc/docker/ssl/key.pem \
    etcd://127.0.0.1:2379
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which you can then access using the docker client:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ export DOCKER_HOST=tcp://127.0.0.1:2375
$ export DOCKER_TLS_VERIFY=1
$ export DOCKER_CERT_PATH=~/.docker

$ docker info
Containers: 6
Images: 5
Role: primary
Strategy: spread
Filters: health, port, dependency, affinity, constraint
Nodes: 3
 core-01: 172.17.8.101:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.023 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.3.3-coreos, operatingsystem=CoreOS 899.1.0, storagedriver=overlay
 core-02: 172.17.8.102:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.023 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.3.3-coreos, operatingsystem=CoreOS 899.1.0, storagedriver=overlay
 core-03: 172.17.8.103:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.023 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.3.3-coreos, operatingsystem=CoreOS 899.1.0, storagedriver=overlay
CPUs: 3
Total Memory: 3.068 GiB
Name: core-01
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Deploying a HA Docker Swarm Cluster</title>
      <link>http://tech.paulcz.net/2016/01/running-ha-docker-swarm/</link>
      <pubDate>Sat, 02 Jan 2016 14:44:30 -0600</pubDate>
      
      <guid>http://tech.paulcz.net/2016/01/running-ha-docker-swarm/</guid>
      <description>

&lt;p&gt;Given Docker&amp;rsquo;s propensity for creating easy to use tools it shouldn&amp;rsquo;t come as a surprise that Docker Swarm is one of the easier to understand and run of the &amp;ldquo;Docker Clustering&amp;rdquo; options currently out there. I recently built some &lt;a href=&#34;http://terraform.io&#34;&gt;Terraform&lt;/a&gt; configs for deploying a &lt;a href=&#34;https://github.com/openstack/osops-tools-contrib/tree/master/terraform/dockerswarm-coreos&#34;&gt;Highly Available Docker Swarm cluster on Openstack&lt;/a&gt; and learned a fair bit about Swarm in the process.&lt;/p&gt;

&lt;p&gt;This guide is meant to be a platform agnostic howto on installing and running a Highly Available Docker Swarm to show you the ideas and concepts that may not be as easy to understand from just reading some config management code.&lt;/p&gt;

&lt;h2 id=&#34;coreos&#34;&gt;CoreOS&lt;/h2&gt;

&lt;p&gt;The reason for using &lt;a href=&#34;http://coreos.com&#34;&gt;CoreOS&lt;/a&gt; here is that to make Swarm run in High Availability mode as well as being able to support docker networking between hosts we need to use service discovery.  We can choose to use &lt;code&gt;etcd&lt;/code&gt;, &lt;code&gt;consul&lt;/code&gt;, or &lt;code&gt;zookeeper&lt;/code&gt; here, CoreOS comes with &lt;code&gt;etcd&lt;/code&gt; thus makes it an excellent choice for running Docker Swarm.&lt;/p&gt;

&lt;p&gt;You will need three servers capable of running &lt;a href=&#34;http://coreos.com&#34;&gt;CoreOS&lt;/a&gt;.  See the &amp;ldquo;Try Out CoreOS&amp;rdquo; section of their website for various installation methods for different infrastructure. For this guide I will use the official &lt;a href=&#34;https://github.com/coreos/coreos-vagrant&#34;&gt;CoreOS Vagrant Example&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;skip the rest of this section if you install CoreOS for a different platform&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Clone down the Vagrant example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/coreos/coreos-vagrant.git vagrant-docker-swarm 
Cloning into &#39;vagrant-docker-swarm&#39;...
remote: Counting objects: 411, done.
remote: Total 411 (delta 0), reused 0 (delta 0), pack-reused 411
Receiving objects: 100% (411/411), 100.33 KiB | 0 bytes/s, done.
Resolving deltas: 100% (181/181), done.
Checking connectivity... done.
cd vagrant-docker-swarm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Edit the &lt;code&gt;Vagrantfile&lt;/code&gt; to set &lt;code&gt;$num_instances = 3&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;on Unix-like systems you can do this easily with sed&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sed -i &#39;s/\$num_instances = 1/\$num_instances = 3/&#39; Vagrantfile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Get a new etcd discovery-url:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;if you are on a windows box and don&amp;rsquo;t have curl you can paste the url into a web browser to get the discovery-url&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl https://discovery.etcd.io/new\?size\=3
https://discovery.etcd.io/6a9c62105f04dac40a29b90fbed322ef
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create a cloud-init file called &lt;code&gt;user-data&lt;/code&gt; in the base of the repo using the discovery-url from above:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#cloud-config

coreos:
  etcd2:
    discovery: https://discovery.etcd.io/888fd1e440faf680a7abb3fd934da6fd
    advertise-client-urls: http://$public_ipv4:2379
    initial-advertise-peer-urls: http://$public_ipv4:2380
    listen-client-urls: http://0.0.0.0:2379,http://0.0.0.0:4001
    listen-peer-urls: http://$public_ipv4:2380,http://$public_ipv4:7001
  units:
    - name: etcd2.service
      command: start

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Start up the CoreOS VMs and log into the first one to check everything worked ok:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vagrant up
Bringing machine &#39;core-01&#39; up with &#39;virtualbox&#39; provider...
Bringing machine &#39;core-02&#39; up with &#39;virtualbox&#39; provider...
Bringing machine &#39;core-03&#39; up with &#39;virtualbox&#39; provider...
...
$ vagrant ssh core-01
$ etcdctl member list
3c5901a3db54efa3: name=f1bae7bba7714ed7b4585c6b1256ddb2 peerURLs=http://172.17.8.101:2380 clientURLs=http://172.17.8.101:2379
9eeb141350af8439: name=5c8e57890d114d7d9d7aef662033a6e0 peerURLs=http://172.17.8.103:2380 clientURLs=http://172.17.8.103:2379
ebcc652087dfe6e8: name=de426249d3b34e23a5706d99b4900665 peerURLs=http://172.17.8.102:2380 clientURLs=http://172.17.8.102:2379
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;docker-swarm&#34;&gt;Docker Swarm&lt;/h2&gt;

&lt;p&gt;Now that we have several CoreOS servers with a working etcd cluster we can move on to setting up Docker Swarm.&lt;/p&gt;

&lt;p&gt;We need to modify docker to listen on tcp port &lt;code&gt;2376&lt;/code&gt; as well as registering itself to service discovery (which will allow us to set up overlay networking later on).  We do this by creating a file &lt;code&gt;custom.conf&lt;/code&gt; in &lt;code&gt;/etc/systemd/system/docker.service.d/&lt;/code&gt; on each server.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;if not using vagrant change &lt;code&gt;eth1&lt;/code&gt; to match the primary interface for your server&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Service]
Environment=&amp;quot;DOCKER_OPTS=-H=0.0.0.0:2376 -H unix:///var/run/docker.sock --cluster-advertise eth1:2376 --cluster-store etcd://127.0.0.1:2379&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We then need to reload the &lt;code&gt;systemctl&lt;/code&gt; daemon and then restart docker for these changes to take effect.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo systemctl daemon-reload
sudo systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Check that you can access docker via tcp on one of your hosts:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker -H tcp://172.17.8.101:2376 info
Containers: 0
Images: 0
Engine Version: 1.9.1
Storage Driver: overlay
 Backing Filesystem: extfs
Execution Driver: native-0.2
Logging Driver: json-file
Kernel Version: 4.3.3-coreos
Operating System: CoreOS 899.1.0
CPUs: 1
Total Memory: 997.4 MiB
Name: core-01
ID: BK64:WF3J:5JU6:VYLI:YJSO:CAQH:HPYM:MPTG:FMTA:VLE3:HSMP:F4VQ
Cluster store: etcd://127.0.0.1:2379/docker

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;re now ready to run Docker Swarm itself. There are two extra components to running Docker Swarm, a Swarm Agent and a Swarm Manager.&lt;/p&gt;

&lt;p&gt;The Swarm Agent watches the local Docker service via it&amp;rsquo;s TCP port and registers it into service discovery (etcd in our case).  We will run this on each server like so:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;set the &amp;ndash;addr= argument to match the primary IP of each node&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d --name swarm-agent \
    --net=host swarm:latest \
        join --addr=172.17.8.101:2376 \
        etcd://127.0.0.1:2379
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The Swarm Manager watches service discovery and exposes a TCP port (2375) which when accessed by a Docker client will perform actions and schedule containers across the Swarm cluster.&lt;/p&gt;

&lt;p&gt;To ensure High Availability of our cluster we&amp;rsquo;ll run a Swarm Manager on each server:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d --name swarm-manager 
    --net=host swarm:latest manage \
    etcd://127.0.0.1:2379
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assuming everything went smoothly we can now access the swarm cluster via the Swarm Managers TCP port on any of the servers:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker -H tcp://172.17.8.101:2375 info
Containers: 6
Images: 5
Role: primary
Strategy: spread
Filters: health, port, dependency, affinity, constraint
Nodes: 3
 core-01: 172.17.8.101:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.023 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.3.3-coreos, operatingsystem=CoreOS 899.1.0, storagedriver=overlay
 core-02: 172.17.8.102:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.023 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.3.3-coreos, operatingsystem=CoreOS 899.1.0, storagedriver=overlay
 core-03: 172.17.8.103:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.023 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.3.3-coreos, operatingsystem=CoreOS 899.1.0, storagedriver=overlay
CPUs: 3
Total Memory: 3.068 GiB
Name: core-01
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our next step is to create an overlay network using the &lt;code&gt;docker network&lt;/code&gt; command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker -H tcp://172.17.8.101:2375 network create --driver overlay my-net
614913b275dee43a63b48d08b4f5e52f7c0e531d70c63eeb8bb35624470da0c4

$ docker -H tcp://172.17.8.101:2375 network ls                            
NETWORK ID          NAME                DRIVER
86ecb0cf32c6        core-02/none        null                
c7a291ed8366        core-01/host        host                
3747364c5961        core-03/none        null                
8245d6d3ac67        core-02/host        host                
614913b275de        my-net              overlay             
61ead145e9dd        core-01/bridge      bridge              
c9457c4f4588        core-03/bridge      bridge              
b8a6c75cb3b9        core-03/host        host                
bdc4d5ccd778        core-02/bridge      bridge              
66afdc892361        core-01/none        null
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally we&amp;rsquo;ll create a Container on one host and then check that it is accessible from another:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;replace the node==XXXX argument with the hostname of one of your hosts, make sure to use a different node for each docker command&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -it --name=web --net=my-net \
    -H tcp://172.17.8.101:2375 \
    --env=&amp;quot;constraint:node==core-01&amp;quot; nginx
e0fe18c946a5692806608f939d4d6f31c670e3f42bf3942a77142bed2095983e

$ docker run -it --rm --net=my-net \
    -H tcp://172.17.8.101:2375 \
    --env=&amp;quot;constraint:node==core02&amp;quot; busybox wget -O- http://web
Connecting to web (10.0.0.2:80)
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you&amp;rsquo;ve been following along you have successfully deployed a Highly Available Docker Swarm cluster.  From here you could use a load balancer to load balance the Swarm Manager port (2375) or even use Round Robin DNS.&lt;/p&gt;

&lt;p&gt;You may have notice there is no authentication or authorization on this and anybody with a Docker binary and TCP access to your hosts could spin up docker containers. This is fairly easily fixed by using Docker&amp;rsquo;s TLS cert based authorization.&lt;/p&gt;

&lt;p&gt;To read how to secure both Docker and Docker Swarm with TLS read the followup post &lt;a href=&#34;http://tech.paulcz.net/2016/01/secure-docker-with-tls/&#34;&gt;Secure Docker with TLS&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Openstacks and Ecosystems</title>
      <link>http://tech.paulcz.net/2016/01/openstacks-and-ecosystems/</link>
      <pubDate>Sat, 02 Jan 2016 13:00:42 -0600</pubDate>
      
      <guid>http://tech.paulcz.net/2016/01/openstacks-and-ecosystems/</guid>
      <description>&lt;p&gt;I have recently had a number of lengthy discussions on the &lt;a href=&#34;https://twitter.com/zehicle/status/678736665792356352&#34;&gt;Twitter&lt;/a&gt; about Interop, Users, and Ecosystems. Specifically about our need to focus on the OpenStack ecosystem to extend the OpenStack IaaS user experience to something a bit more platform[ish].&lt;/p&gt;

&lt;p&gt;I wrote a post for &lt;a href=&#34;http://sysadvent.blogspot.com/2015/12/day-16-merry-paasmas-and-very.html&#34;&gt;SysAdvent&lt;/a&gt; this year on developing applications on top of OpenStack using a collection of OpenSource tools to create a PaaS and CI/CD pipelines. I think it turned out quite well and really helped reinforce my beliefs on the subject.&lt;/p&gt;

&lt;p&gt;My buddy and future OpenStack Board member &lt;a href=&#34;https://twitter.com/jjasghar&#34;&gt;JJ Asghar&lt;/a&gt; has been spearheading a new &lt;a href=&#34;https://wiki.openstack.org/wiki/Osops&#34;&gt;OpenStack Operators Project&lt;/a&gt;. I plan to contribute to this project by creating some examples of deploying tools that provide higher level services on top of the OpenStack IaaS layer.&lt;/p&gt;

&lt;p&gt;Given that I am very bullish about the &lt;a href=&#34;http://docker.com&#34;&gt;Docker&lt;/a&gt; ecosystem it makes sense that my first contribution would be focussed on running one of the several &amp;ldquo;Docker container scheduling/cluster&amp;rdquo; tools.&lt;/p&gt;

&lt;p&gt;After playing around with a few of them, I settled on starting with Docker Swarm as its one of the easier to understand and run and doesn&amp;rsquo;t require any special tooling other than a recent install of the Docker binary to use.&lt;/p&gt;

&lt;p&gt;To increase simplicity I chose to use Hashicorp&amp;rsquo;s &lt;a href=&#34;http://terraform.io&#34;&gt;Terraform&lt;/a&gt; and use only the most basic of the OpenStack services to ensure a fairly high likelyhood that it will run on most fairly up to date OpenStack clouds.&lt;/p&gt;

&lt;p&gt;Based on the project&amp;rsquo;s suggestion I posted the Terraform files up to the &lt;a href=&#34;https://github.com/openstack/osops-tools-contrib/tree/master/terraform/dockerswarm-coreos&#34;&gt;osops-tools-contrib&lt;/a&gt; along with fairly comprehensive documentation on using it.&lt;/p&gt;

&lt;p&gt;I hope this and future work I plan to do to create similar examples will help the OpenStack Community out in some small way.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>